{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpywt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Data Preparation\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\tensorflow\\__init__.py:30\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03mTop-level module of TensorFlow. By convention, we refer to this module as\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m`tf` instead of `tensorflow`, following the common practice of importing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03mthis file with a file generated from [`api_template.__init__.py`](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/api_template.__init__.py)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order,protected-access,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_distutils\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_inspect\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data Preparation\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/origbal\"\n",
    "\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess data (resize, normalize, etc.)\n",
    "\n",
    "# Wavelet Transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs\n",
    "    return LL, (LH, HL, HH)\n",
    "\n",
    "# Building CNN Model\n",
    "model = tf.keras.Sequential([\n",
    "    # Define your CNN layers here\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Model Evaluation\n",
    "loss, mse = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Squared Error on Test Set:\", mse)\n",
    "\n",
    "# Denoising Process\n",
    "def denoise_image(image):\n",
    "    noisy_ll, (noisy_lh, noisy_hl, noisy_hh) = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (noisy_lh, noisy_hl, noisy_hh)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Example denoising\n",
    "noisy_example = X_test[0]\n",
    "denoised_example = denoise_image(noisy_example)\n",
    "\n",
    "# Save or display the denoised image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m venv env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/16/2e/86f24451c2d530c88daf997cb8d6ac622c1d40d19f5a031ed68a4b73a374/numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n",
      "ERROR: No matching distribution found for cv2\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Obtaining dependency information for opencv-python from https://files.pythonhosted.org/packages/c7/ec/9dabb6a9abfdebb3c45b0cc52dec901caafef2b2c7e7d6a839ed86d81e91/opencv_python-4.9.0.80-cp37-abi3-win_amd64.whl.metadata\n",
      "  Using cached opencv_python-4.9.0.80-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.9.0.80-cp37-abi3-win_amd64.whl (38.6 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pywt (from versions: none)\n",
      "ERROR: No matching distribution found for pywt\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pywt (from versions: none)\n",
      "ERROR: No matching distribution found for pywt\n"
     ]
    }
   ],
   "source": [
    "pip install pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyWavelets\n",
      "  Obtaining dependency information for PyWavelets from https://files.pythonhosted.org/packages/37/cc/3aa33e99e1031227749711177d916ca3a4a1fa1b63d830776bc49991f7ff/pywavelets-1.5.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading pywavelets-1.5.0-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.22.4 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from PyWavelets) (1.26.4)\n",
      "Downloading pywavelets-1.5.0-cp312-cp312-win_amd64.whl (4.2 MB)\n",
      "   ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.2/4.2 MB 4.9 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.4/4.2 MB 4.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.7/4.2 MB 4.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.8/4.2 MB 4.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.0/4.2 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.3/4.2 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.5/4.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.0/4.2 MB 4.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.3/4.2 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.4/4.2 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.6/4.2 MB 4.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.0/4.2 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.2/4.2 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.4/4.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.6/4.2 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.2/4.2 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.2/4.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.2/4.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.2/4.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.2/4.2 MB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: PyWavelets\n",
      "Successfully installed PyWavelets-1.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install PyWavelets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sequential model sequential cannot be built because it has no layers. Call `model.add(layer)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Model Training\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Model Evaluation\u001b[39;00m\n\u001b[0;32m     58\u001b[0m loss, mse \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\models\\sequential.py:153\u001b[0m, in \u001b[0;36mSequential.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequential model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be built because it has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno layers. Call `model.add(layer)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer):\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape \u001b[38;5;241m!=\u001b[39m input_shape:\n",
      "\u001b[1;31mValueError\u001b[0m: Sequential model sequential cannot be built because it has no layers. Call `model.add(layer)`."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pywt  # Added import statement for PyWavelets\n",
    "\n",
    "# Your existing code follows...\n",
    "\n",
    "# Data Preparation\n",
    "def load_data(data_dir, target_size=(256, 256)):  # Change the target size as needed\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, target_size)  # Resize the image to a fixed size\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "noisy_data_dir = \"CBSD68/noisy50\"\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_images = load_data(noisy_data_dir, target_size=(256, 256))\n",
    "clean_images = load_data(clean_data_dir, target_size=(256, 256))\n",
    "\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess data (resize, normalize, etc.)\n",
    "\n",
    "# Wavelet Transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs\n",
    "    return LL, (LH, HL, HH)\n",
    "\n",
    "# Building CNN Model\n",
    "model = tf.keras.Sequential([\n",
    "    # Define your CNN layers here\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Model Evaluation\n",
    "loss, mse = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Squared Error on Test Set:\", mse)\n",
    "\n",
    "# Denoising Process\n",
    "def denoise_image(image):\n",
    "    noisy_ll, (noisy_lh, noisy_hl, noisy_hh) = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (noisy_lh, noisy_hl, noisy_hh)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Example denoising\n",
    "noisy_example = X_test[0]\n",
    "denoised_example = denoise_image(noisy_example)\n",
    "\n",
    "# Save or display the denoised image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/tensorboard-data-server/\n",
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/76/4f/39ddae9fb07b8c039fa5a5f2b6623c6e0564199d82da33fcef62bcf93174/tensorflow-2.16.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached tensorflow-2.16.1-cp312-cp312-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-intel==2.16.1 from https://files.pythonhosted.org/packages/14/5a/0e2c734acb91d22fa67ccb7f0cc869e24c418486aaba3d7ca8cad158d5a0/tensorflow_intel-2.16.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached tensorflow_intel-2.16.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for astunparse>=1.6.0 from https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl.metadata\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for flatbuffers>=23.5.26 from https://files.pythonhosted.org/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 from https://files.pythonhosted.org/packages/fa/39/5aae571e5a5f4de9c3445dae08a530498e5c53b0e74410eeeb0991c79047/gast-0.5.4-py3-none-any.whl.metadata\n",
      "  Using cached gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for google-pasta>=0.1.1 from https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl.metadata\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for h5py>=3.10.0 from https://files.pythonhosted.org/packages/9a/10/b0249532b9f91b0390fb1f434ca9b57581dd57112323bf43144f33117814/h5py-3.10.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached h5py-3.10.0-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/0b/2d/3f480b1e1d31eb3d6de5e3ef641954e5c67430d5ac93b7fa7e07589576c7/libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for ml-dtypes~=0.3.1 from https://files.pythonhosted.org/packages/47/f3/847da54c3d243ff2aa778078ecf09da199194d282744718ef325dd8afd41/ml_dtypes-0.3.2-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached ml_dtypes-0.3.2-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for opt-einsum>=2.3.2 from https://files.pythonhosted.org/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl.metadata\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/ad/6e/1bed3b7c904cc178cb8ee8dbaf72934964452b3de95b7a63412591edb93c/protobuf-4.25.3-cp310-abi3-win_amd64.whl.metadata\n",
      "  Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for requests<3,>=2.21.0 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting setuptools (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for setuptools from https://files.pythonhosted.org/packages/92/e1/1c8bb3420105e70bdf357d57dd5567202b4ef8d27f810e98bb962d950834/setuptools-69.2.0-py3-none-any.whl.metadata\n",
      "  Downloading setuptools-69.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for termcolor>=1.1.0 from https://files.pythonhosted.org/packages/d9/5f/8c716e47b3a50cbd7c146f45881e11d9414def768b7cd9c5e6650ec2a80a/termcolor-2.4.0-py3-none-any.whl.metadata\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for typing-extensions>=3.6.6 from https://files.pythonhosted.org/packages/f9/de/dc04a3ea60b22624b51c703a84bbe0184abcd1d0b9bc8074b5d6b7ab90bb/typing_extensions-4.10.0-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for wrapt>=1.11.0 from https://files.pythonhosted.org/packages/5c/cc/8297f9658506b224aa4bd71906447dea6bb0ba629861a758c28f67428b91/wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/71/36/75dc1047117efa2df2c7448e257c90e3af106c36d1592f9e9fadb880013b/grpcio-1.62.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached grpcio-1.62.1-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for tensorboard<2.17,>=2.16 from https://files.pythonhosted.org/packages/3a/d0/b97889ffa769e2d1fdebb632084d5e8b53fc299d43a537acee7ec0c021a3/tensorboard-2.16.2-py3-none-any.whl.metadata\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for keras>=3.0.0 from https://files.pythonhosted.org/packages/59/a8/d94e8acb59d678d908fe1db0c7ad89dfa2c2e2e529eeb3c2b3cc218a758d/keras-3.1.1-py3-none-any.whl.metadata\n",
      "  Downloading keras-3.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for wheel<1.0,>=0.23.0 from https://files.pythonhosted.org/packages/7d/cd/d7460c9a869b16c3dd4e1e403cce337df165368c71d6af229a74699622ce/wheel-0.43.0-py3-none-any.whl.metadata\n",
      "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/87/67/a37f6214d0e9fe57f6ae54b2956d550ca8365857f42a1ce0392bb21d9410/rich-13.7.1-py3-none-any.whl.metadata\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for namex from https://files.pythonhosted.org/packages/cd/43/b971880e2eb45c0bee2093710ae8044764a89afe9620df34a231c6f0ecd2/namex-0.0.7-py3-none-any.whl.metadata\n",
      "  Using cached namex-0.0.7-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for optree from https://files.pythonhosted.org/packages/8d/d6/8fbe48f9a022cd58926be69a5e8a6c2b96b7206f2bd722116b37d334bb50/optree-0.11.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading optree-0.11.0-cp312-cp312-win_amd64.whl.metadata (46 kB)\n",
      "     ---------------------------------------- 0.0/46.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/46.2 kB ? eta -:--:--\n",
      "     ------------------------- ------------ 30.7/46.2 kB 435.7 kB/s eta 0:00:01\n",
      "     --------------------------------- ---- 41.0/46.2 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 46.2/46.2 kB 327.0 kB/s eta 0:00:00\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/b6/7c/8debebb4f90174074b827c63242c23851bdf00a532489fba57fef3416e40/charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for idna<4,>=2.5 from https://files.pythonhosted.org/packages/c2/e7/a82b05cf63a603df6e68d59ae6a68bf5064484a0718ea5033660af4b54a9/idna-3.6-py3-none-any.whl.metadata\n",
      "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/a2/73/a68704750a7679d0b6d3ad7aa8d4da8e14e151ae82e6fee774e6e0d05ec8/urllib3-2.2.1-py3-none-any.whl.metadata\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for certifi>=2017.4.17 from https://files.pythonhosted.org/packages/ba/06/a07f096c664aeb9f01624f858c3add0a4e913d6c96257acb4fce61e7de14/certifi-2024.2.2-py3-none-any.whl.metadata\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/fc/b3/0c0c994fe49cd661084f8d5dc06562af53818cc0abefaca35bdc894577c3/Markdown-3.6-py3-none-any.whl.metadata\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for werkzeug>=1.0.1 from https://files.pythonhosted.org/packages/c3/fc/254c3e9b5feb89ff5b9076a23218dafbc99c96ac5941e900b71206e6313b/werkzeug-3.0.1-py3-none-any.whl.metadata\n",
      "  Using cached werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for MarkupSafe>=2.1.1 from https://files.pythonhosted.org/packages/3f/14/c3554d512d5f9100a95e737502f4a2323a1959f6d0d01e0d0997b35f7b10/MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for mdurl~=0.1 from https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl.metadata\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow-2.16.1-cp312-cp312-win_amd64.whl (2.1 kB)\n",
      "Using cached tensorflow_intel-2.16.1-cp312-cp312-win_amd64.whl (377.1 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.62.1-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "Using cached h5py-3.10.0-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "Downloading keras-3.1.1-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.4/1.1 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.6/1.1 MB 7.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 0.8/1.1 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.0/1.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.1/1.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/26.4 MB 4.3 MB/s eta 0:00:07\n",
      "    --------------------------------------- 0.4/26.4 MB 4.4 MB/s eta 0:00:06\n",
      "    --------------------------------------- 0.6/26.4 MB 4.4 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.9/26.4 MB 4.2 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.3/26.4 MB 4.7 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.6/26.4 MB 5.0 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.9/26.4 MB 4.8 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 2.2/26.4 MB 4.8 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 2.6/26.4 MB 5.0 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.8/26.4 MB 4.9 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 3.0/26.4 MB 4.9 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 3.3/26.4 MB 5.1 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.4/26.4 MB 5.0 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.7/26.4 MB 4.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 4.0/26.4 MB 4.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 4.3/26.4 MB 5.0 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 4.5/26.4 MB 5.0 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 4.8/26.4 MB 5.0 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 5.2/26.4 MB 5.0 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 5.4/26.4 MB 5.0 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 5.6/26.4 MB 5.0 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 5.8/26.4 MB 5.0 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.0/26.4 MB 5.0 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.4/26.4 MB 4.9 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.8/26.4 MB 4.9 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 7.0/26.4 MB 4.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.3/26.4 MB 5.0 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.7/26.4 MB 5.0 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.9/26.4 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 8.2/26.4 MB 5.0 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 8.4/26.4 MB 5.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 8.8/26.4 MB 5.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 9.2/26.4 MB 5.0 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 9.7/26.4 MB 5.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 10.0/26.4 MB 5.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 10.2/26.4 MB 5.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 10.6/26.4 MB 5.2 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 10.9/26.4 MB 5.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 11.2/26.4 MB 5.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 11.5/26.4 MB 5.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 11.7/26.4 MB 5.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 12.2/26.4 MB 5.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 12.7/26.4 MB 5.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 13.0/26.4 MB 5.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 13.4/26.4 MB 5.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 13.7/26.4 MB 5.5 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 13.9/26.4 MB 5.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 14.3/26.4 MB 5.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 14.6/26.4 MB 5.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 14.8/26.4 MB 5.5 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 15.0/26.4 MB 5.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 15.2/26.4 MB 5.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 15.5/26.4 MB 5.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 15.7/26.4 MB 5.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 15.8/26.4 MB 5.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 16.0/26.4 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 16.2/26.4 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 16.4/26.4 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 16.4/26.4 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 16.7/26.4 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 16.8/26.4 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 17.0/26.4 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 17.1/26.4 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.2/26.4 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.3/26.4 MB 4.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.4/26.4 MB 4.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.5/26.4 MB 4.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.6/26.4 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.7/26.4 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.8/26.4 MB 4.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 17.9/26.4 MB 4.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 18.0/26.4 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 18.1/26.4 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 18.3/26.4 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 18.5/26.4 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 18.7/26.4 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 19.0/26.4 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 19.2/26.4 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 19.5/26.4 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 19.7/26.4 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 19.9/26.4 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 20.1/26.4 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 20.5/26.4 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 20.6/26.4 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 20.9/26.4 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 21.0/26.4 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 21.2/26.4 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 21.5/26.4 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 21.7/26.4 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 21.9/26.4 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 22.1/26.4 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 22.3/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.5/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 23.0/26.4 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.2/26.4 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.5/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.7/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.0/26.4 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.2/26.4 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.5/26.4 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.7/26.4 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 25.0/26.4 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.5/26.4 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.8/26.4 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.3/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 3.0 MB/s eta 0:00:00\n",
      "Using cached ml_dtypes-0.3.2-cp312-cp312-win_amd64.whl (128 kB)\n",
      "Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Downloading setuptools-69.2.0-py3-none-any.whl (821 kB)\n",
      "   ---------------------------------------- 0.0/821.5 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 194.6/821.5 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 460.8/821.5 kB 5.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 686.1/821.5 kB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  819.2/821.5 kB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  819.2/821.5 kB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 821.5/821.5 kB 3.1 MB/s eta 0:00:00\n",
      "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "   ---------------------------------------- 0.0/105.4 kB ? eta -:--:--\n",
      "   -------------------------------------- - 102.4/105.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 105.4/105.4 kB 1.5 MB/s eta 0:00:00\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Using cached werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "Using cached namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.11.0-cp312-cp312-win_amd64.whl (241 kB)\n",
      "   ---------------------------------------- 0.0/241.7 kB ? eta -:--:--\n",
      "   -------------------------------------- - 235.5/241.7 kB 7.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 235.5/241.7 kB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 241.7/241.7 kB 1.6 MB/s eta 0:00:00\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorboard-data-server, setuptools, protobuf, opt-einsum, ml-dtypes, mdurl, MarkupSafe, markdown, idna, h5py, grpcio, google-pasta, gast, charset-normalizer, certifi, absl-py, werkzeug, requests, optree, markdown-it-py, astunparse, tensorboard, rich, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 certifi-2024.2.2 charset-normalizer-3.3.2 flatbuffers-24.3.25 gast-0.5.4 google-pasta-0.2.0 grpcio-1.62.1 h5py-3.10.0 idna-3.6 keras-3.1.1 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.7 opt-einsum-3.3.0 optree-0.11.0 protobuf-4.25.3 requests-2.31.0 rich-13.7.1 setuptools-69.2.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-intel-2.16.1 termcolor-2.4.0 typing-extensions-4.10.0 urllib3-2.2.1 werkzeug-3.0.1 wheel-0.43.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement distutils (from versions: none)\n",
      "ERROR: No matching distribution found for distutils\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install distutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyWavelets in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.22.4 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from PyWavelets) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install PyWavelets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (23.2.1)\n",
      "Collecting pip\n",
      "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/8a/6a/19e9fe04fca059ccf770861c7d5721ab4c2aebc539889e97c7977528a53b/pip-24.0-py3-none-any.whl.metadata\n",
      "  Using cached pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.2.1\n",
      "    Uninstalling pip-23.2.1:\n",
      "      Successfully uninstalled pip-23.2.1\n",
      "Successfully installed pip-24.0\n"
     ]
    }
   ],
   "source": [
    "! python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (69.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.1.post1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.12.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 30.7/60.4 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------- ----- 51.2/60.4 kB 871.5 kB/s eta 0:00:01\n",
      "     -------------------------------- ----- 51.2/60.4 kB 871.5 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.4/60.4 kB 321.8 kB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.4.1.post1-cp312-cp312-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.6 MB 8.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.6/10.6 MB 7.5 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.9/10.6 MB 7.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.1/10.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/10.6 MB 6.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.7/10.6 MB 6.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.0/10.6 MB 6.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.3/10.6 MB 6.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.7/10.6 MB 6.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 7.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.5/10.6 MB 7.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.9/10.6 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.3/10.6 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.9/10.6 MB 7.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.3/10.6 MB 7.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.6/10.6 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.9/10.6 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.6/10.6 MB 7.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.9/10.6 MB 7.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.2/10.6 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 7.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.2/10.6 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.5/10.6 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.1/10.6 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.3/10.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.7/10.6 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.1/10.6 MB 7.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.3/10.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 6.1 MB/s eta 0:00:00\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Downloading scipy-1.12.0-cp312-cp312-win_amd64.whl (45.8 MB)\n",
      "   ---------------------------------------- 0.0/45.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.4/45.8 MB 13.2 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.8/45.8 MB 9.7 MB/s eta 0:00:05\n",
      "    --------------------------------------- 1.1/45.8 MB 10.2 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.4/45.8 MB 9.1 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.8/45.8 MB 9.5 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 2.2/45.8 MB 9.2 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.7/45.8 MB 8.3 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 3.3/45.8 MB 9.1 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.6/45.8 MB 9.1 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 4.0/45.8 MB 9.0 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 4.4/45.8 MB 9.0 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.7/45.8 MB 9.1 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 5.1/45.8 MB 8.8 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 5.3/45.8 MB 8.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 5.6/45.8 MB 8.6 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 6.0/45.8 MB 8.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 6.4/45.8 MB 8.6 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 6.7/45.8 MB 8.8 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 7.1/45.8 MB 8.7 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 7.5/45.8 MB 8.8 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 7.8/45.8 MB 8.8 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 8.2/45.8 MB 8.7 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 8.5/45.8 MB 8.6 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 8.8/45.8 MB 8.7 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 9.1/45.8 MB 8.7 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 9.4/45.8 MB 8.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 9.7/45.8 MB 8.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 10.0/45.8 MB 8.5 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 10.4/45.8 MB 8.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 10.7/45.8 MB 8.3 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 11.1/45.8 MB 8.3 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 11.5/45.8 MB 8.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 11.8/45.8 MB 8.3 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 12.2/45.8 MB 8.3 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 12.5/45.8 MB 8.3 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 12.8/45.8 MB 8.4 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 13.2/45.8 MB 8.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 13.5/45.8 MB 8.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 13.8/45.8 MB 8.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 14.2/45.8 MB 8.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 14.6/45.8 MB 8.2 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 15.0/45.8 MB 8.3 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 15.3/45.8 MB 8.3 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 15.7/45.8 MB 8.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 16.1/45.8 MB 8.3 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 16.4/45.8 MB 8.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 16.7/45.8 MB 8.3 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 17.1/45.8 MB 8.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 17.4/45.8 MB 8.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 17.8/45.8 MB 8.2 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 18.1/45.8 MB 8.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 18.5/45.8 MB 8.2 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 18.8/45.8 MB 8.2 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 19.1/45.8 MB 8.2 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 19.5/45.8 MB 8.3 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 19.9/45.8 MB 8.3 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 20.3/45.8 MB 8.3 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 20.6/45.8 MB 8.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 20.9/45.8 MB 8.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 21.2/45.8 MB 8.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 21.5/45.8 MB 8.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 21.8/45.8 MB 8.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 22.1/45.8 MB 8.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 22.3/45.8 MB 8.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 22.6/45.8 MB 8.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 23.0/45.8 MB 8.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 23.1/45.8 MB 8.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 23.3/45.8 MB 7.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 23.5/45.8 MB 7.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 23.8/45.8 MB 7.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 24.2/45.8 MB 7.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 24.5/45.8 MB 7.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 24.8/45.8 MB 7.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 25.1/45.8 MB 7.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 25.4/45.8 MB 7.6 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 25.7/45.8 MB 7.5 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 26.0/45.8 MB 7.6 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 26.3/45.8 MB 7.5 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 26.7/45.8 MB 7.5 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 27.1/45.8 MB 7.5 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 27.4/45.8 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 27.7/45.8 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 28.0/45.8 MB 7.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 28.4/45.8 MB 7.6 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 28.7/45.8 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 29.1/45.8 MB 7.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 29.4/45.8 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 29.7/45.8 MB 7.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 30.0/45.8 MB 7.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 30.4/45.8 MB 7.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 30.8/45.8 MB 7.4 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 31.2/45.8 MB 7.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 31.5/45.8 MB 7.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 31.8/45.8 MB 7.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 32.2/45.8 MB 7.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 32.7/45.8 MB 7.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 33.1/45.8 MB 7.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 33.5/45.8 MB 8.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 33.9/45.8 MB 8.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 34.2/45.8 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 34.6/45.8 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 34.8/45.8 MB 7.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 35.5/45.8 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 35.8/45.8 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 36.2/45.8 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 36.5/45.8 MB 8.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 36.8/45.8 MB 8.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 37.1/45.8 MB 8.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 37.5/45.8 MB 8.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 37.8/45.8 MB 8.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 38.1/45.8 MB 8.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 38.5/45.8 MB 8.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 38.8/45.8 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 39.2/45.8 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 39.6/45.8 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 39.9/45.8 MB 8.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 40.2/45.8 MB 8.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 40.6/45.8 MB 8.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 40.9/45.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.3/45.8 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.6/45.8 MB 8.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 42.0/45.8 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 42.3/45.8 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 42.6/45.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.0/45.8 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.6/45.8 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.0/45.8 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.3/45.8 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.8/45.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.1/45.8 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.5/45.8 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.8/45.8 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.4.1.post1 scipy-1.12.0 threadpoolctl-3.4.0\n"
     ]
    }
   ],
   "source": [
    "! pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node gradient_tape/compile_loss/mse/sub/BroadcastGradientArgs defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 618, in run_forever\n\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1951, in _run_once\n\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 84, in _run\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_224\\1766067322.py\", line 50, in <module>\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 325, in fit\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 118, in one_step_on_iterator\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 106, in one_step_on_data\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 70, in train_step\n\nIncompatible shapes: [32,256,256,3] vs. [32,3]\n\t [[{{node gradient_tape/compile_loss/mse/sub/BroadcastGradientArgs}}]] [Op:__inference_one_step_on_iterator_1990]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Model Training\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Model Evaluation\u001b[39;00m\n\u001b[0;32m     53\u001b[0m loss, mse \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/compile_loss/mse/sub/BroadcastGradientArgs defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 618, in run_forever\n\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1951, in _run_once\n\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 84, in _run\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_224\\1766067322.py\", line 50, in <module>\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 325, in fit\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 118, in one_step_on_iterator\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 106, in one_step_on_data\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 70, in train_step\n\nIncompatible shapes: [32,256,256,3] vs. [32,3]\n\t [[{{node gradient_tape/compile_loss/mse/sub/BroadcastGradientArgs}}]] [Op:__inference_one_step_on_iterator_1990]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pywt\n",
    "\n",
    "# Data Preparation\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, target_size)  # Resize the image to a fixed size\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "noisy_data_dir = \"CBSD68/noisy50\"\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_images = load_data(noisy_data_dir, target_size=(256, 256))\n",
    "clean_images = load_data(clean_data_dir, target_size=(256, 256))\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Wavelet Transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs\n",
    "    return LL, (LH, HL, HH)\n",
    "\n",
    "# Define CNN Model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(3)  # Output layer, adjust the number of units as needed\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Model Evaluation\n",
    "loss, mse = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Squared Error on Test Set:\", mse)\n",
    "\n",
    "# Denoising Process\n",
    "def denoise_image(image):\n",
    "    noisy_ll, (noisy_lh, noisy_hl, noisy_hh) = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (noisy_lh, noisy_hl, noisy_hh)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Example denoising\n",
    "noisy_example = X_test[0]\n",
    "denoised_example = denoise_image(noisy_example)\n",
    "\n",
    "# Save or display the denoised image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node gradient_tape/compile_loss/mse/sub/BroadcastGradientArgs defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 618, in run_forever\n\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1951, in _run_once\n\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 84, in _run\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_224\\3006537999.py\", line 49, in <module>\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 325, in fit\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 118, in one_step_on_iterator\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 106, in one_step_on_data\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 70, in train_step\n\nIncompatible shapes: [32,256,256,3] vs. [32,3]\n\t [[{{node gradient_tape/compile_loss/mse/sub/BroadcastGradientArgs}}]] [Op:__inference_one_step_on_iterator_3911]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Model Training\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Model Evaluation\u001b[39;00m\n\u001b[0;32m     52\u001b[0m loss, mse \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/compile_loss/mse/sub/BroadcastGradientArgs defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 618, in run_forever\n\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1951, in _run_once\n\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 84, in _run\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_224\\3006537999.py\", line 49, in <module>\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 325, in fit\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 118, in one_step_on_iterator\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 106, in one_step_on_data\n\n  File \"d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 70, in train_step\n\nIncompatible shapes: [32,256,256,3] vs. [32,3]\n\t [[{{node gradient_tape/compile_loss/mse/sub/BroadcastGradientArgs}}]] [Op:__inference_one_step_on_iterator_3911]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs\n",
    "    return LL, (LH, HL, HH)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # Change the output dimension based on your task\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Model Evaluation\n",
    "loss, mse = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Squared Error on Test Set:\", mse)\n",
    "\n",
    "# Function for denoising process\n",
    "def denoise_image(image):\n",
    "    noisy_ll, (noisy_lh, noisy_hl, noisy_hh) = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (noisy_lh, noisy_hl, noisy_hh)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Example denoising\n",
    "noisy_example = X_test[0]\n",
    "denoised_example = denoise_image(noisy_example)\n",
    "\n",
    "# Save or display the denoised image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 66s/step - loss: 15008.1221 - mse: 15135.9863 - val_loss: 15977.5498 - val_mse: 15977.5488\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 13s/step - loss: 14488.3037 - mse: 14232.9326 - val_loss: 15977.4355 - val_mse: 15977.4355\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 15s/step - loss: 14795.4248 - mse: 14796.0283 - val_loss: 15977.4287 - val_mse: 15977.4287\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14s/step - loss: 14584.7871 - mse: 14409.8594 - val_loss: 15977.4287 - val_mse: 15977.4287\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15s/step - loss: 14909.9326 - mse: 15005.9590 - val_loss: 15977.4287 - val_mse: 15977.4287\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15s/step - loss: 14734.6826 - mse: 14684.6680 - val_loss: 15977.4287 - val_mse: 15977.4287\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15s/step - loss: 14689.9482 - mse: 14602.6572 - val_loss: 15977.4287 - val_mse: 15977.4287\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15s/step - loss: 14824.8848 - mse: 14850.0400 - val_loss: 15977.4287 - val_mse: 15977.4287\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12s/step - loss: 14641.4922 - mse: 14513.8193 - val_loss: 15977.4287 - val_mse: 15977.4287\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 14s/step - loss: 14759.4600 - mse: 14730.0928 - val_loss: 15977.4287 - val_mse: 15977.4287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 15977.4287 - mse: 15977.4287\n",
      "Mean Squared Error on Test Set: 15977.4287109375\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"conv2d_6\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (1, 256, 128, 2)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(1, 256, 128, 2), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Example denoising\u001b[39;00m\n\u001b[0;32m     59\u001b[0m noisy_example \u001b[38;5;241m=\u001b[39m X_test[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 60\u001b[0m denoised_example \u001b[38;5;241m=\u001b[39m \u001b[43mdenoise_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_example\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Save or display the denoised image\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 54\u001b[0m, in \u001b[0;36mdenoise_image\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdenoise_image\u001b[39m(image):\n\u001b[0;32m     53\u001b[0m     noisy_ll, (noisy_lh, noisy_hl, noisy_hh) \u001b[38;5;241m=\u001b[39m wavelet_transform(image)\n\u001b[1;32m---> 54\u001b[0m     denoised_ll \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_ll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     denoised_image \u001b[38;5;241m=\u001b[39m pywt\u001b[38;5;241m.\u001b[39midwt2((denoised_ll\u001b[38;5;241m.\u001b[39msqueeze(), (noisy_lh, noisy_hl, noisy_hh)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhaar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m denoised_image\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    224\u001b[0m             value,\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    226\u001b[0m         }:\n\u001b[1;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"conv2d_6\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (1, 256, 128, 2)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(1, 256, 128, 2), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs\n",
    "    return LL, (LH, HL, HH)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Model Evaluation\n",
    "loss, mse = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Squared Error on Test Set:\", mse)\n",
    "\n",
    "# Function for denoising process\n",
    "def denoise_image(image):\n",
    "    noisy_ll, (noisy_lh, noisy_hl, noisy_hh) = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (noisy_lh, noisy_hl, noisy_hh)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Example denoising\n",
    "noisy_example = X_test[0]\n",
    "denoised_example = denoise_image(noisy_example)\n",
    "\n",
    "# Save or display the denoised image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"conv2d_10\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 256, 256, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 256, 256, 3), dtype=uint8)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Model Training\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Model Evaluation\u001b[39;00m\n\u001b[0;32m     48\u001b[0m loss, mse \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    224\u001b[0m             value,\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    226\u001b[0m         }:\n\u001b[1;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"conv2d_10\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 256, 256, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 256, 256, 3), dtype=uint8)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Model Evaluation\n",
    "loss, mse = model.evaluate(X_test, y_test)\n",
    "print(\"Mean Squared Error on Test Set:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function for denoising process\n",
    "def denoise_image(image):\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=-1))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Example denoising\n",
    "noisy_example = X_test[0]\n",
    "denoised_example = denoise_image(noisy_example)\n",
    "\n",
    "# Save or display the denoised image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 256, 256, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 256, 256, 3), dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Model Training\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Function for denoising process\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdenoise_image\u001b[39m(image):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    224\u001b[0m             value,\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    226\u001b[0m         }:\n\u001b[1;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 256, 256, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 256, 256, 3), dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "\"\"\"# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.concatenate([images] * 3, axis=-1)\n",
    "    return images\"\"\"\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    # Convert images to float32 and normalize to the range [0, 1]\n",
    "    images = images.astype('float32') / 255.0\n",
    "    # If images are grayscale, convert them to RGB\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.concatenate([images] * 3, axis=-1)\n",
    "    return images\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(preprocess_data(X_train), preprocess_data(y_train), epochs=10, batch_size=32, validation_data=(preprocess_data(X_test), preprocess_data(y_test)))\n",
    "\n",
    "# Function for denoising process\n",
    "def denoise_image(image):\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=-1))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    return denoised_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load noisy image\n",
    "noisy_image_path = \"path/to/noisy_image.jpg\"  # Replace with the path to your noisy image\n",
    "noisy_image = cv2.imread(noisy_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Denoise the image\n",
    "denoised_image = denoise_image(noisy_image)\n",
    "\n",
    "# Save the denoised image\n",
    "cv2.imwrite(\"denoised_image.jpg\", denoised_image)\n",
    "\n",
    "# Display the denoised image\n",
    "cv2.imshow(\"Denoised Image\", denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    if len(images.shape) == 3 and images.shape[-1] == 1:\n",
    "        images = np.concatenate([images] * 3, axis=-1)\n",
    "    return images\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_preprocessed = preprocess_data(X_train)\n",
    "y_train_preprocessed = preprocess_data(y_train)\n",
    "X_test_preprocessed = preprocess_data(X_test)\n",
    "y_test_preprocessed = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model with updated input shape\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Save or display the denoised image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 17s/step - loss: 0.0677 - mse: 0.0682 - val_loss: 0.0637 - val_mse: 0.0637\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 16s/step - loss: 0.0625 - mse: 0.0630 - val_loss: 0.0672 - val_mse: 0.0672\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 16s/step - loss: 0.0620 - mse: 0.0615 - val_loss: 0.0659 - val_mse: 0.0659\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 16s/step - loss: 0.0608 - mse: 0.0604 - val_loss: 0.0632 - val_mse: 0.0632\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 14s/step - loss: 0.0623 - mse: 0.0634 - val_loss: 0.0627 - val_mse: 0.0627\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13s/step - loss: 0.0621 - mse: 0.0630 - val_loss: 0.0626 - val_mse: 0.0626\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17s/step - loss: 0.0609 - mse: 0.0611 - val_loss: 0.0631 - val_mse: 0.0631\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 16s/step - loss: 0.0608 - mse: 0.0612 - val_loss: 0.0643 - val_mse: 0.0643\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 17s/step - loss: 0.0605 - mse: 0.0607 - val_loss: 0.0642 - val_mse: 0.0642\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 14s/step - loss: 0.0608 - mse: 0.0613 - val_loss: 0.0628 - val_mse: 0.0628\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"conv2d_4\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (32, 128, 2, 1)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 128, 2, 1), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Example denoising\u001b[39;00m\n\u001b[0;32m     12\u001b[0m noisy_example \u001b[38;5;241m=\u001b[39m X_test[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 13\u001b[0m denoised_example \u001b[38;5;241m=\u001b[39m \u001b[43mdenoise_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_example\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m, in \u001b[0;36mdenoise_image\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdenoise_image\u001b[39m(image):\n\u001b[0;32m      6\u001b[0m     noisy_ll \u001b[38;5;241m=\u001b[39m wavelet_transform(image)\n\u001b[1;32m----> 7\u001b[0m     denoised_ll \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_ll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     denoised_image \u001b[38;5;241m=\u001b[39m pywt\u001b[38;5;241m.\u001b[39midwt2((denoised_ll\u001b[38;5;241m.\u001b[39msqueeze(), (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhaar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m denoised_image\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    224\u001b[0m             value,\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    226\u001b[0m         }:\n\u001b[1;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"conv2d_4\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (32, 128, 2, 1)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 128, 2, 1), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model Training\n",
    "model.fit(X_train_preprocessed, y_train_preprocessed, epochs=10, batch_size=32, validation_data=(X_test_preprocessed, y_test_preprocessed))\n",
    "\n",
    "# Function for denoising process\n",
    "def denoise_image(image):\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=-1))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Example denoising\n",
    "noisy_example = X_test[0]\n",
    "denoised_example = denoise_image(noisy_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12s/step - loss: 0.0589 - mse: 0.0587 - val_loss: 0.0602 - val_mse: 0.0602\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12s/step - loss: 0.0559 - mse: 0.0566 - val_loss: 0.0622 - val_mse: 0.0622\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12s/step - loss: 0.0553 - mse: 0.0544 - val_loss: 0.0615 - val_mse: 0.0615\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 14s/step - loss: 0.0569 - mse: 0.0579 - val_loss: 0.0602 - val_mse: 0.0602\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15s/step - loss: 0.0560 - mse: 0.0566 - val_loss: 0.0599 - val_mse: 0.0599\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15s/step - loss: 0.0563 - mse: 0.0572 - val_loss: 0.0598 - val_mse: 0.0598\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 12s/step - loss: 0.0546 - mse: 0.0542 - val_loss: 0.0596 - val_mse: 0.0596\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15s/step - loss: 0.0541 - mse: 0.0536 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 12s/step - loss: 0.0547 - mse: 0.0547 - val_loss: 0.0598 - val_mse: 0.0598\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12s/step - loss: 0.0559 - mse: 0.0570 - val_loss: 0.0594 - val_mse: 0.0594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Function for denoising process\n",
    "def denoise_image(image):\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Example denoising\n",
    "noisy_example = X_test[0]\n",
    "denoised_example = denoise_image(noisy_example)\n",
    "\n",
    "# Save or display the denoised image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mb\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588ms/step\n"
     ]
    }
   ],
   "source": [
    "# Function for denoising process\n",
    "def denoise_image(image):\n",
    "    # Perform wavelet transform to get LL coefficients\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    \n",
    "    # Predict denoised LL coefficients using the trained model\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    \n",
    "    # Perform inverse wavelet transform to get the denoised image\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    \n",
    "    return denoised_image\n",
    "\n",
    "# Load a noisy image (replace 'noisy_image_path' with the path to your noisy image)\n",
    "noisy_image = cv2.imread('0038.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Preprocess the noisy image\n",
    "noisy_image = cv2.resize(noisy_image, (256, 256))  # Resize if necessary\n",
    "noisy_image = noisy_image.astype('float32') / 255.0\n",
    "noisy_image = np.expand_dims(noisy_image, axis=-1)\n",
    "\n",
    "# Denoise the image\n",
    "denoised_image = denoise_image(noisy_image)\n",
    "\n",
    "# Display or save the denoised image\n",
    "cv2.imshow('Denoised Image', denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10s/step - loss: 0.0593 - mse: 0.0585 - val_loss: 0.0603 - val_mse: 0.0603\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11s/step - loss: 0.0573 - mse: 0.0588 - val_loss: 0.0615 - val_mse: 0.0615\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 11s/step - loss: 0.0561 - mse: 0.0562 - val_loss: 0.0608 - val_mse: 0.0608\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13s/step - loss: 0.0553 - mse: 0.0553 - val_loss: 0.0602 - val_mse: 0.0602\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12s/step - loss: 0.0557 - mse: 0.0560 - val_loss: 0.0599 - val_mse: 0.0599\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13s/step - loss: 0.0560 - mse: 0.0566 - val_loss: 0.0598 - val_mse: 0.0598\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 10s/step - loss: 0.0538 - mse: 0.0527 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12s/step - loss: 0.0547 - mse: 0.0545 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12s/step - loss: 0.0546 - mse: 0.0542 - val_loss: 0.0599 - val_mse: 0.0599\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12s/step - loss: 0.0556 - mse: 0.0561 - val_loss: 0.0595 - val_mse: 0.0595\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "\"\"\"# Function for denoising process\n",
    "def denoise_image(image):\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Example denoising\n",
    "noisy_example = X_test[0]\n",
    "denoised_example = denoise_image(noisy_example)\n",
    "\n",
    "# Save or display the denoised image\"\"\"\n",
    "\n",
    "# Function for denoising process\n",
    "def denoise_image(image):\n",
    "    # Perform wavelet transform to get LL coefficients\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    \n",
    "    # Predict denoised LL coefficients using the trained model\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    \n",
    "    # Perform inverse wavelet transform to get the denoised image\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar') \n",
    "    \n",
    "    return denoised_image\n",
    "\n",
    "# Load a noisy image (replace 'noisy_image_path' with the path to your noisy image)\n",
    "noisy_image = cv2.imread('0038.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Preprocess the noisy image\n",
    "noisy_image = cv2.resize(noisy_image, (256, 256))  # Resize if necessary\n",
    "noisy_image = noisy_image.astype('float32') / 255.0\n",
    "noisy_image = np.expand_dims(noisy_image, axis=-1)\n",
    "\n",
    "# Denoise the image\n",
    "denoised_image = denoise_image(noisy_image)\n",
    "\n",
    "# Display or save the denoised image\n",
    "cv2.imshow('Denoised Image', denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13s/step - loss: 0.0567 - mse: 0.0569 - val_loss: 0.0616 - val_mse: 0.0616\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12s/step - loss: 0.0561 - mse: 0.0561 - val_loss: 0.0605 - val_mse: 0.0605\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 14s/step - loss: 0.0563 - mse: 0.0570 - val_loss: 0.0602 - val_mse: 0.0602\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 16s/step - loss: 0.0560 - mse: 0.0565 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13s/step - loss: 0.0544 - mse: 0.0538 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 12s/step - loss: 0.0545 - mse: 0.0540 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13s/step - loss: 0.0546 - mse: 0.0544 - val_loss: 0.0596 - val_mse: 0.0596\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 10s/step - loss: 0.0549 - mse: 0.0550 - val_loss: 0.0595 - val_mse: 0.0595\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 11s/step - loss: 0.0557 - mse: 0.0566 - val_loss: 0.0594 - val_mse: 0.0594\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10s/step - loss: 0.0549 - mse: 0.0552 - val_loss: 0.0596 - val_mse: 0.0596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Function for denoising process\n",
    "def denoise_image(image):\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Example denoising\n",
    "noisy_example = X_test[0]\n",
    "denoised_example = denoise_image(noisy_example)\n",
    "\n",
    "# Save or display the denoised image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"denoising_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m denoised_image\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Load the trained CNN model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdenoising_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Update with the path to your CNN model file\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Load the noisy image\u001b[39;00m\n\u001b[0;32m     28\u001b[0m noisy_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoisy_image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Update with the path to your noisy image\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    177\u001b[0m         filepath,\n\u001b[0;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:155\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    151\u001b[0m training_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(training_config)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Compile model.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43msaving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args_from_training_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m )\n\u001b[0;32m    159\u001b[0m saving_utils\u001b[38;5;241m.\u001b[39mtry_build_compiled_arguments(model)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Set optimizer weights.\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:143\u001b[0m, in \u001b[0;36mcompile_args_from_training_config\u001b[1;34m(training_config, custom_objects)\u001b[0m\n\u001b[0;32m    141\u001b[0m loss_config \u001b[38;5;241m=\u001b[39m training_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43m_deserialize_nested_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Ensure backwards compatibility for losses in legacy H5 files\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m _resolve_compile_arguments_compat(loss, loss_config, losses)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:202\u001b[0m, in \u001b[0;36m_deserialize_nested_config\u001b[1;34m(deserialize_fn, config)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_single_object(config):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    205\u001b[0m         k: _deserialize_nested_config(deserialize_fn, v)\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    207\u001b[0m     }\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\losses\\__init__.py:124\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.losses.deserialize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeserialize\u001b[39m(name, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserializes a serialized loss class/function instance.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m        A Keras `Loss` instance or a loss function.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_OBJECTS_DICT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:570\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module_objects[config], types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m--> 570\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                \u001b[49m\u001b[43mserialize_with_public_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_module_name\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m deserialize_keras_object(\n\u001b[0;32m    577\u001b[0m             serialize_with_public_class(\n\u001b[0;32m    578\u001b[0m                 module_objects[config], inner_config\u001b[38;5;241m=\u001b[39minner_config\n\u001b[0;32m    579\u001b[0m             ),\n\u001b[0;32m    580\u001b[0m             custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    581\u001b[0m         )\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PLAIN_TYPES):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:671\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    670\u001b[0m     fn_name \u001b[38;5;241m=\u001b[39m inner_config\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;66;03m# Below, handling of all classes.\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# First, is it a shared object?\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:805\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 805\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure custom classes are decorated with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function for denoising process\n",
    "def denoise_image(model, image):\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Load the trained CNN model\n",
    "model = tf.keras.models.load_model('denoising_model.h5')  # Update with the path to your CNN model file\n",
    "\n",
    "# Load the noisy image\n",
    "noisy_image_path = 'noisy_image.jpg'  # Update with the path to your noisy image\n",
    "noisy_image = cv2.imread(noisy_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Preprocess the noisy image\n",
    "preprocessed_image = preprocess_data(noisy_image)\n",
    "\n",
    "# Denoise the image\n",
    "denoised_image = denoise_image(model, preprocessed_image)\n",
    "\n",
    "# Display comparison between noisy and denoised images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Noisy image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(noisy_image, cmap='gray')\n",
    "plt.title('Noisy Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Denoised image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(denoised_image, cmap='gray')\n",
    "plt.title('Denoised Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 11s/step - loss: 0.0588 - mse: 0.0586 - val_loss: 0.0603 - val_mse: 0.0603\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13s/step - loss: 0.0546 - mse: 0.0542 - val_loss: 0.0617 - val_mse: 0.0617\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 10s/step - loss: 0.0558 - mse: 0.0557 - val_loss: 0.0618 - val_mse: 0.0618\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12s/step - loss: 0.0565 - mse: 0.0568 - val_loss: 0.0607 - val_mse: 0.0607\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13s/step - loss: 0.0551 - mse: 0.0550 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13s/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13s/step - loss: 0.0550 - mse: 0.0550 - val_loss: 0.0599 - val_mse: 0.0599\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 13s/step - loss: 0.0556 - mse: 0.0560 - val_loss: 0.0598 - val_mse: 0.0598\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15s/step - loss: 0.0557 - mse: 0.0564 - val_loss: 0.0599 - val_mse: 0.0599\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11s/step - loss: 0.0550 - mse: 0.0551 - val_loss: 0.0600 - val_mse: 0.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"image_denoising_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained model\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_image(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    return np.expand_dims(img, axis=-1)\n",
    "\n",
    "# Function to denoise image\n",
    "def denoise_image(image):\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Load the noisy image\n",
    "noisy_image_path = \"0038.png\"\n",
    "noisy_image = cv2.imread(noisy_image_path)\n",
    "\n",
    "# Preprocess the noisy image\n",
    "preprocessed_image = preprocess_image(noisy_image)\n",
    "\n",
    "# Denoise the image\n",
    "denoised_image = denoise_image(preprocessed_image)\n",
    "\n",
    "# Convert to uint8 and scale to [0, 255] range\n",
    "denoised_image = (denoised_image * 255).astype(np.uint8)\n",
    "\n",
    "# Display or save the denoised image\n",
    "cv2.imshow(\"Denoised Image\", denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 10s/step - loss: 0.0580 - mse: 0.0574 - val_loss: 0.0602 - val_mse: 0.0602\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12s/step - loss: 0.0554 - mse: 0.0545 - val_loss: 0.0616 - val_mse: 0.0616\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 13s/step - loss: 0.0569 - mse: 0.0577 - val_loss: 0.0604 - val_mse: 0.0604\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11s/step - loss: 0.0555 - mse: 0.0557 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13s/step - loss: 0.0561 - mse: 0.0568 - val_loss: 0.0599 - val_mse: 0.0599\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13s/step - loss: 0.0560 - mse: 0.0567 - val_loss: 0.0598 - val_mse: 0.0598\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13s/step - loss: 0.0543 - mse: 0.0538 - val_loss: 0.0598 - val_mse: 0.0598\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11s/step - loss: 0.0531 - mse: 0.0517 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13s/step - loss: 0.0547 - mse: 0.0544 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13s/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0596 - val_mse: 0.0596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"image_denoising_model.h5\")\n",
    "\n",
    "# Function to denoise image\n",
    "\"\"\"def denoise_image(image):\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    return denoised_image\"\"\"\n",
    "\"\"\"\n",
    "def denoise_image(image):\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    noisy_ll_resized = cv2.resize(noisy_ll, (256, 256))\n",
    "    noisy_ll_resized = np.expand_dims(noisy_ll_resized, axis=-1)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll_resized, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Load a noisy image\n",
    "noisy_image = cv2.imread(\"0038.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Preprocess the noisy image\n",
    "preprocessed_image = preprocess_data(np.array([noisy_image]))\n",
    "\n",
    "# Denoise the image\n",
    "denoised_image = denoise_image(preprocessed_image)\n",
    "\n",
    "# Display or save the denoised image\n",
    "cv2.imwrite(\"denoised_image.jpg\", denoised_image)\n",
    "\"\"\"\n",
    "\n",
    "def denoise_image(image):\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    print(\"Shape of noisy_ll:\", noisy_ll.shape)  # Debugging: Print shape of noisy_ll\n",
    "    if noisy_ll.shape != (256, 256):\n",
    "        print(\"Resizing the image to (256, 256)\")\n",
    "        noisy_ll = cv2.resize(noisy_ll, (256, 256))\n",
    "    noisy_ll_resized = np.expand_dims(noisy_ll, axis=-1)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll_resized, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    return denoised_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[0;32m     44\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_denoising_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Path to your trained model\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Read the input noisy image\u001b[39;00m\n\u001b[0;32m     48\u001b[0m noisy_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0038.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Path to your input noisy image\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model_path):\n\u001b[1;32m----> 8\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    177\u001b[0m         filepath,\n\u001b[0;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:155\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    151\u001b[0m training_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(training_config)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Compile model.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43msaving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args_from_training_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m )\n\u001b[0;32m    159\u001b[0m saving_utils\u001b[38;5;241m.\u001b[39mtry_build_compiled_arguments(model)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Set optimizer weights.\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:143\u001b[0m, in \u001b[0;36mcompile_args_from_training_config\u001b[1;34m(training_config, custom_objects)\u001b[0m\n\u001b[0;32m    141\u001b[0m loss_config \u001b[38;5;241m=\u001b[39m training_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43m_deserialize_nested_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Ensure backwards compatibility for losses in legacy H5 files\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m _resolve_compile_arguments_compat(loss, loss_config, losses)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:202\u001b[0m, in \u001b[0;36m_deserialize_nested_config\u001b[1;34m(deserialize_fn, config)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_single_object(config):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    205\u001b[0m         k: _deserialize_nested_config(deserialize_fn, v)\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    207\u001b[0m     }\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\losses\\__init__.py:124\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.losses.deserialize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeserialize\u001b[39m(name, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserializes a serialized loss class/function instance.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m        A Keras `Loss` instance or a loss function.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_OBJECTS_DICT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:570\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module_objects[config], types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m--> 570\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                \u001b[49m\u001b[43mserialize_with_public_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_module_name\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m deserialize_keras_object(\n\u001b[0;32m    577\u001b[0m             serialize_with_public_class(\n\u001b[0;32m    578\u001b[0m                 module_objects[config], inner_config\u001b[38;5;241m=\u001b[39minner_config\n\u001b[0;32m    579\u001b[0m             ),\n\u001b[0;32m    580\u001b[0m             custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    581\u001b[0m         )\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PLAIN_TYPES):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:671\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    670\u001b[0m     fn_name \u001b[38;5;241m=\u001b[39m inner_config\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;66;03m# Below, handling of all classes.\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# First, is it a shared object?\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:805\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 805\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure custom classes are decorated with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pywt\n",
    "\n",
    "# Function to load the trained model\n",
    "def load_model(model_path):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    return model\n",
    "\n",
    "# Function to preprocess the input image (if needed)\n",
    "def preprocess_image(image):\n",
    "    # Perform any necessary preprocessing steps here\n",
    "    # For example, you can normalize the pixel values or resize the image\n",
    "    return image\n",
    "\n",
    "# Function to denoise the input image using the loaded model\n",
    "def denoise_image(model, noisy_image):\n",
    "    # Perform wavelet transform\n",
    "    noisy_ll = wavelet_transform(noisy_image)\n",
    "    \n",
    "    # Resize if necessary (assuming the shape expected by the model is (256, 256))\n",
    "    if noisy_ll.shape != (256, 256):\n",
    "        noisy_ll = cv2.resize(noisy_ll, (256, 256))\n",
    "    \n",
    "    # Expand dimensions to match model input shape\n",
    "    noisy_ll = np.expand_dims(noisy_ll, axis=-1)\n",
    "    \n",
    "    # Predict denoised image\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    \n",
    "    # Perform inverse wavelet transform to obtain denoised image\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    \n",
    "    return denoised_image\n",
    "\n",
    "# Function to perform wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    # Perform wavelet transform using pywt\n",
    "    # Example code for wavelet transform goes here\n",
    "    return img  # Replace this with actual wavelet transform code\n",
    "\n",
    "# Load the trained model\n",
    "model_path = \"image_denoising_model.h5\"  # Path to your trained model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Read the input noisy image\n",
    "noisy_image_path = \"0038.jpg\"  # Path to your input noisy image\n",
    "noisy_image = cv2.imread(noisy_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Preprocess the input image (if required)\n",
    "preprocessed_image = preprocess_image(noisy_image)\n",
    "\n",
    "# Denoise the image\n",
    "denoised_image = denoise_image(model, preprocessed_image)\n",
    "\n",
    "# Display or save the denoised image\n",
    "cv2.imwrite(\"0038.jpg\", denoised_image)\n",
    "# Display the denoised image using OpenCV or any other library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 31\u001b[0m\n\u001b[0;32m     26\u001b[0m clean_images \u001b[38;5;241m=\u001b[39m load_images(clean_images_path)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Preprocess the images if necessary (e.g., resize, normalize pixel values)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and testing sets\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Perform wavelet transform on the images\u001b[39;00m\n\u001b[0;32m     34\u001b[0m X_train_wavelet \u001b[38;5;241m=\u001b[39m [wavelet_transform(img) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m X_train]\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2660\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2662\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2665\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2308\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2305\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2309\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2312\u001b[0m     )\n\u001b[0;32m   2314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pywt\n",
    "\n",
    "# Function to perform wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')  # Using Haar wavelet for demonstration\n",
    "    LL, (LH, HL, HH) = coeffs  # LL: Approximation, LH, HL, HH: Details\n",
    "    return LL  # Return the approximation coefficients (LL subband)\n",
    "\n",
    "# Function to load images from directories\n",
    "def load_images(directory):\n",
    "    # Placeholder for loading images\n",
    "    return []\n",
    "\n",
    "# Load the dataset containing noisy and clean images\n",
    "\n",
    "\n",
    "noisy_images_path = \"CBSD68/noisy50\" \n",
    "clean_images_path = \"CBSD68/original\"\n",
    "\n",
    "noisy_images = load_images(noisy_images_path)\n",
    "clean_images = load_images(clean_images_path)\n",
    "\n",
    "# Preprocess the images if necessary (e.g., resize, normalize pixel values)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform wavelet transform on the images\n",
    "X_train_wavelet = [wavelet_transform(img) for img in X_train]\n",
    "X_test_wavelet = [wavelet_transform(img) for img in X_test]\n",
    "\n",
    "# Flatten the wavelet transformed images\n",
    "X_train_wavelet_flat = [img.flatten() for img in X_train_wavelet]\n",
    "X_test_wavelet_flat = [img.flatten() for img in X_test_wavelet]\n",
    "\n",
    "# Train a Support Vector Regression (SVR) model using the wavelet transformed features\n",
    "model = SVR()\n",
    "model.fit(X_train_wavelet_flat, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test_wavelet_flat)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Use the trained model to denoise new images\n",
    "# For example, if you have a new noisy image 'new_noisy_image':\n",
    "new_noisy_image = cv2.imread(\"0038.png\")\n",
    "new_noisy_image_wavelet = wavelet_transform(new_noisy_image)\n",
    "new_noisy_image_flat = new_noisy_image_wavelet.flatten()\n",
    "denoised_image_flat = model.predict([new_noisy_image_flat])\n",
    "denoised_image = denoised_image_flat.reshape(new_noisy_image.shape)\n",
    "\n",
    "# Save or display the denoised image\n",
    "cv2.imwrite(\"denoised_image.jpg\", denoised_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of noisy images: 68\n",
      "Number of clean images: 68\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (54,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Train a Support Vector Regression (SVR) model using the wavelet transformed features\u001b[39;00m\n\u001b[0;32m     55\u001b[0m model \u001b[38;5;241m=\u001b[39m SVR()\n\u001b[1;32m---> 56\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_wavelet_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[0;32m     59\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_wavelet_flat)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\svm\\_base.py:190\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    188\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    201\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    202\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    203\u001b[0m )\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1263\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1258\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     )\n\u001b[1;32m-> 1263\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1279\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1281\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:997\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    995\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 997\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1001\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (54,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pywt\n",
    "import os\n",
    "\n",
    "# Function to perform wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')  # Using Haar wavelet for demonstration\n",
    "    LL, (LH, HL, HH) = coeffs  # LL: Approximation, LH, HL, HH: Details\n",
    "    return LL  # Return the approximation coefficients (LL subband)\n",
    "\n",
    "# Function to load images from directories\n",
    "def load_images(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img = cv2.imread(os.path.join(directory, filename))\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Load the dataset containing noisy and clean images\n",
    "noisy_images_path = \"CBSD68/noisy50/\"\n",
    "clean_images_path = \"CBSD68/original\"\n",
    "\n",
    "\n",
    "noisy_images = load_images(noisy_images_path)\n",
    "clean_images = load_images(clean_images_path)\n",
    "\n",
    "# Check if images are loaded\n",
    "print(\"Number of noisy images:\", len(noisy_images))\n",
    "print(\"Number of clean images:\", len(clean_images))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Continue with the remaining code for denoising and evaluation...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Perform wavelet transform on the images\n",
    "X_train_wavelet = [wavelet_transform(img) for img in X_train]\n",
    "X_test_wavelet = [wavelet_transform(img) for img in X_test]\n",
    "\n",
    "# Flatten the wavelet transformed images\n",
    "X_train_wavelet_flat = [img.flatten() for img in X_train_wavelet]\n",
    "X_test_wavelet_flat = [img.flatten() for img in X_test_wavelet]\n",
    "\n",
    "# Train a Support Vector Regression (SVR) model using the wavelet transformed features\n",
    "model = SVR()\n",
    "model.fit(X_train_wavelet_flat, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test_wavelet_flat)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Use the trained model to denoise new images\n",
    "# For example, if you have a new noisy image 'new_noisy_image':\n",
    "new_noisy_image = cv2.imread(\"0038.png\")\n",
    "new_noisy_image_wavelet = wavelet_transform(new_noisy_image)\n",
    "new_noisy_image_flat = new_noisy_image_wavelet.flatten()\n",
    "denoised_image_flat = model.predict([new_noisy_image_flat])\n",
    "denoised_image = denoised_image_flat.reshape(new_noisy_image.shape)\n",
    "\n",
    "# Save or display the denoised image\n",
    "cv2.imwrite(\"denoised_image.jpg\", denoised_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of noisy images: 68\n",
      "Number of clean images: 68\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (54,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m X_test_wavelet \u001b[38;5;241m=\u001b[39m [wavelet_transform(img) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m X_test]\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Flatten the wavelet transformed features\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m X_train_wavelet_flat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX_train_wavelet\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m X_test_wavelet_flat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([img\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m X_test_wavelet])\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Train a Support Vector Regression (SVR) model using the wavelet transformed features\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (54,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pywt\n",
    "import os\n",
    "\n",
    "# Function to perform wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')  # Using Haar wavelet for demonstration\n",
    "    LL, (LH, HL, HH) = coeffs  # LL: Approximation, LH, HL, HH: Details\n",
    "    return LL  # Return the approximation coefficients (LL subband)\n",
    "\n",
    "# Function to load images from directories\n",
    "def load_images(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img = cv2.imread(os.path.join(directory, filename))\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset containing noisy and clean images\n",
    "noisy_images_path = \"CBSD68/noisy50\"\n",
    "clean_images_path = \"CBSD68/original\"\n",
    "\n",
    "noisy_images = load_images(noisy_images_path)\n",
    "clean_images = load_images(clean_images_path)\n",
    "\n",
    "# Check if images are loaded\n",
    "print(\"Number of noisy images:\", len(noisy_images))\n",
    "print(\"Number of clean images:\", len(clean_images))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform wavelet transform on the images\n",
    "X_train_wavelet = [wavelet_transform(img) for img in X_train]\n",
    "X_test_wavelet = [wavelet_transform(img) for img in X_test]\n",
    "\n",
    "# Flatten the wavelet transformed features\n",
    "X_train_wavelet_flat = np.array([img.flatten() for img in X_train_wavelet])\n",
    "X_test_wavelet_flat = np.array([img.flatten() for img in X_test_wavelet])\n",
    "\n",
    "# Train a Support Vector Regression (SVR) model using the wavelet transformed features\n",
    "model = SVR()\n",
    "model.fit(X_train_wavelet_flat, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test_wavelet_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of noisy images: 68\n",
      "Number of clean images: 68\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (54,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Train a Support Vector Regression (SVR) model using the wavelet transformed features\u001b[39;00m\n\u001b[0;32m     52\u001b[0m model \u001b[38;5;241m=\u001b[39m SVR()\n\u001b[1;32m---> 53\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_wavelet_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[0;32m     56\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_wavelet_flat)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\svm\\_base.py:190\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    188\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    201\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    202\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    203\u001b[0m )\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1279\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     )\n\u001b[0;32m   1263\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1264\u001b[0m     X,\n\u001b[0;32m   1265\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1277\u001b[0m )\n\u001b[1;32m-> 1279\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1281\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1299\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m-> 1300\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1301\u001b[0m     _assert_all_finite(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39mestimator_name)\n\u001b[0;32m   1302\u001b[0m     _ensure_no_complex_data(y)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1342\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Ravel column or 1d numpy array, else raises an error.\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;124;03marray([1, 1])\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1341\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y)\n\u001b[1;32m-> 1342\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1343\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1346\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1349\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1351\u001b[0m shape \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:997\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    995\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 997\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1001\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (54,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pywt\n",
    "import os\n",
    "\n",
    "# Function to perform wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')  # Using Haar wavelet for demonstration\n",
    "    LL, (LH, HL, HH) = coeffs  # LL: Approximation, LH, HL, HH: Details\n",
    "    return LL  # Return the approximation coefficients (LL subband)\n",
    "\n",
    "# Function to load images from directories\n",
    "def load_images(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img = cv2.imread(os.path.join(directory, filename))\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Load the dataset containing noisy and clean images\n",
    "noisy_images_path = \"CBSD68/noisy50\"\n",
    "clean_images_path = \"CBSD68/original\"\n",
    "\n",
    "noisy_images = load_images(noisy_images_path)\n",
    "clean_images = load_images(clean_images_path)\n",
    "\n",
    "# Check if images are loaded\n",
    "print(\"Number of noisy images:\", len(noisy_images))\n",
    "print(\"Number of clean images:\", len(clean_images))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform wavelet transform on the images\n",
    "X_train_wavelet = [wavelet_transform(img) for img in X_train]\n",
    "X_test_wavelet = [wavelet_transform(img) for img in X_test]\n",
    "\n",
    "# Resize wavelet transformed images to a common size\n",
    "resized_shape = (256, 256)  # Change this to your desired size\n",
    "X_train_wavelet_resized = [cv2.resize(img, resized_shape) for img in X_train_wavelet]\n",
    "X_test_wavelet_resized = [cv2.resize(img, resized_shape) for img in X_test_wavelet]\n",
    "\n",
    "# Flatten the resized wavelet transformed features\n",
    "X_train_wavelet_flat = np.array([img.flatten() for img in X_train_wavelet_resized])\n",
    "X_test_wavelet_flat = np.array([img.flatten() for img in X_test_wavelet_resized])\n",
    "\n",
    "# Train a Support Vector Regression (SVR) model using the wavelet transformed features\n",
    "model = SVR()\n",
    "model.fit(X_train_wavelet_flat, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test_wavelet_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (68,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m noisy_images_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCBSD68/noisy50\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m clean_images_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCBSD68/original\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 57\u001b[0m noisy_images \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_images_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m clean_images \u001b[38;5;241m=\u001b[39m load_images(clean_images_path)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Preprocess the images if necessary (e.g., resize, normalize pixel values)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 17\u001b[0m, in \u001b[0;36mload_images\u001b[1;34m(images_path)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m         images\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (68,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to load images\n",
    "def load_images(images_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(images_path):\n",
    "        img = cv2.imread(os.path.join(images_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform (placeholder)\n",
    "def wavelet_transform(image):\n",
    "    # Placeholder for wavelet transform code\n",
    "    return image\n",
    "\n",
    "# Function to preprocess data (placeholder)\n",
    "def preprocess_data(images):\n",
    "    # Placeholder for data preprocessing code\n",
    "    return images\n",
    "\n",
    "# Function to build the CNN model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2), padding='same'),\n",
    "        Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2), padding='same'),\n",
    "        Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "# Function to denoise image\n",
    "def denoise_image(image):\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    noisy_ll_resized = cv2.resize(noisy_ll, (256, 256))\n",
    "    noisy_ll_resized = np.expand_dims(noisy_ll_resized, axis=-1)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll_resized, axis=0))\n",
    "    denoised_image = cv2.resize(denoised_ll.squeeze(), (image.shape[1], image.shape[0]))\n",
    "    return denoised_image\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_images_path = \"CBSD68/noisy50\"\n",
    "clean_images_path = \"CBSD68/original\"\n",
    "noisy_images = load_images(noisy_images_path)\n",
    "clean_images = load_images(clean_images_path)\n",
    "\n",
    "# Preprocess the images if necessary (e.g., resize, normalize pixel values)\n",
    "noisy_images = preprocess_data(noisy_images)\n",
    "clean_images = preprocess_data(clean_images)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and train the CNN model\n",
    "model = build_model(input_shape=X_train.shape[1:])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mse = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test MSE:\", mse)\n",
    "\n",
    "# Example denoising\n",
    "example_index = 0\n",
    "noisy_example = X_test[example_index]\n",
    "denoised_example = denoise_image(noisy_example)\n",
    "\n",
    "# Display the noisy and denoised images\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Noisy Image\")\n",
    "plt.imshow(noisy_example, cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Denoised Image\")\n",
    "plt.imshow(denoised_example, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.3-cp312-cp312-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.2.0-cp312-cp312-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.50.0-cp312-cp312-win_amd64.whl.metadata (162 kB)\n",
      "     ---------------------------------------- 0.0/162.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/162.6 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/162.6 kB ? eta -:--:--\n",
      "     ------------- ----------------------- 61.4/162.6 kB 656.4 kB/s eta 0:00:01\n",
      "     -------------------- ---------------- 92.2/162.6 kB 585.1 kB/s eta 0:00:01\n",
      "     ------------------------ ----------- 112.6/162.6 kB 595.3 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 153.6/162.6 kB 654.6 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 153.6/162.6 kB 654.6 kB/s eta 0:00:01\n",
      "     ------------------------------------ 162.6/162.6 kB 513.0 kB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.5-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-10.2.0-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.8.3-cp312-cp312-win_amd64.whl (7.6 MB)\n",
      "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/7.6 MB 5.9 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.3/7.6 MB 4.2 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.3/7.6 MB 3.4 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.4/7.6 MB 2.3 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.6/7.6 MB 2.8 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.6/7.6 MB 2.9 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.8/7.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.9/7.6 MB 2.7 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.9/7.6 MB 2.7 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.0/7.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.3/7.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.3/7.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.3/7.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.4/7.6 MB 2.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.4/7.6 MB 1.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.5/7.6 MB 1.9 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.7/7.6 MB 2.0 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 1.8/7.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.1/7.6 MB 2.1 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.2/7.6 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.3/7.6 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.4/7.6 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.5/7.6 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.6/7.6 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.8/7.6 MB 2.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.9/7.6 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.2/7.6 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.5/7.6 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.6/7.6 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.7/7.6 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.9/7.6 MB 2.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.0/7.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 4.2/7.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.5/7.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.5/7.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 4.8/7.6 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 5.0/7.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.5/7.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 5.6/7.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 5.7/7.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.7/7.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.9/7.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.9/7.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.1/7.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.1/7.6 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.2/7.6 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.4/7.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.6/7.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.9/7.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.0/7.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.2/7.6 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.4/7.6 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.4/7.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.6/7.6 MB 2.6 MB/s eta 0:00:00\n",
      "Using cached contourpy-1.2.0-cp312-cp312-win_amd64.whl (187 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.50.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 16.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.6/2.2 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.2 MB 6.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.2 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.2 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.2/2.2 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.5/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.5/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.5/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.2 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.2 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.2 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.2 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.2 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.2 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.2 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.2 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 1.3 MB/s eta 0:00:00\n",
      "Using cached kiwisolver-1.4.5-cp312-cp312-win_amd64.whl (56 kB)\n",
      "Downloading pillow-10.2.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.3/2.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.5/2.6 MB 3.5 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.6/2.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.8/2.6 MB 3.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.0/2.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.1/2.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.2/2.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.5/2.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.5/2.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.5/2.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.1/2.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.3/2.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.3/2.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 2.9 MB/s eta 0:00:00\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.50.0 kiwisolver-1.4.5 matplotlib-3.8.3 pillow-10.2.0 pyparsing-3.1.2\n"
     ]
    }
   ],
   "source": [
    "! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of noisy images: 68\n",
      "Number of clean images: 68\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(images_path, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(images_path):\n",
    "        img = cv2.imread(os.path.join(images_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, target_size)  # Resize images to a common size\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_images_path = \"CBSD68/noisy50\"\n",
    "clean_images_path = \"CBSD68/original\"\n",
    "noisy_images = load_images(noisy_images_path)\n",
    "clean_images = load_images(clean_images_path)\n",
    "\n",
    "print(\"Number of noisy images:\", len(noisy_images))\n",
    "print(\"Number of clean images:\", len(clean_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (68,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m noisy_images_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCBSD68/noisy50\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     20\u001b[0m clean_images_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCBSD68/original\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 21\u001b[0m noisy_images \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_images_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m clean_images \u001b[38;5;241m=\u001b[39m load_images(clean_images_path)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Preprocess the images if necessary (e.g., resize, normalize pixel values)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and testing sets\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m, in \u001b[0;36mload_images\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m         images\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (68,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Function to load images from a given directory\n",
    "def load_images(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        img = cv2.imread(os.path.join(directory, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_images_path = \"CBSD68/noisy50\"\n",
    "clean_images_path = \"CBSD68/original\"\n",
    "noisy_images = load_images(noisy_images_path)\n",
    "clean_images = load_images(clean_images_path)\n",
    "\n",
    "# Preprocess the images if necessary (e.g., resize, normalize pixel values)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the CNN model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(None, None, 3)),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "checkpoint = ModelCheckpoint(\"image_denoising_model.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, callbacks=[checkpoint])\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"image_denoising_model.h5\")\n",
    "\n",
    "# Function to denoise an image using the trained model\n",
    "def denoise_image(image):\n",
    "    denoised_image = model.predict(np.expand_dims(image, axis=0))\n",
    "    return denoised_image[0]\n",
    "\n",
    "# Example denoising\n",
    "noisy_example = X_test[0]\n",
    "denoised_example = denoise_image(noisy_example)\n",
    "\n",
    "# Save the denoised image\n",
    "cv2.imwrite(\"denoised_image.jpg\", denoised_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (68,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Load dataset and apply wavelet transform to generate noisy images\u001b[39;00m\n\u001b[0;32m     31\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCBSD68/noisy50\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Choose desired noise level folder\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m noisy_images \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m noisy_images \u001b[38;5;241m=\u001b[39m apply_wavelet_transform(noisy_images)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Normalize images to range [0, 1]\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(folder_path)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Check if the image was loaded successfully\u001b[39;00m\n\u001b[0;32m     16\u001b[0m             dataset\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (68,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "def load_dataset(folder_path):\n",
    "    dataset = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.png'):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:  # Check if the image was loaded successfully\n",
    "                dataset.append(img)\n",
    "    return np.array(dataset)\n",
    "\n",
    "\n",
    "def apply_wavelet_transform(images):\n",
    "    transformed_images = []\n",
    "    for img in images:\n",
    "        coeffs2 = pywt.dwt2(img, 'haar')\n",
    "        LL, (LH, HL, HH) = coeffs2\n",
    "        noisy_coeffs = (LL, (LH * 0.05, HL * 0.10, HH * 0.15))  # Adjust noise levels\n",
    "        noisy_img = pywt.idwt2(noisy_coeffs, 'haar')\n",
    "        transformed_images.append(noisy_img)\n",
    "    return np.array(transformed_images)\n",
    "\n",
    "# Load dataset and apply wavelet transform to generate noisy images\n",
    "dataset_path = 'CBSD68/noisy50'  # Choose desired noise level folder\n",
    "noisy_images = load_dataset(dataset_path)\n",
    "noisy_images = apply_wavelet_transform(noisy_images)\n",
    "\n",
    "# Normalize images to range [0, 1]\n",
    "noisy_images = noisy_images / 255.0\n",
    "\n",
    "# Step 2: Model Building\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define model\n",
    "input_shape = (noisy_images.shape[1], noisy_images.shape[2], 1)\n",
    "model = build_model(input_shape)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Step 3: Model Training\n",
    "# Assuming you have corresponding clean images in the 'origbal' folder\n",
    "clean_images = load_dataset('CBSD68/original')\n",
    "clean_images = clean_images / 255.0  # Normalize\n",
    "\n",
    "# Train the model\n",
    "model.fit(noisy_images, clean_images, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Step 4: Model Evaluation and Inference\n",
    "# Evaluate on test data\n",
    "test_dataset_path = 'CBSD68/noisy50'  # Change to test data folder\n",
    "test_images = load_dataset(test_dataset_path)\n",
    "test_images = apply_wavelet_transform(test_images)\n",
    "test_images = test_images / 255.0  # Normalize\n",
    "\n",
    "# Denoise test images\n",
    "denoised_images = model.predict(test_images)\n",
    "\n",
    "# Show example results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(test_images[i].reshape(256, 256), cmap='gray')\n",
    "    plt.title('Noisy')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(2, 5, i+6)\n",
    "    plt.imshow(denoised_images[i].reshape(256, 256), cmap='gray')\n",
    "    plt.title('Denoised')\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wavelet_image\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Preprocess all images\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m noisy_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m noisy_images])\n\u001b[0;32m     39\u001b[0m original_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([preprocess_image(image) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m original_images])\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Step 3: Model Architecture\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 28\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Resize image to desired dimensions\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     resized_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# Normalize image to range [0, 1]\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     normalized_image \u001b[38;5;241m=\u001b[39m resized_image \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pywt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanSquaredError\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Data Preparation\n",
    "def load_data():\n",
    "    # Load CBSD68 dataset\n",
    "    noisy_images = []\n",
    "    original_images = []\n",
    "    for i in range(1, 69):\n",
    "        noisy_img = cv2.imread(f'CBSD68/noisy/{i}.png', cv2.IMREAD_GRAYSCALE)\n",
    "        orig_img = cv2.imread(f'CBSD68/original/{i}.png', cv2.IMREAD_GRAYSCALE)\n",
    "        noisy_images.append(noisy_img)\n",
    "        original_images.append(orig_img)\n",
    "    return np.array(noisy_images), np.array(original_images)\n",
    "\n",
    "noisy_images, original_images = load_data()\n",
    "\n",
    "# Step 2: Preprocessing\n",
    "def preprocess_image(image):\n",
    "    # Resize image to desired dimensions\n",
    "    resized_image = cv2.resize(image, (256, 256))\n",
    "    # Normalize image to range [0, 1]\n",
    "    normalized_image = resized_image / 255.0\n",
    "    # Apply wavelet transform (using Haar wavelet)\n",
    "    coeffs2 = pywt.dwt2(normalized_image, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs2\n",
    "    wavelet_image = np.concatenate((LL, LH, HL, HH), axis=0)\n",
    "    return wavelet_image\n",
    "\n",
    "# Preprocess all images\n",
    "noisy_images = np.array([preprocess_image(image) for image in noisy_images])\n",
    "original_images = np.array([preprocess_image(image) for image in original_images])\n",
    "\n",
    "# Step 3: Model Architecture\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    # Encoder\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    # Decoder\n",
    "    model.add(Conv2D(1, (3, 3), padding='same'))\n",
    "    model.add(Activation('sigmoid'))  # Ensure output values are between 0 and 1\n",
    "    return model\n",
    "\n",
    "input_shape = noisy_images[0].shape\n",
    "model = build_model(input_shape)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "model.summary()\n",
    "\n",
    "# Step 4: Training\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, original_images, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# Step 5: Evaluation\n",
    "# Evaluate model on test set and calculate metrics (PSNR, SSIM)\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = MeanSquaredError()\n",
    "    mse.update_state(y_test, y_pred)\n",
    "    mse_result = mse.result().numpy()\n",
    "    psnr_result = peak_signal_noise_ratio(y_test, y_pred)\n",
    "    ssim_result = structural_similarity(y_test, y_pred, multichannel=True)\n",
    "    return {'MSE': mse_result, 'PSNR': psnr_result, 'SSIM': ssim_result}\n",
    "\n",
    "metrics = evaluate_model(model, X_test, y_test)\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(metrics)\n",
    "\n",
    "# Step 6: Deployment\n",
    "# Deploy your model for inference, create user interface, or integrate into an application\n",
    "# This part depends on your specific requirements and could involve creating a user interface or integrating the model into an existing application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Using cached scikit_image-0.22.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from scikit-image) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from scikit-image) (1.12.0)\n",
      "Collecting networkx>=2.8 (from scikit-image)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pillow>=9.0.1 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from scikit-image) (10.2.0)\n",
      "Collecting imageio>=2.27 (from scikit-image)\n",
      "  Using cached imageio-2.34.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Using cached tifffile-2024.2.12-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging>=21 in d:\\greatestwork\\data\\cbsd68-dataset-master\\env\\lib\\site-packages (from scikit-image) (24.0)\n",
      "Collecting lazy_loader>=0.3 (from scikit-image)\n",
      "  Using cached lazy_loader-0.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Using cached scikit_image-0.22.0-cp312-cp312-win_amd64.whl (25.0 MB)\n",
      "Using cached imageio-2.34.0-py3-none-any.whl (313 kB)\n",
      "Using cached lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached tifffile-2024.2.12-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: tifffile, networkx, lazy_loader, imageio, scikit-image\n",
      "Successfully installed imageio-2.34.0 lazy_loader-0.3 networkx-3.2.1 scikit-image-0.22.0 tifffile-2024.2.12\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m noisy_images, original_images \u001b[38;5;241m=\u001b[39m load_data()\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Preprocess all images\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m noisy_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m noisy_images])\n\u001b[0;32m     71\u001b[0m original_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([preprocess_image(image) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m original_images])\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Split dataset into train and test sets\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 26\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Resize image to desired dimensions\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     resized_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Normalize image to range [0, 1]\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     normalized_image \u001b[38;5;241m=\u001b[39m resized_image \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pywt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanSquaredError\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Data Preparation\n",
    "def load_data():\n",
    "    # Load CBSD68 dataset\n",
    "    noisy_images = []\n",
    "    original_images = []\n",
    "    for i in range(1, 69):\n",
    "        noisy_img = cv2.imread(f'CBSD68/noisy/{i}.png', cv2.IMREAD_GRAYSCALE)\n",
    "        orig_img = cv2.imread(f'CBSD68/original/{i}.png', cv2.IMREAD_GRAYSCALE)\n",
    "        noisy_images.append(noisy_img)\n",
    "        original_images.append(orig_img)\n",
    "    return np.array(noisy_images), np.array(original_images)\n",
    "\n",
    "# Step 2: Preprocessing\n",
    "def preprocess_image(image):\n",
    "    # Resize image to desired dimensions\n",
    "    resized_image = cv2.resize(image, (256, 256))\n",
    "    # Normalize image to range [0, 1]\n",
    "    normalized_image = resized_image / 255.0\n",
    "    # Apply wavelet transform (using Haar wavelet)\n",
    "    coeffs2 = pywt.dwt2(normalized_image, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs2\n",
    "    wavelet_image = np.concatenate((LL, LH, HL, HH), axis=0)\n",
    "    return wavelet_image\n",
    "\n",
    "# Step 3: Model Architecture\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    # Encoder\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    # Decoder\n",
    "    model.add(Conv2D(1, (3, 3), padding='same'))\n",
    "    model.add(Activation('sigmoid'))  # Ensure output values are between 0 and 1\n",
    "    return model\n",
    "\n",
    "# Step 4: Training\n",
    "def train_model(X_train, y_train, X_test, y_test):\n",
    "    input_shape = X_train[0].shape\n",
    "    model = build_model(input_shape)\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "    return model\n",
    "\n",
    "# Step 5: Evaluation\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = MeanSquaredError()\n",
    "    mse.update_state(y_test, y_pred)\n",
    "    mse_result = mse.result().numpy()\n",
    "    psnr_result = peak_signal_noise_ratio(y_test, y_pred)\n",
    "    ssim_result = structural_similarity(y_test, y_pred, multichannel=True)\n",
    "    return {'MSE': mse_result, 'PSNR': psnr_result, 'SSIM': ssim_result}\n",
    "\n",
    "# Step 6: Deployment (Not Included)\n",
    "\n",
    "# Load data\n",
    "noisy_images, original_images = load_data()\n",
    "\n",
    "# Preprocess all images\n",
    "noisy_images = np.array([preprocess_image(image) for image in noisy_images])\n",
    "original_images = np.array([preprocess_image(image) for image in original_images])\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, original_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = train_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Evaluate the model\n",
    "metrics = evaluate_model(model, X_test, y_test)\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(metrics)\n",
    "\n",
    "# Deployment: This part depends on your specific requirements and could involve creating a user interface or integrating the model into an existing application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image: 1\n",
      "Error loading image: 2\n",
      "Error loading image: 3\n",
      "Error loading image: 4\n",
      "Error loading image: 5\n",
      "Error loading image: 6\n",
      "Error loading image: 7\n",
      "Error loading image: 8\n",
      "Error loading image: 9\n",
      "Error loading image: 10\n",
      "Error loading image: 11\n",
      "Error loading image: 12\n",
      "Error loading image: 13\n",
      "Error loading image: 14\n",
      "Error loading image: 15\n",
      "Error loading image: 16\n",
      "Error loading image: 17\n",
      "Error loading image: 18\n",
      "Error loading image: 19\n",
      "Error loading image: 20\n",
      "Error loading image: 21\n",
      "Error loading image: 22\n",
      "Error loading image: 23\n",
      "Error loading image: 24\n",
      "Error loading image: 25\n",
      "Error loading image: 26\n",
      "Error loading image: 27\n",
      "Error loading image: 28\n",
      "Error loading image: 29\n",
      "Error loading image: 30\n",
      "Error loading image: 31\n",
      "Error loading image: 32\n",
      "Error loading image: 33\n",
      "Error loading image: 34\n",
      "Error loading image: 35\n",
      "Error loading image: 36\n",
      "Error loading image: 37\n",
      "Error loading image: 38\n",
      "Error loading image: 39\n",
      "Error loading image: 40\n",
      "Error loading image: 41\n",
      "Error loading image: 42\n",
      "Error loading image: 43\n",
      "Error loading image: 44\n",
      "Error loading image: 45\n",
      "Error loading image: 46\n",
      "Error loading image: 47\n",
      "Error loading image: 48\n",
      "Error loading image: 49\n",
      "Error loading image: 50\n",
      "Error loading image: 51\n",
      "Error loading image: 52\n",
      "Error loading image: 53\n",
      "Error loading image: 54\n",
      "Error loading image: 55\n",
      "Error loading image: 56\n",
      "Error loading image: 57\n",
      "Error loading image: 58\n",
      "Error loading image: 59\n",
      "Error loading image: 60\n",
      "Error loading image: 61\n",
      "Error loading image: 62\n",
      "Error loading image: 63\n",
      "Error loading image: 64\n",
      "Error loading image: 65\n",
      "Error loading image: 66\n",
      "Error loading image: 67\n",
      "Error loading image: 68\n",
      "Error: No valid images found after preprocessing.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pywt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanSquaredError\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Data Preparation\n",
    "def load_data():\n",
    "    # Load CBSD68 dataset\n",
    "    noisy_images = []\n",
    "    original_images = []\n",
    "    for i in range(1, 69):\n",
    "        noisy_img = cv2.imread(f'CBSD68/noisy/{i}.png', cv2.IMREAD_GRAYSCALE)\n",
    "        orig_img = cv2.imread(f'CBSD68/original/{i}.png', cv2.IMREAD_GRAYSCALE)\n",
    "        if noisy_img is None or orig_img is None:\n",
    "            print(f\"Error loading image: {i}\")\n",
    "            continue\n",
    "        noisy_images.append(noisy_img)\n",
    "        original_images.append(orig_img)\n",
    "    return np.array(noisy_images), np.array(original_images)\n",
    "\n",
    "# Step 2: Preprocessing\n",
    "def preprocess_image(image):\n",
    "    if image is None:\n",
    "        return None\n",
    "    # Resize image to desired dimensions\n",
    "    resized_image = cv2.resize(image, (256, 256))\n",
    "    # Normalize image to range [0, 1]\n",
    "    normalized_image = resized_image / 255.0\n",
    "    # Apply wavelet transform (using Haar wavelet)\n",
    "    coeffs2 = pywt.dwt2(normalized_image, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs2\n",
    "    wavelet_image = np.concatenate((LL, LH, HL, HH), axis=0)\n",
    "    return wavelet_image\n",
    "\n",
    "# Step 3: Model Architecture\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    # Encoder\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    # Decoder\n",
    "    model.add(Conv2D(1, (3, 3), padding='same'))\n",
    "    model.add(Activation('sigmoid'))  # Ensure output values are between 0 and 1\n",
    "    return model\n",
    "\n",
    "# Step 4: Training\n",
    "def train_model(X_train, y_train, X_test, y_test):\n",
    "    input_shape = X_train[0].shape\n",
    "    model = build_model(input_shape)\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "    return model\n",
    "\n",
    "# Step 5: Evaluation\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = MeanSquaredError()\n",
    "    mse.update_state(y_test, y_pred)\n",
    "    mse_result = mse.result().numpy()\n",
    "    psnr_result = peak_signal_noise_ratio(y_test, y_pred)\n",
    "    ssim_result = structural_similarity(y_test, y_pred, multichannel=True)\n",
    "    return {'MSE': mse_result, 'PSNR': psnr_result, 'SSIM': ssim_result}\n",
    "\n",
    "# Step 6: Deployment (Not Included)\n",
    "# Load data\n",
    "noisy_images, original_images = load_data()\n",
    "\n",
    "# Preprocess all images\n",
    "preprocessed_noisy_images = [preprocess_image(image) for image in noisy_images]\n",
    "preprocessed_original_images = [preprocess_image(image) for image in original_images]\n",
    "\n",
    "# Filter out None values\n",
    "valid_indices = [i for i, img in enumerate(preprocessed_noisy_images) if img is not None]\n",
    "noisy_images = np.array([preprocessed_noisy_images[i] for i in valid_indices])\n",
    "original_images = np.array([preprocessed_original_images[i] for i in valid_indices])\n",
    "\n",
    "# Check if dataset is empty after filtering\n",
    "if len(noisy_images) == 0:\n",
    "    print(\"Error: No valid images found after preprocessing.\")\n",
    "else:\n",
    "    # Split dataset into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(noisy_images, original_images, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    model = train_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    metrics = evaluate_model(model, X_test, y_test)\n",
    "    print(\"Evaluation Metrics:\")\n",
    "    print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (68,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m clean_images_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCBSD68/original\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m noisy_images \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_images_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m clean_images \u001b[38;5;241m=\u001b[39m load_images(clean_images_path)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Check the number of images loaded\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m, in \u001b[0;36mload_images\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m         images\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (68,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Function to load images from a directory\n",
    "def load_images(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        img = cv2.imread(os.path.join(directory, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs2 = pywt.dwt2(img, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs2\n",
    "    return LL\n",
    "\n",
    "# Dataset paths\n",
    "noisy_images_path = \"CBSD68/noisy50\"\n",
    "clean_images_path = \"CBSD68/original\"\n",
    "\n",
    "# Load the dataset\n",
    "noisy_images = load_images(noisy_images_path)\n",
    "clean_images = load_images(clean_images_path)\n",
    "\n",
    "# Check the number of images loaded\n",
    "print(\"Number of noisy images:\", len(noisy_images))\n",
    "print(\"Number of clean images:\", len(clean_images))\n",
    "\n",
    "# Preprocess the images if necessary (e.g., resize, normalize pixel values)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform wavelet transform on the images\n",
    "X_train_wavelet = [wavelet_transform(img) for img in X_train]\n",
    "X_test_wavelet = [wavelet_transform(img) for img in X_test]\n",
    "\n",
    "# Convert lists to arrays\n",
    "X_train_wavelet = np.array(X_train_wavelet)\n",
    "X_test_wavelet = np.array(X_test_wavelet)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Define the CNN model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(None, None, 3)),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_wavelet, y_train, validation_data=(X_test_wavelet, y_test), epochs=10)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"image_denoising_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of noisy images: 68\n",
      "Number of clean images: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 256, 128, 2)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 256, 128, 2), dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_wavelet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_wavelet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m     70\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_denoising_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    224\u001b[0m             value,\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    226\u001b[0m         }:\n\u001b[1;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 256, 128, 2)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 256, 128, 2), dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "# Function to load and preprocess images from a directory\n",
    "def load_images(directory, target_shape=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        img = cv2.imread(os.path.join(directory, filename))\n",
    "        if img is not None:\n",
    "            # Resize the image to the target shape if necessary\n",
    "            if img.shape[:2] != target_shape:\n",
    "                img = cv2.resize(img, target_shape)\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs2 = pywt.dwt2(img, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs2\n",
    "    return LL\n",
    "\n",
    "# Load the dataset\n",
    "noisy_images_path = \"CBSD68/noisy50\"\n",
    "clean_images_path = \"CBSD68/original\"\n",
    "noisy_images = load_images(noisy_images_path)\n",
    "clean_images = load_images(clean_images_path)\n",
    "\n",
    "# Check the number of images loaded\n",
    "print(\"Number of noisy images:\", len(noisy_images))\n",
    "print(\"Number of clean images:\", len(clean_images))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform wavelet transform on the images\n",
    "X_train_wavelet = [wavelet_transform(img) for img in X_train]\n",
    "X_test_wavelet = [wavelet_transform(img) for img in X_test]\n",
    "\n",
    "# Convert the lists of wavelet-transformed images to arrays\n",
    "X_train_wavelet = np.array(X_train_wavelet)\n",
    "X_test_wavelet = np.array(X_test_wavelet)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_wavelet, y_train, epochs=10, batch_size=16, validation_data=(X_test_wavelet, y_test))\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"image_denoising_model.h5\")\n",
    "\n",
    "# Function to denoise an image\n",
    "def denoise_image(image):\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    noisy_ll_resized = cv2.resize(noisy_ll, (256, 256))\n",
    "    noisy_ll_resized = np.expand_dims(noisy_ll_resized, axis=-1)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll_resized, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Test the denoising function on a sample noisy image\n",
    "noisy_image_path = \"0038.jpg\"\n",
    "noisy_image = cv2.imread(noisy_image_path)\n",
    "denoised_image = denoise_image(noisy_image)\n",
    "\n",
    "# Display or save the denoised image\n",
    "cv2.imshow(\"Denoised Image\", denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of noisy images: 68\n",
      "Number of clean images: 68\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 256, 128, 2, 3), dtype=float32). Expected shape (None, 256, 256, 3), but input has incompatible shape (None, 256, 128, 2, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 256, 128, 2, 3), dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_wavelet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_wavelet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m     69\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_denoising_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\models\\functional.py:280\u001b[0m, in \u001b[0;36mFunctional._adjust_input_rank\u001b[1;34m(self, flat_inputs)\u001b[0m\n\u001b[0;32m    278\u001b[0m             adjusted\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    279\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m     )\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 256, 128, 2, 3), dtype=float32). Expected shape (None, 256, 256, 3), but input has incompatible shape (None, 256, 128, 2, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 256, 128, 2, 3), dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "# Function to load and preprocess images from a directory\n",
    "def load_images(directory, target_shape=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        img = cv2.imread(os.path.join(directory, filename))\n",
    "        if img is not None:\n",
    "            # Resize the image to the target shape if necessary\n",
    "            if img.shape[:2] != target_shape:\n",
    "                img = cv2.resize(img, target_shape)\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs2 = pywt.dwt2(img, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs2\n",
    "    # Concatenate LH, HL, and HH coefficients to create a 3-channel image\n",
    "    return np.stack([LH, HL, HH], axis=-1)\n",
    "\n",
    "# Load the dataset\n",
    "noisy_images_path = \"CBSD68/noisy50\"\n",
    "clean_images_path = \"CBSD68/original\"\n",
    "noisy_images = load_images(noisy_images_path)\n",
    "clean_images = load_images(clean_images_path)\n",
    "\n",
    "# Check the number of images loaded\n",
    "print(\"Number of noisy images:\", len(noisy_images))\n",
    "print(\"Number of clean images:\", len(clean_images))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform wavelet transform on the images\n",
    "X_train_wavelet = [wavelet_transform(img) for img in X_train]\n",
    "X_test_wavelet = [wavelet_transform(img) for img in X_test]\n",
    "\n",
    "# Convert the lists of wavelet-transformed images to arrays\n",
    "X_train_wavelet = np.array(X_train_wavelet)\n",
    "X_test_wavelet = np.array(X_test_wavelet)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_wavelet, y_train, epochs=10, batch_size=16, validation_data=(X_test_wavelet, y_test))\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"image_denoising_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of noisy images: 68\n",
      "Number of clean images: 68\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 256, 256, 2, 3), dtype=float32). Expected shape (None, 256, 256, 3), but input has incompatible shape (None, 256, 256, 2, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 256, 256, 2, 3), dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_wavelet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_wavelet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m     72\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_denoising_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\models\\functional.py:280\u001b[0m, in \u001b[0;36mFunctional._adjust_input_rank\u001b[1;34m(self, flat_inputs)\u001b[0m\n\u001b[0;32m    278\u001b[0m             adjusted\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    279\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m     )\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 256, 256, 2, 3), dtype=float32). Expected shape (None, 256, 256, 3), but input has incompatible shape (None, 256, 256, 2, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 256, 256, 2, 3), dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "# Function to load and preprocess images from a directory\n",
    "def load_images(directory, target_shape=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        img = cv2.imread(os.path.join(directory, filename))\n",
    "        if img is not None:\n",
    "            # Resize the image to the target shape if necessary\n",
    "            if img.shape[:2] != target_shape:\n",
    "                img = cv2.resize(img, target_shape)\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs2 = pywt.dwt2(img, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs2\n",
    "    # Resize LH, HL, and HH to target shape and stack to create a 3-channel image\n",
    "    LH = cv2.resize(LH, (256, 256))\n",
    "    HL = cv2.resize(HL, (256, 256))\n",
    "    HH = cv2.resize(HH, (256, 256))\n",
    "    return np.stack([LH, HL, HH], axis=-1)\n",
    "\n",
    "# Load the dataset\n",
    "noisy_images_path = \"noisy50\"\n",
    "clean_images_path = \"CBSD68/original\"\n",
    "noisy_images = load_images(noisy_images_path)\n",
    "clean_images = load_images(clean_images_path)\n",
    "\n",
    "# Check the number of images loaded\n",
    "print(\"Number of noisy images:\", len(noisy_images))\n",
    "print(\"Number of clean images:\", len(clean_images))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform wavelet transform on the images\n",
    "X_train_wavelet = [wavelet_transform(img) for img in X_train]\n",
    "X_test_wavelet = [wavelet_transform(img) for img in X_test]\n",
    "\n",
    "# Convert the lists of wavelet-transformed images to arrays\n",
    "X_train_wavelet = np.array(X_train_wavelet)\n",
    "X_test_wavelet = np.array(X_test_wavelet)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_wavelet, y_train, epochs=10, batch_size=16, validation_data=(X_test_wavelet, y_test))\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"image_denoising_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of noisy images: 68\n",
      "Number of clean images: 68\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 256, 256, 2, 3), dtype=float32). Expected shape (None, 256, 256, 3), but input has incompatible shape (None, 256, 256, 2, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 256, 256, 2, 3), dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 73\u001b[0m\n\u001b[0;32m     70\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_wavelet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_wavelet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m     76\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_denoising_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\models\\functional.py:280\u001b[0m, in \u001b[0;36mFunctional._adjust_input_rank\u001b[1;34m(self, flat_inputs)\u001b[0m\n\u001b[0;32m    278\u001b[0m             adjusted\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    279\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m     )\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 256, 256, 2, 3), dtype=float32). Expected shape (None, 256, 256, 3), but input has incompatible shape (None, 256, 256, 2, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 256, 256, 2, 3), dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "# Function to load and preprocess images from a directory\n",
    "def load_images(directory, target_shape=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        img = cv2.imread(os.path.join(directory, filename))\n",
    "        if img is not None:\n",
    "            # Resize the image to the target shape if necessary\n",
    "            if img.shape[:2] != target_shape:\n",
    "                img = cv2.resize(img, target_shape)\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs2 = pywt.dwt2(img, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs2\n",
    "    # Resize LH, HL, and HH to target shape\n",
    "    LH_resized = cv2.resize(LH, (256, 256))\n",
    "    HL_resized = cv2.resize(HL, (256, 256))\n",
    "    HH_resized = cv2.resize(HH, (256, 256))\n",
    "    # Stack LH, HL, and HH channels\n",
    "    stacked_channels = np.stack([LH_resized, HL_resized, HH_resized], axis=-1)\n",
    "    return stacked_channels.astype(np.float32)\n",
    "\n",
    "# Load the dataset\n",
    "noisy_images_path = \"CBSD68/noisy50\"\n",
    "clean_images_path = \"CBSD68/original\"\n",
    "\n",
    "\n",
    "noisy_images = load_images(noisy_images_path)\n",
    "clean_images = load_images(clean_images_path)\n",
    "\n",
    "# Check the number of images loaded\n",
    "print(\"Number of noisy images:\", len(noisy_images))\n",
    "print(\"Number of clean images:\", len(clean_images))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform wavelet transform on the images\n",
    "X_train_wavelet = [wavelet_transform(img) for img in X_train]\n",
    "X_test_wavelet = [wavelet_transform(img) for img in X_test]\n",
    "\n",
    "# Convert the lists of wavelet-transformed images to arrays\n",
    "X_train_wavelet = np.array(X_train_wavelet)\n",
    "X_test_wavelet = np.array(X_test_wavelet)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_wavelet, y_train, epochs=10, batch_size=16, validation_data=(X_test_wavelet, y_test))\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"image_denoising_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 15s/step - loss: 0.0586 - mse: 0.0585 - val_loss: 0.0603 - val_mse: 0.0603\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 10s/step - loss: 0.0552 - mse: 0.0545 - val_loss: 0.0607 - val_mse: 0.0607\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12s/step - loss: 0.0557 - mse: 0.0558 - val_loss: 0.0606 - val_mse: 0.0606\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14s/step - loss: 0.0558 - mse: 0.0562 - val_loss: 0.0603 - val_mse: 0.0603\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13s/step - loss: 0.0566 - mse: 0.0577 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 11s/step - loss: 0.0544 - mse: 0.0538 - val_loss: 0.0598 - val_mse: 0.0598\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11s/step - loss: 0.0554 - mse: 0.0557 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 11s/step - loss: 0.0538 - mse: 0.0531 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12s/step - loss: 0.0558 - mse: 0.0567 - val_loss: 0.0594 - val_mse: 0.0594\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 13s/step - loss: 0.0548 - mse: 0.0550 - val_loss: 0.0593 - val_mse: 0.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"image_denoising_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in the native Keras format\n",
    "tf.keras.models.save_model(model, \"image_denoising_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_denoising_model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Function to preprocess the input image\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    177\u001b[0m         filepath,\n\u001b[0;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:155\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    151\u001b[0m training_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(training_config)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Compile model.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43msaving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args_from_training_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m )\n\u001b[0;32m    159\u001b[0m saving_utils\u001b[38;5;241m.\u001b[39mtry_build_compiled_arguments(model)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Set optimizer weights.\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:143\u001b[0m, in \u001b[0;36mcompile_args_from_training_config\u001b[1;34m(training_config, custom_objects)\u001b[0m\n\u001b[0;32m    141\u001b[0m loss_config \u001b[38;5;241m=\u001b[39m training_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43m_deserialize_nested_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Ensure backwards compatibility for losses in legacy H5 files\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m _resolve_compile_arguments_compat(loss, loss_config, losses)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:202\u001b[0m, in \u001b[0;36m_deserialize_nested_config\u001b[1;34m(deserialize_fn, config)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_single_object(config):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    205\u001b[0m         k: _deserialize_nested_config(deserialize_fn, v)\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    207\u001b[0m     }\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\losses\\__init__.py:124\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.losses.deserialize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeserialize\u001b[39m(name, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserializes a serialized loss class/function instance.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m        A Keras `Loss` instance or a loss function.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_OBJECTS_DICT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:570\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module_objects[config], types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m--> 570\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                \u001b[49m\u001b[43mserialize_with_public_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_module_name\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m deserialize_keras_object(\n\u001b[0;32m    577\u001b[0m             serialize_with_public_class(\n\u001b[0;32m    578\u001b[0m                 module_objects[config], inner_config\u001b[38;5;241m=\u001b[39minner_config\n\u001b[0;32m    579\u001b[0m             ),\n\u001b[0;32m    580\u001b[0m             custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    581\u001b[0m         )\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PLAIN_TYPES):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:671\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    670\u001b[0m     fn_name \u001b[38;5;241m=\u001b[39m inner_config\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;66;03m# Below, handling of all classes.\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# First, is it a shared object?\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:805\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 805\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure custom classes are decorated with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.h5\")\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read the image in grayscale\n",
    "    img = cv2.resize(img, target_size)  # Resize the image\n",
    "    img = img.astype('float32') / 255.0  # Normalize pixel values\n",
    "    img = np.expand_dims(img, axis=-1)  # Add a channel dimension\n",
    "    return img\n",
    "\n",
    "# Function to denoise the image using the loaded model\n",
    "def denoise_image(model, input_image):\n",
    "    # Reshape the input image to match model's input shape\n",
    "    input_image = np.expand_dims(input_image, axis=0)\n",
    "    # Predict the denoised image\n",
    "    denoised_image = model.predict(input_image)\n",
    "    # Remove the batch dimension and rescale pixel values to [0, 255]\n",
    "    denoised_image = denoised_image.squeeze() * 255.0\n",
    "    # Convert to uint8\n",
    "    denoised_image = denoised_image.astype(np.uint8)\n",
    "    return denoised_image\n",
    "\n",
    "# Path to the input noisy image\n",
    "noisy_image_path = \"0038.png\"\n",
    "\n",
    "# Preprocess the noisy image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Denoise the image using the model\n",
    "denoised_image = denoise_image(model, input_image)\n",
    "\n",
    "# Display or save the denoised image\n",
    "cv2.imshow(\"Denoised Image\", denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39msquare(y_true \u001b[38;5;241m-\u001b[39m y_pred))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load the trained model with custom metric\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_denoising_model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmse\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Function to preprocess the input image (same as before)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    177\u001b[0m         filepath,\n\u001b[0;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:155\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    151\u001b[0m training_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(training_config)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Compile model.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43msaving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args_from_training_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m )\n\u001b[0;32m    159\u001b[0m saving_utils\u001b[38;5;241m.\u001b[39mtry_build_compiled_arguments(model)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Set optimizer weights.\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:143\u001b[0m, in \u001b[0;36mcompile_args_from_training_config\u001b[1;34m(training_config, custom_objects)\u001b[0m\n\u001b[0;32m    141\u001b[0m loss_config \u001b[38;5;241m=\u001b[39m training_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43m_deserialize_nested_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Ensure backwards compatibility for losses in legacy H5 files\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m _resolve_compile_arguments_compat(loss, loss_config, losses)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:202\u001b[0m, in \u001b[0;36m_deserialize_nested_config\u001b[1;34m(deserialize_fn, config)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_single_object(config):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    205\u001b[0m         k: _deserialize_nested_config(deserialize_fn, v)\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    207\u001b[0m     }\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\losses\\__init__.py:124\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.losses.deserialize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeserialize\u001b[39m(name, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserializes a serialized loss class/function instance.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m        A Keras `Loss` instance or a loss function.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_OBJECTS_DICT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:570\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module_objects[config], types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m--> 570\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                \u001b[49m\u001b[43mserialize_with_public_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_module_name\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m deserialize_keras_object(\n\u001b[0;32m    577\u001b[0m             serialize_with_public_class(\n\u001b[0;32m    578\u001b[0m                 module_objects[config], inner_config\u001b[38;5;241m=\u001b[39minner_config\n\u001b[0;32m    579\u001b[0m             ),\n\u001b[0;32m    580\u001b[0m             custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    581\u001b[0m         )\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PLAIN_TYPES):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:671\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    670\u001b[0m     fn_name \u001b[38;5;241m=\u001b[39m inner_config\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;66;03m# Below, handling of all classes.\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# First, is it a shared object?\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:805\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 805\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure custom classes are decorated with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define custom metric function\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Load the trained model with custom metric\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.h5\", custom_objects={'mse': mse})\n",
    "\n",
    "# Function to preprocess the input image (same as before)\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to denoise the image (same as before)\n",
    "def denoise_image(model, input_image):\n",
    "    input_image = np.expand_dims(input_image, axis=0)\n",
    "    denoised_image = model.predict(input_image)\n",
    "    denoised_image = denoised_image.squeeze() * 255.0\n",
    "    denoised_image = denoised_image.astype(np.uint8)\n",
    "    return denoised_image\n",
    "\n",
    "# Path to the input noisy image\n",
    "noisy_image_path = \"0038.png\"\n",
    "\n",
    "# Preprocess the noisy image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Denoise the image using the model\n",
    "denoised_image = denoise_image(model, input_image)\n",
    "\n",
    "# Display or save the denoised image (same as before)\n",
    "cv2.imshow(\"Denoised Image\", denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39msquare(y_true \u001b[38;5;241m-\u001b[39m y_pred))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load the trained model with custom metric\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_denoising_model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmse\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Function to preprocess the input image (same as before)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    177\u001b[0m         filepath,\n\u001b[0;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:155\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    151\u001b[0m training_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(training_config)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Compile model.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43msaving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args_from_training_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m )\n\u001b[0;32m    159\u001b[0m saving_utils\u001b[38;5;241m.\u001b[39mtry_build_compiled_arguments(model)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Set optimizer weights.\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:143\u001b[0m, in \u001b[0;36mcompile_args_from_training_config\u001b[1;34m(training_config, custom_objects)\u001b[0m\n\u001b[0;32m    141\u001b[0m loss_config \u001b[38;5;241m=\u001b[39m training_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43m_deserialize_nested_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Ensure backwards compatibility for losses in legacy H5 files\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m _resolve_compile_arguments_compat(loss, loss_config, losses)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:202\u001b[0m, in \u001b[0;36m_deserialize_nested_config\u001b[1;34m(deserialize_fn, config)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_single_object(config):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    205\u001b[0m         k: _deserialize_nested_config(deserialize_fn, v)\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    207\u001b[0m     }\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\losses\\__init__.py:124\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.losses.deserialize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeserialize\u001b[39m(name, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserializes a serialized loss class/function instance.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m        A Keras `Loss` instance or a loss function.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_OBJECTS_DICT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:570\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module_objects[config], types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m--> 570\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                \u001b[49m\u001b[43mserialize_with_public_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_module_name\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m deserialize_keras_object(\n\u001b[0;32m    577\u001b[0m             serialize_with_public_class(\n\u001b[0;32m    578\u001b[0m                 module_objects[config], inner_config\u001b[38;5;241m=\u001b[39minner_config\n\u001b[0;32m    579\u001b[0m             ),\n\u001b[0;32m    580\u001b[0m             custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    581\u001b[0m         )\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PLAIN_TYPES):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:671\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    670\u001b[0m     fn_name \u001b[38;5;241m=\u001b[39m inner_config\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;66;03m# Below, handling of all classes.\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# First, is it a shared object?\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:805\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 805\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure custom classes are decorated with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define custom MSE function\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Load the trained model with custom metric\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.h5\", custom_objects={'mse': mse})\n",
    "\n",
    "# Function to preprocess the input image (same as before)\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to denoise the image (same as before)\n",
    "def denoise_image(model, input_image):\n",
    "    input_image = np.expand_dims(input_image, axis=0)\n",
    "    denoised_image = model.predict(input_image)\n",
    "    denoised_image = denoised_image.squeeze() * 255.0\n",
    "    denoised_image = denoised_image.astype(np.uint8)\n",
    "    return denoised_image\n",
    "\n",
    "# Path to the input noisy image\n",
    "noisy_image_path = \"0038.png\"\n",
    "\n",
    "# Preprocess the noisy image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Denoise the image using the model\n",
    "denoised_image = denoise_image(model, input_image)\n",
    "\n",
    "# Display or save the denoised image (same as before)\n",
    "cv2.imshow(\"Denoised Image\", denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12s/step - loss: 0.0578 - mse: 0.0578 - val_loss: 0.0603 - val_mse: 0.0603\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12s/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0627 - val_mse: 0.0627\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12s/step - loss: 0.0568 - mse: 0.0568 - val_loss: 0.0614 - val_mse: 0.0614\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 14s/step - loss: 0.0554 - mse: 0.0554 - val_loss: 0.0603 - val_mse: 0.0603\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 11s/step - loss: 0.0562 - mse: 0.0562 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 11s/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 11s/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12s/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12s/step - loss: 0.0555 - mse: 0.0555 - val_loss: 0.0596 - val_mse: 0.0596\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 11s/step - loss: 0.0543 - mse: 0.0543 - val_loss: 0.0596 - val_mse: 0.0596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define custom mean squared error (MSE) metric\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model with custom MSE metric\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[mse])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"image_denoising_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13s/step - loss: 0.0590 - mse: 0.0590 - val_loss: 0.0605 - val_mse: 0.0605\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12s/step - loss: 0.0561 - mse: 0.0561 - val_loss: 0.0617 - val_mse: 0.0617\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12s/step - loss: 0.0570 - mse: 0.0570 - val_loss: 0.0603 - val_mse: 0.0603\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 13s/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 14s/step - loss: 0.0559 - mse: 0.0559 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13s/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 11s/step - loss: 0.0538 - mse: 0.0538 - val_loss: 0.0603 - val_mse: 0.0603\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13s/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0599 - val_mse: 0.0599\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 11s/step - loss: 0.0550 - mse: 0.0550 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13s/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.0597 - val_mse: 0.0597\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define custom mean squared error (MSE) metric\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model with custom MSE metric\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[mse])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model in the native Keras format\n",
    "model.save(\"image_denoising_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to post-process the predicted image\n",
    "def postprocess_image(img):\n",
    "    img = np.clip(img, 0, 1) * 255\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.keras\", compile=False)\n",
    "\n",
    "# Define the path to the noisy image\n",
    "noisy_image_path = \"0038.png\"\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Use the model to predict the denoised image\n",
    "denoised_image = model.predict(np.expand_dims(input_image, axis=0))[0]\n",
    "\n",
    "# Post-process the predicted image\n",
    "denoised_image = postprocess_image(denoised_image)\n",
    "\n",
    "# Display the original and denoised images\n",
    "original_image = cv2.imread(noisy_image_path)\n",
    "cv2.imshow(\"Original Image\", original_image)\n",
    "cv2.imshow(\"Denoised Image\", denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'builtins', 'class_name': 'function', 'config': 'mse', 'registered_name': 'function'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the trained denoising model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_denoising_model.keras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Function to preprocess the input image\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:176\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    173\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip:\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(filepath)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:155\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[1;32m--> 155\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _VARS_FNAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m all_filenames:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:727\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     compile_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompile_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compile_config:\n\u001b[1;32m--> 727\u001b[0m         \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompile_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    728\u001b[0m         instance\u001b[38;5;241m.\u001b[39mcompiled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py:834\u001b[0m, in \u001b[0;36mTrainer.compile_from_config\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    823\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    824\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`compile()` was not called as part of model loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    825\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbecause the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms `compile()` method is custom. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    831\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 834\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;66;03m# Create optimizer variables.\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:590\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m config \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m config:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m--> 590\u001b[0m         key: \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    593\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    594\u001b[0m     }\n\u001b[0;32m    596\u001b[0m class_name \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    597\u001b[0m inner_config \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:515\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m custom_objects[config]\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 515\u001b[0m         \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m config\n\u001b[0;32m    519\u001b[0m     ]\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_objects \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    522\u001b[0m     inner_config, fn_module_name, has_custom_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:671\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    670\u001b[0m     fn_name \u001b[38;5;241m=\u001b[39m inner_config\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;66;03m# Below, handling of all classes.\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# First, is it a shared object?\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:805\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 805\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure custom classes are decorated with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'builtins', 'class_name': 'function', 'config': 'mse', 'registered_name': 'function'}"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained denoising model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.keras\")\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to denoise the image\n",
    "def denoise_image(image):\n",
    "    denoised_image = model.predict(np.array([image]))\n",
    "    return denoised_image[0]\n",
    "\n",
    "# Function to save the denoised image\n",
    "def save_denoised_image(image, output_path):\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "# Input noisy image path\n",
    "noisy_image_path = \"0038.jpg\"\n",
    "\n",
    "# Preprocess the noisy image\n",
    "noisy_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Denoise the image\n",
    "denoised_image = denoise_image(noisy_image)\n",
    "\n",
    "# Save the denoised image\n",
    "output_path = \"clean_image.jpg\"\n",
    "save_denoised_image(denoised_image, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 17s/step - loss: 0.0608 - mse: 0.0611 - val_loss: 0.0605 - val_mse: 0.0605\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12s/step - loss: 0.0550 - mse: 0.0539 - val_loss: 0.0607 - val_mse: 0.0607\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12s/step - loss: 0.0548 - mse: 0.0543 - val_loss: 0.0609 - val_mse: 0.0609\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13s/step - loss: 0.0548 - mse: 0.0541 - val_loss: 0.0605 - val_mse: 0.0605\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13s/step - loss: 0.0550 - mse: 0.0548 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13s/step - loss: 0.0552 - mse: 0.0554 - val_loss: 0.0599 - val_mse: 0.0599\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12s/step - loss: 0.0564 - mse: 0.0575 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12s/step - loss: 0.0546 - mse: 0.0544 - val_loss: 0.0598 - val_mse: 0.0598\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12s/step - loss: 0.0537 - mse: 0.0530 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13s/step - loss: 0.0544 - mse: 0.0542 - val_loss: 0.0595 - val_mse: 0.0595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training and saving completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"image_denoising_model.h5\")\n",
    "\n",
    "print(\"Model training and saving completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_denoising_model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Function to preprocess the input image\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    177\u001b[0m         filepath,\n\u001b[0;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:155\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    151\u001b[0m training_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(training_config)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Compile model.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43msaving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args_from_training_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m )\n\u001b[0;32m    159\u001b[0m saving_utils\u001b[38;5;241m.\u001b[39mtry_build_compiled_arguments(model)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Set optimizer weights.\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:143\u001b[0m, in \u001b[0;36mcompile_args_from_training_config\u001b[1;34m(training_config, custom_objects)\u001b[0m\n\u001b[0;32m    141\u001b[0m loss_config \u001b[38;5;241m=\u001b[39m training_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43m_deserialize_nested_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Ensure backwards compatibility for losses in legacy H5 files\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m _resolve_compile_arguments_compat(loss, loss_config, losses)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:202\u001b[0m, in \u001b[0;36m_deserialize_nested_config\u001b[1;34m(deserialize_fn, config)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_single_object(config):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    205\u001b[0m         k: _deserialize_nested_config(deserialize_fn, v)\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    207\u001b[0m     }\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\losses\\__init__.py:124\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.losses.deserialize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeserialize\u001b[39m(name, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserializes a serialized loss class/function instance.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m        A Keras `Loss` instance or a loss function.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_OBJECTS_DICT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:570\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module_objects[config], types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m--> 570\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                \u001b[49m\u001b[43mserialize_with_public_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_module_name\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m deserialize_keras_object(\n\u001b[0;32m    577\u001b[0m             serialize_with_public_class(\n\u001b[0;32m    578\u001b[0m                 module_objects[config], inner_config\u001b[38;5;241m=\u001b[39minner_config\n\u001b[0;32m    579\u001b[0m             ),\n\u001b[0;32m    580\u001b[0m             custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    581\u001b[0m         )\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PLAIN_TYPES):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:671\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    670\u001b[0m     fn_name \u001b[38;5;241m=\u001b[39m inner_config\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;66;03m# Below, handling of all classes.\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# First, is it a shared object?\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:805\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 805\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure custom classes are decorated with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.h5\")\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return np.expand_dims(img, axis=0)\n",
    "\n",
    "# Function to denoise the image\n",
    "def denoise_image(image_path, output_path):\n",
    "    # Preprocess the input image\n",
    "    input_image = preprocess_image(image_path)\n",
    "\n",
    "    # Predict the denoised image\n",
    "    denoised_image = model.predict(input_image)\n",
    "\n",
    "    # Rescale pixel values to [0, 255]\n",
    "    denoised_image = (denoised_image[0] * 255).astype(np.uint8)\n",
    "\n",
    "    # Save the denoised image\n",
    "    cv2.imwrite(output_path, denoised_image)\n",
    "\n",
    "# Example usage:\n",
    "noisy_image_path = \"input_noisy_image.jpg\"  # Provide the path to your noisy image\n",
    "output_image_path = \"output_clean_image.jpg\"  # Output path for the denoised image\n",
    "\n",
    "denoise_image(noisy_image_path, output_image_path)\n",
    "print(\"Denoised image saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_denoising_model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Function to preprocess the input image\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    177\u001b[0m         filepath,\n\u001b[0;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:155\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    151\u001b[0m training_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(training_config)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Compile model.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43msaving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args_from_training_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m )\n\u001b[0;32m    159\u001b[0m saving_utils\u001b[38;5;241m.\u001b[39mtry_build_compiled_arguments(model)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Set optimizer weights.\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:143\u001b[0m, in \u001b[0;36mcompile_args_from_training_config\u001b[1;34m(training_config, custom_objects)\u001b[0m\n\u001b[0;32m    141\u001b[0m loss_config \u001b[38;5;241m=\u001b[39m training_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43m_deserialize_nested_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Ensure backwards compatibility for losses in legacy H5 files\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m _resolve_compile_arguments_compat(loss, loss_config, losses)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:202\u001b[0m, in \u001b[0;36m_deserialize_nested_config\u001b[1;34m(deserialize_fn, config)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_single_object(config):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    205\u001b[0m         k: _deserialize_nested_config(deserialize_fn, v)\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    207\u001b[0m     }\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\losses\\__init__.py:124\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.losses.deserialize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeserialize\u001b[39m(name, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserializes a serialized loss class/function instance.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m        A Keras `Loss` instance or a loss function.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_OBJECTS_DICT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:570\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module_objects[config], types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m--> 570\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                \u001b[49m\u001b[43mserialize_with_public_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_module_name\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m deserialize_keras_object(\n\u001b[0;32m    577\u001b[0m             serialize_with_public_class(\n\u001b[0;32m    578\u001b[0m                 module_objects[config], inner_config\u001b[38;5;241m=\u001b[39minner_config\n\u001b[0;32m    579\u001b[0m             ),\n\u001b[0;32m    580\u001b[0m             custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    581\u001b[0m         )\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PLAIN_TYPES):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:671\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    670\u001b[0m     fn_name \u001b[38;5;241m=\u001b[39m inner_config\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;66;03m# Below, handling of all classes.\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# First, is it a shared object?\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:805\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 805\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure custom classes are decorated with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.h5\")\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to denoise the input image and save the denoised image\n",
    "def denoise_image(input_image_path, output_image_path):\n",
    "    # Preprocess the input image\n",
    "    input_image = preprocess_image(input_image_path)\n",
    "    # Denoise the input image using the trained model\n",
    "    denoised_image = model.predict(np.array([input_image]))[0]\n",
    "    # Scale the pixel values back to 0-255 range\n",
    "    denoised_image = (denoised_image * 255).astype(np.uint8)\n",
    "    # Save the denoised image\n",
    "    cv2.imwrite(output_image_path, denoised_image)\n",
    "\n",
    "# Specify the paths for input noisy image and output denoised image\n",
    "input_image_path = \"noisy_image.jpg\"  # Replace with the path to your noisy image\n",
    "output_image_path = \"clean_image.jpg\"  # Path to save the denoised image\n",
    "\n",
    "# Denoise the input image and save the denoised image\n",
    "denoise_image(input_image_path, output_image_path)\n",
    "\n",
    "print(\"Denoising completed and clean image saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39msquare(y_true \u001b[38;5;241m-\u001b[39m y_pred))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load the trained model with custom metric\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_denoising_model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmse\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Function to preprocess the input image\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    177\u001b[0m         filepath,\n\u001b[0;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:155\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    151\u001b[0m training_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(training_config)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Compile model.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43msaving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args_from_training_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m )\n\u001b[0;32m    159\u001b[0m saving_utils\u001b[38;5;241m.\u001b[39mtry_build_compiled_arguments(model)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Set optimizer weights.\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:143\u001b[0m, in \u001b[0;36mcompile_args_from_training_config\u001b[1;34m(training_config, custom_objects)\u001b[0m\n\u001b[0;32m    141\u001b[0m loss_config \u001b[38;5;241m=\u001b[39m training_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43m_deserialize_nested_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Ensure backwards compatibility for losses in legacy H5 files\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m _resolve_compile_arguments_compat(loss, loss_config, losses)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:202\u001b[0m, in \u001b[0;36m_deserialize_nested_config\u001b[1;34m(deserialize_fn, config)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_single_object(config):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    205\u001b[0m         k: _deserialize_nested_config(deserialize_fn, v)\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    207\u001b[0m     }\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\losses\\__init__.py:124\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.losses.deserialize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeserialize\u001b[39m(name, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserializes a serialized loss class/function instance.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m        A Keras `Loss` instance or a loss function.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_OBJECTS_DICT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:570\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module_objects[config], types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m--> 570\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                \u001b[49m\u001b[43mserialize_with_public_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_module_name\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m deserialize_keras_object(\n\u001b[0;32m    577\u001b[0m             serialize_with_public_class(\n\u001b[0;32m    578\u001b[0m                 module_objects[config], inner_config\u001b[38;5;241m=\u001b[39minner_config\n\u001b[0;32m    579\u001b[0m             ),\n\u001b[0;32m    580\u001b[0m             custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    581\u001b[0m         )\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PLAIN_TYPES):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:671\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    670\u001b[0m     fn_name \u001b[38;5;241m=\u001b[39m inner_config\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;66;03m# Below, handling of all classes.\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# First, is it a shared object?\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:805\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 805\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure custom classes are decorated with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define custom metric function\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Load the trained model with custom metric\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.h5\", custom_objects={'mse': mse})\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to denoise the input image and save the denoised image\n",
    "def denoise_image(input_image_path, output_image_path):\n",
    "    # Preprocess the input image\n",
    "    input_image = preprocess_image(input_image_path)\n",
    "    # Denoise the input image using the trained model\n",
    "    denoised_image = model.predict(np.array([input_image]))[0]\n",
    "    # Scale the pixel values back to 0-255 range\n",
    "    denoised_image = (denoised_image * 255).astype(np.uint8)\n",
    "    # Save the denoised image\n",
    "    cv2.imwrite(output_image_path, denoised_image)\n",
    "\n",
    "# Specify the paths for input noisy image and output denoised image\n",
    "input_image_path = \"noisy_image.jpg\"  # Replace with the path to your noisy image\n",
    "output_image_path = \"clean_image.jpg\"  # Path to save the denoised image\n",
    "\n",
    "# Denoise the input image and save the denoised image\n",
    "denoise_image(input_image_path, output_image_path)\n",
    "\n",
    "print(\"Denoising completed and clean image saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 256, 256, 2, 3), dtype=float32). Expected shape (None, 256, 256, 3), but input has incompatible shape (None, 256, 256, 2, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 256, 256, 2, 3), dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_wavelet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_wavelet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m     72\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_denoising_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\models\\functional.py:280\u001b[0m, in \u001b[0;36mFunctional._adjust_input_rank\u001b[1;34m(self, flat_inputs)\u001b[0m\n\u001b[0;32m    278\u001b[0m             adjusted\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    279\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m     )\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 256, 256, 2, 3), dtype=float32). Expected shape (None, 256, 256, 3), but input has incompatible shape (None, 256, 256, 2, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 256, 256, 2, 3), dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "# Function to load and preprocess images from a directory\n",
    "def load_images(directory, target_shape=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        img = cv2.imread(os.path.join(directory, filename))\n",
    "        if img is not None:\n",
    "            # Resize the image to the target shape if necessary\n",
    "            if img.shape[:2] != target_shape:\n",
    "                img = cv2.resize(img, target_shape)\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs2 = pywt.dwt2(img, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs2\n",
    "    # Resize LH, HL, and HH to target shape\n",
    "    LH_resized = cv2.resize(LH, (256, 256))\n",
    "    HL_resized = cv2.resize(HL, (256, 256))\n",
    "    HH_resized = cv2.resize(HH, (256, 256))\n",
    "    # Stack the wavelet coefficients to create a 3-channel image\n",
    "    stacked_channels = np.stack([LH_resized, HL_resized, HH_resized], axis=-1)\n",
    "    return stacked_channels.astype(np.float32)\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "noisy_images_path = \"CBSD68/noisy50\"\n",
    "clean_images_path = \"CBSD68/original\"\n",
    "noisy_images = load_images(noisy_images_path)\n",
    "clean_images = load_images(clean_images_path)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform wavelet transform on the images\n",
    "X_train_wavelet = [wavelet_transform(img) for img in X_train]\n",
    "X_test_wavelet = [wavelet_transform(img) for img in X_test]\n",
    "\n",
    "# Convert the lists of wavelet-transformed images to arrays\n",
    "X_train_wavelet = np.array(X_train_wavelet)\n",
    "X_test_wavelet = np.array(X_test_wavelet)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_wavelet, y_train, epochs=10, batch_size=16, validation_data=(X_test_wavelet, y_test))\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"image_denoising_model.h5\")\n",
    "\n",
    "# Function to denoise a given noisy image and save the resulting clear image\n",
    "def denoise_image(input_image_path, output_image_path):\n",
    "    noisy_img = cv2.imread(input_image_path)\n",
    "    noisy_img_wavelet = wavelet_transform(noisy_img)\n",
    "    denoised_img_wavelet = model.predict(np.array([noisy_img_wavelet]))[0]\n",
    "    denoised_img = np.zeros_like(noisy_img)\n",
    "    for i in range(3):\n",
    "        denoised_img[:, :, i] = cv2.resize(denoised_img_wavelet[:, :, i], (noisy_img.shape[1], noisy_img.shape[0]))\n",
    "    cv2.imwrite(output_image_path, denoised_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "input_image_path = \"noisy_image.jpg\"  # Replace with the path to your noisy image\n",
    "output_image_path = \"clean_image.jpg\"  # Path to save the denoised image\n",
    "denoise_image(input_image_path, output_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to post-process the predicted image\n",
    "def postprocess_image(img):\n",
    "    img = np.clip(img, 0, 1) * 255\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.keras\", compile=False)\n",
    "\n",
    "# Define the path to the noisy image\n",
    "noisy_image_path = \"0038.png\"\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Use the model to predict the denoised image\n",
    "denoised_image = model.predict(np.expand_dims(input_image, axis=0))[0]\n",
    "\n",
    "# Post-process the predicted image\n",
    "denoised_image = postprocess_image(denoised_image)\n",
    "\n",
    "# Display the original and denoised images\n",
    "original_image = cv2.imread(noisy_image_path)\n",
    "cv2.imshow(\"Original Image\", original_image)\n",
    "cv2.imshow(\"Denoised Image\", denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained denoising model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.keras\")\n",
    "\"\"\"# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to denoise the image\n",
    "def denoise_image(image):\n",
    "    denoised_image = model.predict(np.array([image]))\n",
    "    return denoised_image[0]\n",
    "\n",
    "# Function to save the denoised image\n",
    "def save_denoised_image(image, output_path):\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "# Input noisy image path\n",
    "noisy_image_path = \"0038.jpg\"\n",
    "\n",
    "# Preprocess the noisy image\n",
    "noisy_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Denoise the image\n",
    "denoised_image = denoise_image(noisy_image)\n",
    "\n",
    "# Save the denoised image\n",
    "output_path = \"clean_image.jpg\"\n",
    "save_denoised_image(denoised_image, output_path)\n",
    "\n",
    "he code accurate but not show clean image noize removd after (add noize remove concept and image give me clean)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 958ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.keras\", compile=False)\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to post-process the predicted image\n",
    "def postprocess_image(img):\n",
    "    img = np.clip(img, 0, 1) * 255\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Function to display original and denoised images\n",
    "def display_images(original_image, denoised_image):\n",
    "    cv2.imshow(\"Original Image\", original_image)\n",
    "    cv2.imshow(\"Denoised Image\", denoised_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Define the path to the noisy image\n",
    "noisy_image_path = \"0038.png\"\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Use the model to predict the denoised image\n",
    "denoised_image = model.predict(np.expand_dims(input_image, axis=0))[0]\n",
    "\n",
    "# Post-process the predicted image\n",
    "denoised_image = postprocess_image(denoised_image)\n",
    "\n",
    "# Load the original noisy image\n",
    "original_image = cv2.imread(noisy_image_path)\n",
    "\n",
    "# Display the original and denoised images side by side\n",
    "display_images(original_image, denoised_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'builtins', 'class_name': 'function', 'config': 'mse', 'registered_name': 'function'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the trained denoising model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_denoising_model.keras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Save the model with a different filename\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_denoising_model_updated\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:176\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    173\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip:\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(filepath)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:155\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[1;32m--> 155\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _VARS_FNAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m all_filenames:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:727\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     compile_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompile_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compile_config:\n\u001b[1;32m--> 727\u001b[0m         \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompile_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    728\u001b[0m         instance\u001b[38;5;241m.\u001b[39mcompiled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py:834\u001b[0m, in \u001b[0;36mTrainer.compile_from_config\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    823\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    824\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`compile()` was not called as part of model loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    825\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbecause the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms `compile()` method is custom. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    831\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 834\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;66;03m# Create optimizer variables.\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:590\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m config \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m config:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m--> 590\u001b[0m         key: \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    593\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    594\u001b[0m     }\n\u001b[0;32m    596\u001b[0m class_name \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    597\u001b[0m inner_config \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:515\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m custom_objects[config]\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 515\u001b[0m         \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m config\n\u001b[0;32m    519\u001b[0m     ]\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_objects \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    522\u001b[0m     inner_config, fn_module_name, has_custom_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:671\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    670\u001b[0m     fn_name \u001b[38;5;241m=\u001b[39m inner_config\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;66;03m# Below, handling of all classes.\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# First, is it a shared object?\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:805\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 805\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure custom classes are decorated with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'builtins', 'class_name': 'function', 'config': 'mse', 'registered_name': 'function'}"
     ]
    }
   ],
   "source": [
    "# Load the trained denoising model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.keras\")\n",
    "\n",
    "# Save the model with a different filename\n",
    "model.save(\"image_denoising_model_updated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 15s/step - loss: 0.0578 - mse: 0.0576 - val_loss: 0.0609 - val_mse: 0.0609\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12s/step - loss: 0.0559 - mse: 0.0560 - val_loss: 0.0611 - val_mse: 0.0611\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12s/step - loss: 0.0553 - mse: 0.0550 - val_loss: 0.0602 - val_mse: 0.0602\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 11s/step - loss: 0.0552 - mse: 0.0551 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12s/step - loss: 0.0538 - mse: 0.0524 - val_loss: 0.0599 - val_mse: 0.0599\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 13s/step - loss: 0.0542 - mse: 0.0532 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 12s/step - loss: 0.0547 - mse: 0.0546 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 12s/step - loss: 0.0548 - mse: 0.0547 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 14s/step - loss: 0.0545 - mse: 0.0544 - val_loss: 0.0596 - val_mse: 0.0596\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13s/step - loss: 0.0543 - mse: 0.0541 - val_loss: 0.0596 - val_mse: 0.0596\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A total of 1 objects could not be loaded. Example error message for object <keras.src.optimizers.adam.Adam object at 0x000002D35EB62690>:\n\n'Unable to synchronously open object (bad object header chunk size)'\n\nList of objects that could not be loaded:\n[<keras.src.optimizers.adam.Adam object at 0x000002D35EB62690>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_denoising_model.keras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Define the path to the noisy image\u001b[39;00m\n\u001b[0;32m     81\u001b[0m noisy_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0038.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:176\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    173\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip:\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(filepath)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:192\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    189\u001b[0m         asset_store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m failed_trackables:\n\u001b[1;32m--> 192\u001b[0m         \u001b[43m_raise_loading_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror_msgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:273\u001b[0m, in \u001b[0;36m_raise_loading_failure\u001b[1;34m(error_msgs, warn_only)\u001b[0m\n\u001b[0;32m    271\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: A total of 1 objects could not be loaded. Example error message for object <keras.src.optimizers.adam.Adam object at 0x000002D35EB62690>:\n\n'Unable to synchronously open object (bad object header chunk size)'\n\nList of objects that could not be loaded:\n[<keras.src.optimizers.adam.Adam object at 0x000002D35EB62690>]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "\n",
    "\n",
    "\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"image_denoising_model.keras\")\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to post-process the predicted image\n",
    "def postprocess_image(img):\n",
    "    img = np.clip(img, 0, 1) * 255\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.keras\")\n",
    "\n",
    "# Define the path to the noisy image\n",
    "noisy_image_path = \"0038.png\"\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Use the model to predict the denoised image\n",
    "denoised_image = model.predict(np.expand_dims(input_image, axis=0))[0]\n",
    "\n",
    "# Post-process the predicted image\n",
    "denoised_image = postprocess_image(denoised_image)\n",
    "\n",
    "# Save the denoised image\n",
    "cv2.imwrite(\"denoised_image.png\", denoised_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_images_path = \"CBSD68/noisy50\"\n",
    "clean_images_path = \"CBSD68/original\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 14s/step - loss: 0.0578 - mse: 0.0578 - val_loss: 0.0607 - val_mse: 0.0607\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13s/step - loss: 0.0555 - mse: 0.0555 - val_loss: 0.0611 - val_mse: 0.0611\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 12s/step - loss: 0.0559 - mse: 0.0558 - val_loss: 0.0607 - val_mse: 0.0607\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 35s/step - loss: 0.0545 - mse: 0.0540 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13s/step - loss: 0.0550 - mse: 0.0547 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12s/step - loss: 0.0554 - mse: 0.0555 - val_loss: 0.0599 - val_mse: 0.0599\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13s/step - loss: 0.0560 - mse: 0.0566 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13s/step - loss: 0.0550 - mse: 0.0552 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13s/step - loss: 0.0540 - mse: 0.0535 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11s/step - loss: 0.0538 - mse: 0.0529 - val_loss: 0.0601 - val_mse: 0.0601\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A total of 1 objects could not be loaded. Example error message for object <keras.src.optimizers.adam.Adam object at 0x000002D35DBD2450>:\n\n'Unable to synchronously open object (bad object header chunk size)'\n\nList of objects that could not be loaded:\n[<keras.src.optimizers.adam.Adam object at 0x000002D35DBD2450>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_denoising_model.keras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Define the path to the noisy image\u001b[39;00m\n\u001b[0;32m     78\u001b[0m noisy_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0038.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:176\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    173\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip:\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(filepath)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:192\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    189\u001b[0m         asset_store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m failed_trackables:\n\u001b[1;32m--> 192\u001b[0m         \u001b[43m_raise_loading_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror_msgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:273\u001b[0m, in \u001b[0;36m_raise_loading_failure\u001b[1;34m(error_msgs, warn_only)\u001b[0m\n\u001b[0;32m    271\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: A total of 1 objects could not be loaded. Example error message for object <keras.src.optimizers.adam.Adam object at 0x000002D35DBD2450>:\n\n'Unable to synchronously open object (bad object header chunk size)'\n\nList of objects that could not be loaded:\n[<keras.src.optimizers.adam.Adam object at 0x000002D35DBD2450>]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"image_denoising_model.keras\")\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to post-process the predicted image\n",
    "def postprocess_image(img):\n",
    "    img = np.clip(img, 0, 1) * 255\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.keras\")\n",
    "\n",
    "# Define the path to the noisy image\n",
    "noisy_image_path = \"0038.png\"\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Use the model to predict the denoised image\n",
    "denoised_image = model.predict(np.expand_dims(input_image, axis=0))[0]\n",
    "\n",
    "# Post-process the predicted image\n",
    "denoised_image = postprocess_image(denoised_image)\n",
    "\n",
    "# Save the denoised image\n",
    "cv2.imwrite(\"denoised_image.png\", denoised_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 50) (1766718668.py, line 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 50\u001b[1;36m\u001b[0m\n\u001b[1;33m    clean_images = load_data(os.path.join(\"CBSD68\", clean_data_dir))\"\u001b[0m\n\u001b[1;37m                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 50)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dirs = [\"noisy5\", \"noisy10\", \"noisy15\", \"noisy25\", \"noisy35\", \"noisy50\"]\n",
    "clean_data_dir = \"original_png\"\n",
    "\n",
    "noisy_images = np.concatenate([load_data(os.path.join(\"CBSD68\", noisy_dir)) for noisy_dir in noisy_data_dirs])\n",
    "clean_images = load_data(os.path.join(\"CBSD68\", clean_data_dir))\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"image_denoising_model.keras\")\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to post-process the predicted image\n",
    "def postprocess_image(img):\n",
    "    img = np.clip(img, 0, 1) * 255\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.keras\")\n",
    "\n",
    "# Define the path to the noisy image\n",
    "noisy_image_path = \"0038.png\"\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Use the model to predict the denoised image\n",
    "denoised_image = model.predict(np.expand_dims(input_image, axis=0))[0]\n",
    "\n",
    "# Post-process the predicted image\n",
    "denoised_image = postprocess_image(denoised_image)\n",
    "\n",
    "# Save the denoised image\n",
    "cv2.imwrite(\"output_clean_image.png\", denoised_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of noisy images and clean images do not match!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Check if the number of noisy and clean images match\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(noisy_images) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(clean_images):\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of noisy images and clean images do not match!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Apply wavelet transform to noisy images\u001b[39;00m\n\u001b[0;32m     40\u001b[0m noisy_images_wavelet \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([wavelet_transform(img) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m noisy_images])\n",
      "\u001b[1;31mValueError\u001b[0m: Number of noisy images and clean images do not match!"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dirs = [\"noisy5\", \"noisy10\", \"noisy15\", \"noisy25\", \"noisy35\", \"noisy50\"]\n",
    "clean_data_dir = \"original_png\"\n",
    "\n",
    "noisy_images = np.concatenate([load_data(os.path.join(\"CBSD68\", noisy_dir)) for noisy_dir in noisy_data_dirs])\n",
    "clean_images = load_data(os.path.join(\"CBSD68\", clean_data_dir))\n",
    "\n",
    "# Check if the number of noisy and clean images match\n",
    "if len(noisy_images) != len(clean_images):\n",
    "    raise ValueError(\"Number of noisy images and clean images do not match!\")\n",
    "\n",
    "# Apply wavelet transform to noisy images\n",
    "noisy_images_wavelet = np.array([wavelet_transform(img) for img in noisy_images])\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"image_denoising_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to denoise the image\n",
    "def denoise_image(image):\n",
    "    wavelet_image = wavelet_transform(image)\n",
    "    denoised_image = model.predict(np.array([wavelet_image]))\n",
    "    return denoised_image[0]\n",
    "\n",
    "# Function to save the denoised image\n",
    "def save_denoised_image(image, output_path):\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "# Input noisy image path\n",
    "noisy_image_path = \"0038.png\"\n",
    "\n",
    "# Preprocess the noisy image\n",
    "noisy_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Denoise the image\n",
    "denoised_image = denoise_image(noisy_image)\n",
    "\n",
    "# Save the denoised image\n",
    "output_path = \"clean_image.png\"\n",
    "save_denoised_image(denoised_image, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy folder 'noisy5' contains 68 images\n",
      "Noisy folder 'noisy10' contains 68 images\n",
      "Noisy folder 'noisy15' contains 68 images\n",
      "Noisy folder 'noisy25' contains 68 images\n",
      "Noisy folder 'noisy35' contains 68 images\n",
      "Noisy folder 'noisy50' contains 68 images\n",
      "Clean folder contains 68 images\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Function to count the number of images in a directory\n",
    "def count_images(data_dir):\n",
    "    return len([filename for filename in os.listdir(data_dir) if filename.endswith('.png')])\n",
    "\n",
    "# Check the number of images in each noisy folder\n",
    "noisy_data_dirs = [\"noisy5\", \"noisy10\", \"noisy15\", \"noisy25\", \"noisy35\", \"noisy50\"]\n",
    "for noisy_dir in noisy_data_dirs:\n",
    "    noisy_dir_path = os.path.join(\"CBSD68\", noisy_dir)\n",
    "    num_noisy_images = count_images(noisy_dir_path)\n",
    "    print(f\"Noisy folder '{noisy_dir}' contains {num_noisy_images} images\")\n",
    "\n",
    "# Check the number of images in the clean folder\n",
    "clean_dir_path = os.path.join(\"CBSD68\", \"original_png\")\n",
    "num_clean_images = count_images(clean_dir_path)\n",
    "print(f\"Clean folder contains {num_clean_images} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement dwt2 (from versions: none)\n",
      "ERROR: No matching distribution found for dwt2\n"
     ]
    }
   ],
   "source": [
    "pip install dwt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy folder 'noisy5' contains 68 images\n",
      "Noisy folder 'noisy10' contains 68 images\n",
      "Noisy folder 'noisy15' contains 68 images\n",
      "Noisy folder 'noisy25' contains 68 images\n",
      "Noisy folder 'noisy35' contains 68 images\n",
      "Noisy folder 'noisy50' contains 68 images\n",
      "Clean folder contains 68 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load images from a folder\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        img = cv2.imread(os.path.join(folder,filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, (HL, LH, HH) = coeffs\n",
    "    return LL\n",
    "\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    # Resize images to a fixed size\n",
    "    resized_images = [cv2.resize(img, (256, 256)) for img in images]\n",
    "    # Convert to numpy array and normalize\n",
    "    images_array = np.array(resized_images, dtype='float32') / 255.0\n",
    "    return images_array\n",
    "\n",
    "\n",
    "# Path to the dataset folders\n",
    "dataset_path = \"CBSD68\"\n",
    "\n",
    "# Load noisy images from different folders\n",
    "noisy5_images = load_images_from_folder(os.path.join(dataset_path, \"noisy5\"))\n",
    "noisy10_images = load_images_from_folder(os.path.join(dataset_path, \"noisy10\"))\n",
    "noisy15_images = load_images_from_folder(os.path.join(dataset_path, \"noisy15\"))\n",
    "noisy25_images = load_images_from_folder(os.path.join(dataset_path, \"noisy25\"))\n",
    "noisy35_images = load_images_from_folder(os.path.join(dataset_path, \"noisy35\"))\n",
    "noisy50_images = load_images_from_folder(os.path.join(dataset_path, \"noisy50\"))\n",
    "\n",
    "# Load clean images\n",
    "clean_images = load_images_from_folder(os.path.join(dataset_path, \"original_png\"))\n",
    "\n",
    "# Apply wavelet transform to noisy images\n",
    "noisy5_images_wavelet = [wavelet_transform(img) for img in noisy5_images]\n",
    "noisy10_images_wavelet = [wavelet_transform(img) for img in noisy10_images]\n",
    "noisy15_images_wavelet = [wavelet_transform(img) for img in noisy15_images]\n",
    "noisy25_images_wavelet = [wavelet_transform(img) for img in noisy25_images]\n",
    "noisy35_images_wavelet = [wavelet_transform(img) for img in noisy35_images]\n",
    "noisy50_images_wavelet = [wavelet_transform(img) for img in noisy50_images]\n",
    "\n",
    "# Preprocess the data\n",
    "noisy5_images_wavelet = preprocess_data(noisy5_images_wavelet)\n",
    "noisy10_images_wavelet = preprocess_data(noisy10_images_wavelet)\n",
    "noisy15_images_wavelet = preprocess_data(noisy15_images_wavelet)\n",
    "noisy25_images_wavelet = preprocess_data(noisy25_images_wavelet)\n",
    "noisy35_images_wavelet = preprocess_data(noisy35_images_wavelet)\n",
    "noisy50_images_wavelet = preprocess_data(noisy50_images_wavelet)\n",
    "clean_images = preprocess_data(clean_images)\n",
    "\n",
    "# Check the number of images in each folder\n",
    "print(\"Noisy folder 'noisy5' contains\", len(noisy5_images), \"images\")\n",
    "print(\"Noisy folder 'noisy10' contains\", len(noisy10_images), \"images\")\n",
    "print(\"Noisy folder 'noisy15' contains\", len(noisy15_images), \"images\")\n",
    "print(\"Noisy folder 'noisy25' contains\", len(noisy25_images), \"images\")\n",
    "print(\"Noisy folder 'noisy35' contains\", len(noisy35_images), \"images\")\n",
    "print(\"Noisy folder 'noisy50' contains\", len(noisy50_images), \"images\")\n",
    "print(\"Clean folder contains\", len(clean_images), \"images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load images from a folder\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Function to apply wavelet transform to an image\n",
    "# Function to apply wavelet transform to an image\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL = coeffs[0]  # Extract the LL subband\n",
    "    return LL\n",
    "\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(images):\n",
    "    # Resize images to a fixed size\n",
    "    resized_images = [cv2.resize(img, (256, 256)) for img in images]\n",
    "    # Convert to numpy array and normalize\n",
    "    images_array = np.array(resized_images, dtype='float32') / 255.0\n",
    "    return images_array\n",
    "\n",
    "# Define the path to the dataset\n",
    "dataset_path = \"CBSD68\"\n",
    "\n",
    "# Load noisy images from different folders\n",
    "noisy5_images = load_images_from_folder(os.path.join(dataset_path, \"noisy5\"))\n",
    "noisy10_images = load_images_from_folder(os.path.join(dataset_path, \"noisy10\"))\n",
    "noisy15_images = load_images_from_folder(os.path.join(dataset_path, \"noisy15\"))\n",
    "noisy25_images = load_images_from_folder(os.path.join(dataset_path, \"noisy25\"))\n",
    "noisy35_images = load_images_from_folder(os.path.join(dataset_path, \"noisy35\"))\n",
    "noisy50_images = load_images_from_folder(os.path.join(dataset_path, \"noisy50\"))\n",
    "\n",
    "# Load clean images\n",
    "clean_images = load_images_from_folder(os.path.join(dataset_path, \"original_png\"))\n",
    "\n",
    "# Check if the number of noisy and clean images match\n",
    "if len(noisy5_images) != len(clean_images):\n",
    "    raise ValueError(\"Number of noisy images and clean images do not match!\")\n",
    "\n",
    "# Apply wavelet transform to noisy images\n",
    "noisy5_images_wavelet = [wavelet_transform(img) for img in noisy5_images]\n",
    "noisy10_images_wavelet = [wavelet_transform(img) for img in noisy10_images]\n",
    "noisy15_images_wavelet = [wavelet_transform(img) for img in noisy15_images]\n",
    "noisy25_images_wavelet = [wavelet_transform(img) for img in noisy25_images]\n",
    "noisy35_images_wavelet = [wavelet_transform(img) for img in noisy35_images]\n",
    "noisy50_images_wavelet = [wavelet_transform(img) for img in noisy50_images]\n",
    "\n",
    "# Preprocess the data\n",
    "noisy5_images_wavelet = preprocess_data(noisy5_images_wavelet)\n",
    "noisy10_images_wavelet = preprocess_data(noisy10_images_wavelet)\n",
    "noisy15_images_wavelet = preprocess_data(noisy15_images_wavelet)\n",
    "noisy25_images_wavelet = preprocess_data(noisy25_images_wavelet)\n",
    "noisy35_images_wavelet = preprocess_data(noisy35_images_wavelet)\n",
    "noisy50_images_wavelet = preprocess_data(noisy50_images_wavelet)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy5_images_wavelet, clean_images, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(images):\n",
    "    images = np.array(images, dtype='float32') / 255.0\n",
    "    return images\n",
    "\n",
    "# Preprocess the wavelet-transformed images\n",
    "noisy5_images_wavelet = preprocess_data(noisy5_images_wavelet)\n",
    "noisy10_images_wavelet = preprocess_data(noisy10_images_wavelet)\n",
    "noisy15_images_wavelet = preprocess_data(noisy15_images_wavelet)\n",
    "noisy25_images_wavelet = preprocess_data(noisy25_images_wavelet)\n",
    "noisy35_images_wavelet = preprocess_data(noisy35_images_wavelet)\n",
    "noisy50_images_wavelet = preprocess_data(noisy50_images_wavelet)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(noisy5_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "X_train_10, X_test_10, y_train_10, y_test_10 = train_test_split(noisy10_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "X_train_15, X_test_15, y_train_15, y_test_15 = train_test_split(noisy15_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "X_train_25, X_test_25, y_train_25, y_test_25 = train_test_split(noisy25_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "X_train_35, X_test_35, y_train_35, y_test_35 = train_test_split(noisy35_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "X_train_50, X_test_50, y_train_50, y_test_50 = train_test_split(noisy50_images_wavelet, clean_images, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 54\n'y' sizes: 321, 481, 321, 481, 481, 321, 321, 321, 321, 481, 321, 321, 321, 481, 321, 321, 321, 321, 481, 321, 321, 481, 321, 321, 321, 481, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 481, 321, 321, 321, 481, 321, 321, 321, 481, 321, 321, 321, 321\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m model_50\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m history_5 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_5\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_5\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m history_10 \u001b[38;5;241m=\u001b[39m model_10\u001b[38;5;241m.\u001b[39mfit(X_train_10, y_train_10, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test_10, y_test_10))\n\u001b[0;32m     31\u001b[0m history_15 \u001b[38;5;241m=\u001b[39m model_15\u001b[38;5;241m.\u001b[39mfit(X_train_15, y_train_15, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test_15, y_test_15))\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\data_adapter_utils.py:114\u001b[0m, in \u001b[0;36mcheck_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    110\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    113\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 54\n'y' sizes: 321, 481, 321, 481, 481, 321, 321, 321, 321, 481, 321, 321, 321, 481, 321, 321, 321, 321, 481, 321, 321, 481, 321, 321, 321, 481, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 321, 481, 321, 321, 321, 481, 321, 321, 321, 481, 321, 321, 321, 321\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the CNN model architecture\n",
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model_5 = build_model()\n",
    "model_10 = build_model()\n",
    "model_15 = build_model()\n",
    "model_25 = build_model()\n",
    "model_35 = build_model()\n",
    "model_50 = build_model()\n",
    "\n",
    "# Compile the model\n",
    "model_5.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_10.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_15.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_25.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_35.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_50.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "history_5 = model_5.fit(X_train_5, y_train_5, epochs=10, batch_size=16, validation_data=(X_test_5, y_test_5))\n",
    "history_10 = model_10.fit(X_train_10, y_train_10, epochs=10, batch_size=16, validation_data=(X_test_10, y_test_10))\n",
    "history_15 = model_15.fit(X_train_15, y_train_15, epochs=10, batch_size=16, validation_data=(X_test_15, y_test_15))\n",
    "history_25 = model_25.fit(X_train_25, y_train_25, epochs=10, batch_size=16, validation_data=(X_test_25, y_test_25))\n",
    "history_35 = model_35.fit(X_train_35, y_train_35, epochs=10, batch_size=16, validation_data=(X_test_35, y_test_35))\n",
    "history_50 = model_50.fit(X_train_50, y_train_50, epochs=10, batch_size=16, validation_data=(X_test_50, y_test_50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of noisy images and clean images do not match!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Check if the number of noisy and clean images match\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(noisy_images) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(clean_images):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of noisy images and clean images do not match!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Apply wavelet transform to noisy images\u001b[39;00m\n\u001b[0;32m     43\u001b[0m noisy_images_wavelet \u001b[38;5;241m=\u001b[39m [wavelet_transform(img) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m noisy_images]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of noisy images and clean images do not match!"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Function to load images from a folder\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Function to perform wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, (_, _) = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(images):\n",
    "    images = np.array(images, dtype='float32') / 255.0\n",
    "    return images\n",
    "\n",
    "# Load noisy images from different noise levels\n",
    "noisy_folders = [\"noisy5\", \"noisy10\", \"noisy15\", \"noisy25\", \"noisy35\", \"noisy50\"]\n",
    "noisy_images = []\n",
    "for folder in noisy_folders:\n",
    "    noisy_images.extend(load_images_from_folder(os.path.join(\"CBSD68\", folder)))\n",
    "\n",
    "# Load clean images\n",
    "clean_images = load_images_from_folder(os.path.join(\"CBSD68\", \"original_png\"))\n",
    "\n",
    "# Check if the number of noisy and clean images match\n",
    "if len(noisy_images) != len(clean_images):\n",
    "    raise ValueError(\"Number of noisy images and clean images do not match!\")\n",
    "\n",
    "# Apply wavelet transform to noisy images\n",
    "noisy_images_wavelet = [wavelet_transform(img) for img in noisy_images]\n",
    "\n",
    "# Preprocess the data\n",
    "noisy_images_wavelet = preprocess_data(noisy_images_wavelet)\n",
    "clean_images = preprocess_data(clean_images)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(None, None, 1)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load images from a folder\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Function to apply wavelet transform to an image\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL = coeffs[0]  # Extract the LL subband\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(images):\n",
    "    images = np.array(images, dtype='float32') / 255.0\n",
    "    return images\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = \"CBSD68\"\n",
    "\n",
    "# Load noisy images\n",
    "noisy5_images = load_images_from_folder(os.path.join(dataset_path, \"noisy5\"))\n",
    "noisy10_images = load_images_from_folder(os.path.join(dataset_path, \"noisy10\"))\n",
    "noisy15_images = load_images_from_folder(os.path.join(dataset_path, \"noisy15\"))\n",
    "noisy25_images = load_images_from_folder(os.path.join(dataset_path, \"noisy25\"))\n",
    "noisy35_images = load_images_from_folder(os.path.join(dataset_path, \"noisy35\"))\n",
    "noisy50_images = load_images_from_folder(os.path.join(dataset_path, \"noisy50\"))\n",
    "\n",
    "# Load clean images\n",
    "clean_images = load_images_from_folder(os.path.join(dataset_path, \"original_png\"))\n",
    "\n",
    "# Check if the number of noisy and clean images match for each noise level folder\n",
    "if len(noisy5_images) != len(clean_images):\n",
    "    raise ValueError(\"Number of noisy images and clean images do not match for noisy5 folder!\")\n",
    "elif len(noisy10_images) != len(clean_images):\n",
    "    raise ValueError(\"Number of noisy images and clean images do not match for noisy10 folder!\")\n",
    "elif len(noisy15_images) != len(clean_images):\n",
    "    raise ValueError(\"Number of noisy images and clean images do not match for noisy15 folder!\")\n",
    "elif len(noisy25_images) != len(clean_images):\n",
    "    raise ValueError(\"Number of noisy images and clean images do not match for noisy25 folder!\")\n",
    "elif len(noisy35_images) != len(clean_images):\n",
    "    raise ValueError(\"Number of noisy images and clean images do not match for noisy35 folder!\")\n",
    "elif len(noisy50_images) != len(clean_images):\n",
    "    raise ValueError(\"Number of noisy images and clean images do not match for noisy50 folder!\")\n",
    "\n",
    "# Apply wavelet transform to noisy images\n",
    "noisy5_images_wavelet = [wavelet_transform(img) for img in noisy5_images]\n",
    "noisy10_images_wavelet = [wavelet_transform(img) for img in noisy10_images]\n",
    "noisy15_images_wavelet = [wavelet_transform(img) for img in noisy15_images]\n",
    "noisy25_images_wavelet = [wavelet_transform(img) for img in noisy25_images]\n",
    "noisy35_images_wavelet = [wavelet_transform(img) for img in noisy35_images]\n",
    "noisy50_images_wavelet = [wavelet_transform(img) for img in noisy50_images]\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(noisy5_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "X_train_10, X_test_10, y_train_10, y_test_10 = train_test_split(noisy10_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "X_train_15, X_test_15, y_train_15, y_test_15 = train_test_split(noisy15_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "X_train_25, X_test_25, y_train_25, y_test_25 = train_test_split(noisy25_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "X_train_35, X_test_35, y_train_35, y_test_35 = train_test_split(noisy35_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "X_train_50, X_test_50, y_train_50, y_test_50 = train_test_split(noisy50_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_5: [array([[ 99. ,  99.5, 106.5, ...,  83.5,  81. ,  88. ],\n",
      "       [ 95. , 102. , 107. , ..., 111.5, 100.5, 108. ],\n",
      "       [101. , 101. , 106. , ..., 165. , 159. , 153. ],\n",
      "       ...,\n",
      "       [158. , 182.5, 190.5, ..., 291. , 292.5, 299. ],\n",
      "       [168. , 193.5, 198. , ..., 294. , 284.5, 278. ],\n",
      "       [173. , 181. , 201. , ..., 318. , 290. , 262. ]]), array([[343.5, 348. , 355. , ..., 221.5, 168. , 119. ],\n",
      "       [348. , 349.5, 356.5, ..., 166.5, 132.5, 105. ],\n",
      "       [351. , 354.5, 357.5, ..., 141.5, 116.5, 125. ],\n",
      "       ...,\n",
      "       [305. , 320.5, 332.5, ..., 326.5, 321.5, 324. ],\n",
      "       [318. , 333. , 319.5, ..., 330.5, 311.5, 310. ],\n",
      "       [336. , 330. , 329. , ..., 346. , 309. , 308. ]]), array([[207.5, 205. , 191. , ..., 288.5, 283.5, 293. ],\n",
      "       [208. , 194.5, 170. , ..., 283. , 253. , 228. ],\n",
      "       [178.5, 172.5, 146. , ..., 233.5, 183.5, 201. ],\n",
      "       ...,\n",
      "       [245.5, 245. , 236. , ..., 112. , 117.5, 102. ],\n",
      "       [235. , 213.5, 152.5, ...,  94.5,  92.5,  84. ],\n",
      "       [179. , 190. , 165. , ...,  83. , 104. ,  90. ]]), array([[108. ,  75. ,  93. , ...,  66.5,  87. , 104. ],\n",
      "       [ 83. ,  89.5,  80.5, ...,  84. ,  86. ,  97. ],\n",
      "       [ 91.5,  94.5,  90.5, ..., 380.5, 147. ,  82. ],\n",
      "       ...,\n",
      "       [153.5, 186. , 172.5, ..., 178.5, 195. , 158. ],\n",
      "       [205.5, 197. , 171.5, ..., 163. , 131. , 160. ],\n",
      "       [184. , 138. , 176. , ..., 136. , 129. ,  94. ]]), array([[ 76.5, 112. , 131. , ..., 179.5, 179.5, 125. ],\n",
      "       [ 94. , 113.5, 138. , ..., 183. , 156. , 128. ],\n",
      "       [102.5, 119. , 140.5, ..., 188. , 136. , 140. ],\n",
      "       ...,\n",
      "       [186. , 185.5, 186. , ..., 461.5, 459. , 461. ],\n",
      "       [183. , 183.5, 178. , ..., 455.5, 460. , 463. ],\n",
      "       [166. , 171. , 175. , ..., 453. , 461. , 468. ]])]\n",
      "y_train_5: [array([[ 47,  48,  49, ...,  41,  41,  40],\n",
      "       [ 47,  48,  50, ...,  42,  40,  41],\n",
      "       [ 47,  49,  51, ...,  39,  38,  39],\n",
      "       ...,\n",
      "       [ 83,  85,  92, ..., 144, 140, 147],\n",
      "       [ 87,  89,  95, ..., 142, 137, 132],\n",
      "       [ 94,  82,  87, ..., 151, 144, 133]], dtype=uint8), array([[176, 174, 175, ...,  95,  82,  62],\n",
      "       [175, 173, 175, ...,  94,  74,  55],\n",
      "       [173, 172, 173, ...,  79,  63,  54],\n",
      "       ...,\n",
      "       [149, 157, 165, ..., 164, 155, 160],\n",
      "       [163, 164, 172, ..., 161, 154, 151],\n",
      "       [170, 165, 164, ..., 167, 150, 152]], dtype=uint8), array([[ 92, 106, 108, ..., 137, 148, 151],\n",
      "       [106, 114, 112, ..., 141, 145, 142],\n",
      "       [106, 109, 105, ..., 143, 132, 126],\n",
      "       ...,\n",
      "       [116, 114, 112, ...,  49,  48,  44],\n",
      "       [118, 113, 104, ...,  42,  50,  44],\n",
      "       [ 89,  90,  90, ...,  48,  55,  45]], dtype=uint8), array([[ 62,  55,  35, ...,  51,  58,  54],\n",
      "       [ 54,  37,  34, ...,  36,  43,  49],\n",
      "       [ 42,  40,  46, ...,  43,  43,  48],\n",
      "       ...,\n",
      "       [100, 114, 115, ...,  88,  72,  78],\n",
      "       [112,  90,  80, ...,  42,  57,  84],\n",
      "       [ 95,  90,  70, ...,  69,  61,  52]], dtype=uint8), array([[ 35,  38,  49, ...,  92,  88,  70],\n",
      "       [ 40,  45,  51, ...,  94,  80,  67],\n",
      "       [ 43,  48,  54, ...,  91,  69,  67],\n",
      "       ...,\n",
      "       [ 95,  93,  91, ..., 233, 231, 233],\n",
      "       [ 93,  91,  90, ..., 232, 234, 235],\n",
      "       [ 77,  86,  90, ..., 230, 233, 234]], dtype=uint8)]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_5:\", X_train_5[:5])\n",
    "print(\"y_train_5:\", y_train_5[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape arrays in X_train_5\n",
    "X_train_5 = [img.reshape((img.shape[0], img.shape[1], 1)) for img in X_train_5]\n",
    "\n",
    "# Convert data type of arrays in y_train_5\n",
    "y_train_5 = [img.astype('float32') / 255.0 for img in y_train_5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_5 shapes:\n",
      "(161, 241, 1)\n",
      "(241, 161, 1)\n",
      "(161, 241, 1)\n",
      "(241, 161, 1)\n",
      "(241, 161, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(241, 161, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(241, 161, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(241, 161, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(241, 161, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(241, 161, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(241, 161, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(241, 161, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(241, 161, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "(161, 241, 1)\n",
      "\n",
      "y_train_5 shapes:\n",
      "(321, 481)\n",
      "float32\n",
      "(481, 321)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(481, 321)\n",
      "float32\n",
      "(481, 321)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(481, 321)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(481, 321)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(481, 321)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(481, 321)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(481, 321)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(481, 321)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(481, 321)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(481, 321)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n",
      "(321, 481)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "# Reshape arrays in X_train_5\n",
    "X_train_5 = [img.reshape((img.shape[0], img.shape[1], 1)) for img in X_train_5]\n",
    "\n",
    "# Convert data type of arrays in y_train_5\n",
    "y_train_5 = [img.astype('float32') / 255.0 for img in y_train_5]\n",
    "\n",
    "# Check shapes and data types\n",
    "print(\"X_train_5 shapes:\")\n",
    "for img in X_train_5:\n",
    "    print(img.shape)\n",
    "\n",
    "print(\"\\ny_train_5 shapes:\")\n",
    "for img in y_train_5:\n",
    "    print(img.shape)\n",
    "    print(img.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (54,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m model_50\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Train the models\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m history_5 \u001b[38;5;241m=\u001b[39m model_5\u001b[38;5;241m.\u001b[39mfit(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_5\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39marray(y_train_5), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(X_test_5), np\u001b[38;5;241m.\u001b[39marray(y_test_5)))\n\u001b[0;32m     11\u001b[0m history_10 \u001b[38;5;241m=\u001b[39m model_10\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39marray(X_train_10), np\u001b[38;5;241m.\u001b[39marray(y_train_10), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(X_test_10), np\u001b[38;5;241m.\u001b[39marray(y_test_10)))\n\u001b[0;32m     12\u001b[0m history_15 \u001b[38;5;241m=\u001b[39m model_15\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39marray(X_train_15), np\u001b[38;5;241m.\u001b[39marray(y_train_15), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(X_test_15), np\u001b[38;5;241m.\u001b[39marray(y_test_15)))\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (54,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Compile the models\n",
    "model_5.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_10.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_15.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_25.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_35.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_50.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the models\n",
    "history_5 = model_5.fit(np.array(X_train_5), np.array(y_train_5), epochs=10, batch_size=16, validation_data=(np.array(X_test_5), np.array(y_test_5)))\n",
    "history_10 = model_10.fit(np.array(X_train_10), np.array(y_train_10), epochs=10, batch_size=16, validation_data=(np.array(X_test_10), np.array(y_test_10)))\n",
    "history_15 = model_15.fit(np.array(X_train_15), np.array(y_train_15), epochs=10, batch_size=16, validation_data=(np.array(X_test_15), np.array(y_test_15)))\n",
    "history_25 = model_25.fit(np.array(X_train_25), np.array(y_train_25), epochs=10, batch_size=16, validation_data=(np.array(X_test_25), np.array(y_test_25)))\n",
    "history_35 = model_35.fit(np.array(X_train_35), np.array(y_train_35), epochs=10, batch_size=16, validation_data=(np.array(X_test_35), np.array(y_test_35)))\n",
    "history_50 = model_50.fit(np.array(X_train_50), np.array(y_train_50), epochs=10, batch_size=16, validation_data=(np.array(X_test_50), np.array(y_test_50)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (54,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m model_50\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Train the models\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m history_5 \u001b[38;5;241m=\u001b[39m model_5\u001b[38;5;241m.\u001b[39mfit(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_5\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39marray(y_train_5), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(X_test_5), np\u001b[38;5;241m.\u001b[39marray(y_test_5)))\n\u001b[0;32m     33\u001b[0m history_10 \u001b[38;5;241m=\u001b[39m model_10\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39marray(X_train_10), np\u001b[38;5;241m.\u001b[39marray(y_train_10), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(X_test_10), np\u001b[38;5;241m.\u001b[39marray(y_test_10)))\n\u001b[0;32m     34\u001b[0m history_15 \u001b[38;5;241m=\u001b[39m model_15\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39marray(X_train_15), np\u001b[38;5;241m.\u001b[39marray(y_train_15), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(X_test_15), np\u001b[38;5;241m.\u001b[39marray(y_test_15)))\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (54,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the CNN model architecture\n",
    "def create_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "    return model\n",
    "\n",
    "# Compile the models\n",
    "model_5 = create_model(input_shape=(X_train_5[0].shape[0], X_train_5[0].shape[1], 1))\n",
    "model_5.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "model_10 = create_model(input_shape=(X_train_10[0].shape[0], X_train_10[0].shape[1], 1))\n",
    "model_10.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "model_15 = create_model(input_shape=(X_train_15[0].shape[0], X_train_15[0].shape[1], 1))\n",
    "model_15.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "model_25 = create_model(input_shape=(X_train_25[0].shape[0], X_train_25[0].shape[1], 1))\n",
    "model_25.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "model_35 = create_model(input_shape=(X_train_35[0].shape[0], X_train_35[0].shape[1], 1))\n",
    "model_35.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "model_50 = create_model(input_shape=(X_train_50[0].shape[0], X_train_50[0].shape[1], 1))\n",
    "model_50.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the models\n",
    "history_5 = model_5.fit(np.array(X_train_5), np.array(y_train_5), epochs=10, batch_size=16, validation_data=(np.array(X_test_5), np.array(y_test_5)))\n",
    "history_10 = model_10.fit(np.array(X_train_10), np.array(y_train_10), epochs=10, batch_size=16, validation_data=(np.array(X_test_10), np.array(y_test_10)))\n",
    "history_15 = model_15.fit(np.array(X_train_15), np.array(y_train_15), epochs=10, batch_size=16, validation_data=(np.array(X_test_15), np.array(y_test_15)))\n",
    "history_25 = model_25.fit(np.array(X_train_25), np.array(y_train_25), epochs=10, batch_size=16, validation_data=(np.array(X_test_25), np.array(y_test_25)))\n",
    "history_35 = model_35.fit(np.array(X_train_35), np.array(y_train_35), epochs=10, batch_size=16, validation_data=(np.array(X_test_35), np.array(y_test_35)))\n",
    "history_50 = model_50.fit(np.array(X_train_50), np.array(y_train_50), epochs=10, batch_size=16, validation_data=(np.array(X_test_50), np.array(y_test_50)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of noisy images and clean images do not match!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Apply wavelet transform to noisy images\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m noisy5_images_wavelet \u001b[38;5;241m=\u001b[39m [\u001b[43mwavelet_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m noisy5_images]\n\u001b[0;32m     44\u001b[0m noisy10_images_wavelet \u001b[38;5;241m=\u001b[39m [wavelet_transform(img) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m noisy10_images]\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Preprocess the data\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 24\u001b[0m, in \u001b[0;36mwavelet_transform\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwavelet_transform\u001b[39m(img):\n\u001b[0;32m     23\u001b[0m     coeffs \u001b[38;5;241m=\u001b[39m pywt\u001b[38;5;241m.\u001b[39mdwt2(img, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhaar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m     LL, (_, _) \u001b[38;5;241m=\u001b[39m coeffs\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LL\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the path to the dataset\n",
    "dataset_path = \"CBSD68\"\n",
    "\n",
    "# Function to load images from a folder\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Function to apply wavelet transform to an image\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, (_, _) = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess data\n",
    "def preprocess_data(images):\n",
    "    images = np.array(images, dtype='float32') / 255.0\n",
    "    return images\n",
    "\n",
    "# Load noisy images from folders\n",
    "noisy5_images = load_images_from_folder(os.path.join(dataset_path, \"noisy5\"))\n",
    "noisy10_images = load_images_from_folder(os.path.join(dataset_path, \"noisy10\"))\n",
    "# Load clean images from folder\n",
    "clean_images = load_images_from_folder(os.path.join(dataset_path, \"original_png\"))\n",
    "\n",
    "# Check if the number of noisy and clean images match\n",
    "if len(noisy5_images) != len(clean_images):\n",
    "    raise ValueError(\"Number of noisy images and clean images do not match!\")\n",
    "\n",
    "# Apply wavelet transform to noisy images\n",
    "noisy5_images_wavelet = [wavelet_transform(img) for img in noisy5_images]\n",
    "noisy10_images_wavelet = [wavelet_transform(img) for img in noisy10_images]\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(noisy5_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "X_train_10, X_test_10, y_train_10, y_test_10 = train_test_split(noisy10_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_5 = preprocess_data(X_train_5)\n",
    "X_test_5 = preprocess_data(X_test_5)\n",
    "y_train_5 = preprocess_data(y_train_5)\n",
    "y_test_5 = preprocess_data(y_test_5)\n",
    "\n",
    "X_train_10 = preprocess_data(X_train_10)\n",
    "X_test_10 = preprocess_data(X_test_10)\n",
    "y_train_10 = preprocess_data(y_train_10)\n",
    "y_test_10 = preprocess_data(y_test_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - loss: 0.0618 - mse: 0.0598 - val_loss: 0.0552 - val_mse: 0.0552\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0608 - mse: 0.0612 - val_loss: 0.0546 - val_mse: 0.0546\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.0620 - mse: 0.0622 - val_loss: 0.0531 - val_mse: 0.0531\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.0604 - mse: 0.0610 - val_loss: 0.0526 - val_mse: 0.0526\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.0548 - mse: 0.0548 - val_loss: 0.0521 - val_mse: 0.0521\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0527 - val_mse: 0.0527\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.0587 - mse: 0.0580 - val_loss: 0.0559 - val_mse: 0.0559\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0563 - mse: 0.0547 - val_loss: 0.0509 - val_mse: 0.0509\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - loss: 0.0532 - mse: 0.0536 - val_loss: 0.0524 - val_mse: 0.0524\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.0543 - mse: 0.0545 - val_loss: 0.0463 - val_mse: 0.0463\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - loss: 0.0615 - mse: 0.0609 - val_loss: 0.0552 - val_mse: 0.0552\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - loss: 0.0588 - mse: 0.0599 - val_loss: 0.0542 - val_mse: 0.0542\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - loss: 0.0588 - mse: 0.0583 - val_loss: 0.0558 - val_mse: 0.0558\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - loss: 0.0520 - mse: 0.0501 - val_loss: 0.0500 - val_mse: 0.0500\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - loss: 0.0548 - mse: 0.0555 - val_loss: 0.0491 - val_mse: 0.0491\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - loss: 0.0502 - mse: 0.0494 - val_loss: 0.0496 - val_mse: 0.0496\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - loss: 0.0462 - mse: 0.0461 - val_loss: 0.0465 - val_mse: 0.0465\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - loss: 0.0426 - mse: 0.0423 - val_loss: 0.0423 - val_mse: 0.0423\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - loss: 0.0417 - mse: 0.0415 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - loss: 0.0396 - mse: 0.0395 - val_loss: 0.0391 - val_mse: 0.0391\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Function to load images from a folder\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        img = cv2.imread(os.path.join(folder_path,filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Function to apply wavelet transform to an image\n",
    "# Function to apply wavelet transform to an image\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL = coeffs[0]  # Select the approximation coefficients (LL) only\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(images, desired_width, desired_height):\n",
    "    resized_images = [cv2.resize(img, (desired_width, desired_height)) for img in images]\n",
    "    processed_images = np.array([img.reshape(img.shape[0], img.shape[1], 1) for img in resized_images], dtype='float32') / 255.0\n",
    "    return processed_images\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy5_images = load_images_from_folder(\"CBSD68/noisy5\")\n",
    "noisy10_images = load_images_from_folder(\"CBSD68/noisy10\")\n",
    "clean_images = load_images_from_folder(\"CBSD68/original_png\")\n",
    "\n",
    "# Check if the number of noisy and clean images match\n",
    "if len(noisy5_images) != len(clean_images):\n",
    "    raise ValueError(\"Number of noisy images and clean images do not match!\")\n",
    "\n",
    "# Apply wavelet transform to noisy images\n",
    "noisy5_images_wavelet = [wavelet_transform(img) for img in noisy5_images]\n",
    "noisy10_images_wavelet = [wavelet_transform(img) for img in noisy10_images]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(noisy5_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "X_train_10, X_test_10, y_train_10, y_test_10 = train_test_split(noisy10_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "desired_width = 256\n",
    "desired_height = 256\n",
    "X_train_5 = preprocess_data(X_train_5, desired_width, desired_height)\n",
    "X_test_5 = preprocess_data(X_test_5, desired_width, desired_height)\n",
    "y_train_5 = preprocess_data(y_train_5, desired_width, desired_height)\n",
    "y_test_5 = preprocess_data(y_test_5, desired_width, desired_height)\n",
    "X_train_10 = preprocess_data(X_train_10, desired_width, desired_height)\n",
    "X_test_10 = preprocess_data(X_test_10, desired_width, desired_height)\n",
    "y_train_10 = preprocess_data(y_train_10, desired_width, desired_height)\n",
    "y_test_10 = preprocess_data(y_test_10, desired_width, desired_height)\n",
    "\n",
    "# Define the CNN model\n",
    "def create_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(desired_width, desired_height, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(desired_width * desired_height, activation='sigmoid'))\n",
    "    model.add(layers.Reshape((desired_width, desired_height, 1)))\n",
    "    return model\n",
    "\n",
    "# Create models\n",
    "model_5 = create_model()\n",
    "model_10 = create_model()\n",
    "\n",
    "# Compile models\n",
    "model_5.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_10.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the models\n",
    "history_5 = model_5.fit(X_train_5, y_train_5, epochs=10, batch_size=16, validation_data=(X_test_5, y_test_5))\n",
    "history_10 = model_10.fit(X_train_10, y_train_10, epochs=10, batch_size=16, validation_data=(X_test_10, y_test_10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_dataset(dataset_path):\n",
    "    noisy_images = []\n",
    "    clean_images = []\n",
    "    folders = [\"noisy5\", \"noisy10\", \"noisy15\", \"noisy25\", \"noisy35\", \"noisy50\", \"original_png\"]\n",
    "    for folder in folders:\n",
    "        images_path = os.path.join(dataset_path, folder)\n",
    "        images = [cv2.imread(os.path.join(images_path, filename), cv2.IMREAD_GRAYSCALE) for filename in sorted(os.listdir(images_path))]\n",
    "        if \"noisy\" in folder:\n",
    "            noisy_images.extend(images)\n",
    "        elif \"original\" in folder:\n",
    "            clean_images.extend(images)\n",
    "    return noisy_images, clean_images\n",
    "\n",
    "# Reload the dataset\n",
    "noisy_images, clean_images = load_dataset(\"CBSD68\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 161, 161, 161, 241, 161, 241, 161, 161, 161, 161, 161, 241, 241, 161\n'y' sizes: 321, 321, 321, 481, 321, 481, 321, 321, 321, 321, 321, 481, 481, 321\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the models\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m loss_5, mse_5 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_5\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m loss_10, mse_10 \u001b[38;5;241m=\u001b[39m model_10\u001b[38;5;241m.\u001b[39mevaluate(X_test_10, y_test_10)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel with noise level 5 evaluation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\data_adapter_utils.py:114\u001b[0m, in \u001b[0;36mcheck_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    110\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    113\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 161, 161, 161, 241, 161, 241, 161, 161, 161, 161, 161, 241, 241, 161\n'y' sizes: 321, 321, 321, 481, 321, 481, 321, 321, 321, 321, 321, 481, 481, 321\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models\n",
    "loss_5, mse_5 = model_5.evaluate(X_test_5, y_test_5)\n",
    "loss_10, mse_10 = model_10.evaluate(X_test_10, y_test_10)\n",
    "\n",
    "print(\"Model with noise level 5 evaluation:\")\n",
    "print(\"Test Loss:\", loss_5)\n",
    "print(\"Test MSE:\", mse_5)\n",
    "print(\"\\nModel with noise level 10 evaluation:\")\n",
    "print(\"Test Loss:\", loss_10)\n",
    "print(\"Test MSE:\", mse_10)\n",
    "\n",
    "# Function to denoise an input image using the trained model\n",
    "def denoise_image(model, noisy_image):\n",
    "    noisy_image_wavelet = wavelet_transform(noisy_image)\n",
    "    noisy_image_processed = preprocess_data([noisy_image_wavelet], desired_width, desired_height)\n",
    "    denoised_image = model.predict(noisy_image_processed)\n",
    "    return denoised_image.reshape(desired_width, desired_height)\n",
    "\n",
    "# Example of denoising an input image\n",
    "input_image = cv2.imread(\"0038.png\", cv2.IMREAD_GRAYSCALE)\n",
    "denoised_image_5 = denoise_image(model_5, input_image)\n",
    "denoised_image_10 = denoise_image(model_10, input_image)\n",
    "\n",
    "# Save denoised images\n",
    "cv2.imwrite(\"denoised_image_noise_level_5.png\", denoised_image_5 * 255.0)\n",
    "cv2.imwrite(\"denoised_image_noise_level_10.png\", denoised_image_10 * 255.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of noisy images: 408\n",
      "Number of clean images: 68\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [408, 68]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m noisy_images_wavelet \u001b[38;5;241m=\u001b[39m [wavelet_transform(img) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m noisy_images]\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_images_wavelet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Preprocess the data\u001b[39;00m\n\u001b[0;32m     49\u001b[0m X_train \u001b[38;5;241m=\u001b[39m preprocess_data(X_train)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2657\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2661\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2662\u001b[0m )\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 514\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [408, 68]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the function to load the dataset\n",
    "def load_dataset(dataset_path):\n",
    "    noisy_images = []\n",
    "    clean_images = []\n",
    "    folders = [\"noisy5\", \"noisy10\", \"noisy15\", \"noisy25\", \"noisy35\", \"noisy50\", \"original_png\"]\n",
    "    for folder in folders:\n",
    "        images_path = os.path.join(dataset_path, folder)\n",
    "        images = [cv2.imread(os.path.join(images_path, filename), cv2.IMREAD_GRAYSCALE) for filename in sorted(os.listdir(images_path))]\n",
    "        if \"noisy\" in folder:\n",
    "            noisy_images.extend(images)\n",
    "        elif \"original\" in folder:\n",
    "            clean_images.extend(images)\n",
    "    return noisy_images, clean_images\n",
    "print(\"Number of noisy images:\", len(noisy_images))\n",
    "print(\"Number of clean images:\", len(clean_images))\n",
    "\n",
    "# Define the function to apply wavelet transform to images\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL = coeffs[0]  # Select the approximation coefficients (LL) only\n",
    "    return LL\n",
    "\n",
    "# Define the function to preprocess the data\n",
    "def preprocess_data(images):\n",
    "    desired_width = 161\n",
    "    desired_height = 161\n",
    "    resized_images = [cv2.resize(img, (desired_width, desired_height)) for img in images]\n",
    "    processed_images = np.array([img.reshape(img.shape[0], img.shape[1], 1) for img in resized_images], dtype='float32') / 255.0\n",
    "    return processed_images\n",
    "\n",
    "# Load the dataset\n",
    "noisy_images, clean_images = load_dataset(\"CBSD68\")\n",
    "\n",
    "# Apply wavelet transform to noisy images\n",
    "noisy_images_wavelet = [wavelet_transform(img) for img in noisy_images]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_train = preprocess_data(y_train)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the model architecture\n",
    "def create_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(161, 161, 1)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create models for different noise levels\n",
    "model_5 = create_model()\n",
    "model_10 = create_model()\n",
    "model_15 = create_model()\n",
    "model_25 = create_model()\n",
    "model_35 = create_model()\n",
    "model_50 = create_model()\n",
    "\n",
    "# Compile the models\n",
    "model_5.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_10.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_15.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_25.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_35.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_50.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the models\n",
    "history_5 = model_5.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
    "history_10 = model_10.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
    "history_15 = model_15.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
    "history_25 = model_25.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
    "history_35 = model_35.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
    "history_50 = model_50.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the models\n",
    "loss_5, mse_5 = model_5.evaluate(X_test, y_test)\n",
    "loss_10, mse_10 = model_10.evaluate(X_test, y_test)\n",
    "loss_15, mse_15 = model_15.evaluate(X_test, y_test)\n",
    "loss_25, mse_25 = model_25.evaluate(X_test, y_test)\n",
    "loss_35, mse_35 = model_35.evaluate(X_test, y_test)\n",
    "loss_50, mse_50 = model_50.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Model with noise level 5 evaluation:\")\n",
    "print(\"Loss:\", loss_5)\n",
    "print(\"MSE:\", mse_5)\n",
    "print(\"\\nModel with noise level 10 evaluation:\")\n",
    "print(\"Loss:\", loss_10)\n",
    "print(\"MSE:\", mse_10)\n",
    "print(\"\\nModel with noise level 15 evaluation:\")\n",
    "print(\"Loss:\", loss_15)\n",
    "print(\"MSE:\", mse_15)\n",
    "print(\"\\nModel with noise level 25 evaluation:\")\n",
    "print(\"Loss:\", loss_25)\n",
    "print(\"MSE:\", mse_25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(noisy_images, clean_images, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Reshape the input data\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     50\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     51\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, y_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], y_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Function to load and preprocess the dataset\n",
    "def load_dataset(dataset_path):\n",
    "    noisy_images = []\n",
    "    clean_images = []\n",
    "    # Load noisy images\n",
    "    for i in range(1, 69):\n",
    "        noisy_img = cv2.imread(f\"{dataset_path}/noisy50/{i:04d}.png\", cv2.IMREAD_GRAYSCALE)\n",
    "        noisy_images.append(noisy_img)\n",
    "    # Load clean images\n",
    "    for i in range(1, 69):\n",
    "        clean_img = cv2.imread(f\"{dataset_path}/original_png/{i:04d}.png\", cv2.IMREAD_GRAYSCALE)\n",
    "        clean_images.append(clean_img)\n",
    "    return noisy_images, clean_images\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(noisy_images, clean_images):\n",
    "    # Convert lists to numpy arrays\n",
    "    noisy_images = np.array(noisy_images)\n",
    "    clean_images = np.array(clean_images)\n",
    "    # Normalize the pixel values\n",
    "    noisy_images = noisy_images.astype('float32') / 255.0\n",
    "    clean_images = clean_images.astype('float32') / 255.0\n",
    "    return noisy_images, clean_images\n",
    "\n",
    "# Function to build the model\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "dataset_path = \"path/to/your/dataset\"\n",
    "noisy_images, clean_images = load_dataset(dataset_path)\n",
    "noisy_images, clean_images = preprocess_data(noisy_images, clean_images)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data\n",
    "X_train = X_train.reshape(-1, X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(-1, X_test.shape[1], X_test.shape[2], 1)\n",
    "y_train = y_train.reshape(-1, y_train.shape[1], y_train.shape[2], 1)\n",
    "y_test = y_test.reshape(-1, y_test.shape[1], y_test.shape[2], 1)\n",
    "\n",
    "# Build the model\n",
    "model = build_model(input_shape=X_train.shape[1:])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mse = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test MSE:\", mse)\n",
    "\n",
    "# Make predictions\n",
    "# You can use the trained model to denoise new images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (68,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCBSD68\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     45\u001b[0m noisy_images, clean_images \u001b[38;5;241m=\u001b[39m load_dataset(dataset_path)\n\u001b[1;32m---> 46\u001b[0m noisy_images, clean_images \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and testing sets\u001b[39;00m\n\u001b[0;32m     49\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(noisy_images, clean_images, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[1;32mIn[37], line 24\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(noisy_images, clean_images, desired_height, desired_width)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_data\u001b[39m(noisy_images, clean_images, desired_height, desired_width):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Convert lists to numpy arrays\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     noisy_images \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     clean_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(clean_images)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Resize the images\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (68,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Function to load and preprocess the dataset\n",
    "def load_dataset(dataset_path):\n",
    "    noisy_images = []\n",
    "    clean_images = []\n",
    "    # Load noisy images\n",
    "    for i in range(1, 69):\n",
    "        noisy_img = cv2.imread(f\"{dataset_path}/noisy50/{i:04d}.png\", cv2.IMREAD_GRAYSCALE)\n",
    "        noisy_images.append(noisy_img)\n",
    "    # Load clean images\n",
    "    for i in range(1, 69):\n",
    "        clean_img = cv2.imread(f\"{dataset_path}/original_png/{i:04d}.png\", cv2.IMREAD_GRAYSCALE)\n",
    "        clean_images.append(clean_img)\n",
    "    return noisy_images, clean_images\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(noisy_images, clean_images, desired_height, desired_width):\n",
    "    # Convert lists to numpy arrays\n",
    "    noisy_images = np.array(noisy_images)\n",
    "    clean_images = np.array(clean_images)\n",
    "    # Resize the images\n",
    "    noisy_images_resized = [cv2.resize(img, (desired_width, desired_height)) for img in noisy_images]\n",
    "    clean_images_resized = [cv2.resize(img, (desired_width, desired_height)) for img in clean_images]\n",
    "    # Normalize the pixel values\n",
    "    noisy_images_resized = noisy_images_resized.astype('float32') / 255.0\n",
    "    clean_images_resized = clean_images_resized.astype('float32') / 255.0\n",
    "    return noisy_images_resized, clean_images_resized\n",
    "\n",
    "# Function to build the model\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "dataset_path = \"CBSD68\"\n",
    "noisy_images, clean_images = load_dataset(dataset_path)\n",
    "noisy_images, clean_images = preprocess_data(noisy_images, clean_images, desired_height=256, desired_width=256)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "y_train = np.expand_dims(y_train, axis=-1)\n",
    "y_test = np.expand_dims(y_test, axis=-1)\n",
    "\n",
    "# Build the model\n",
    "model = build_model(input_shape=X_train.shape[1:])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mse = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test MSE:\", mse)\n",
    "\n",
    "# Make predictions\n",
    "# You can use the trained model to denoise new images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m desired_height \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[0;32m     35\u001b[0m desired_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[1;32m---> 36\u001b[0m noisy_images, clean_images \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and testing sets\u001b[39;00m\n\u001b[0;32m     39\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(noisy_images, clean_images, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[1;32mIn[38], line 14\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(dataset_path, desired_height, desired_width)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m69\u001b[39m):\n\u001b[0;32m     13\u001b[0m     noisy_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/noisy50/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[1;32m---> 14\u001b[0m     noisy_img_resized \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesired_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_height\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     noisy_images\u001b[38;5;241m.\u001b[39mappend(noisy_img_resized)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Load and preprocess clean images\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Function to load and preprocess the dataset\n",
    "def load_dataset(dataset_path, desired_height, desired_width):\n",
    "    noisy_images = []\n",
    "    clean_images = []\n",
    "    # Load and preprocess noisy images\n",
    "    for i in range(1, 69):\n",
    "        noisy_img = cv2.imread(f\"{dataset_path}/noisy50/{i:04d}.png\", cv2.IMREAD_GRAYSCALE)\n",
    "        noisy_img_resized = cv2.resize(noisy_img, (desired_width, desired_height))\n",
    "        noisy_images.append(noisy_img_resized)\n",
    "    # Load and preprocess clean images\n",
    "    for i in range(1, 69):\n",
    "        clean_img = cv2.imread(f\"{dataset_path}/original_png/{i:04d}.png\", cv2.IMREAD_GRAYSCALE)\n",
    "        clean_img_resized = cv2.resize(clean_img, (desired_width, desired_height))\n",
    "        clean_images.append(clean_img_resized)\n",
    "    return np.array(noisy_images), np.array(clean_images)\n",
    "\n",
    "# Function to build the model\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "dataset_path = \"CBSD68\"\n",
    "desired_height = 256\n",
    "desired_width = 256\n",
    "noisy_images, clean_images = load_dataset(dataset_path, desired_height, desired_width)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "y_train = np.expand_dims(y_train, axis=-1)\n",
    "y_test = np.expand_dims(y_test, axis=-1)\n",
    "\n",
    "# Build the model\n",
    "model = build_model(input_shape=X_train.shape[1:])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mse = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test MSE:\", mse)\n",
    "\n",
    "# Make predictions\n",
    "# You can use the trained model to denoise new images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading images: CBSD68\\noisy50\\0068.png, CBSD68\\original_png\\0068.png\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 256 and 128 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, sequential_17_1/conv2d_53_1/Sigmoid)' with input shapes: [?,256,256,1], [?,128,128,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     81\u001b[0m loss, mse \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\losses\\losses.py:1154\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m   1152\u001b[0m y_true \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(y_true, dtype\u001b[38;5;241m=\u001b[39my_pred\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   1153\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m squeeze_or_expand_to_same_rank(y_true, y_pred)\n\u001b[1;32m-> 1154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mmean(ops\u001b[38;5;241m.\u001b[39msquare(\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 256 and 128 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, sequential_17_1/conv2d_53_1/Sigmoid)' with input shapes: [?,256,256,1], [?,128,128,1]."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Function to load and preprocess the dataset\n",
    "\"\"\"def load_dataset(dataset_path, desired_height, desired_width):\n",
    "    noisy_images = []\n",
    "    clean_images = []\n",
    "    for i in range(1, 69):\n",
    "        noisy_img = cv2.imread(os.path.join(dataset_path, \"CBSD68/noisy50\", f\"{i:04d}.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "        clean_img = cv2.imread(os.path.join(dataset_path, \"CBSD68/original_png\", f\"{i:04d}.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "        noisy_img_resized = cv2.resize(noisy_img, (desired_width, desired_height))\n",
    "        clean_img_resized = cv2.resize(clean_img, (desired_width, desired_height))\n",
    "        noisy_images.append(noisy_img_resized)\n",
    "        clean_images.append(clean_img_resized)\n",
    "    return np.array(noisy_images), np.array(clean_images)\"\"\"\n",
    "def load_dataset(dataset_path, desired_height, desired_width):\n",
    "    noisy_images = []\n",
    "    clean_images = []\n",
    "    for i in range(1, 69):\n",
    "        noisy_img_path = os.path.join(dataset_path, \"noisy50\", f\"{i:04d}.png\")\n",
    "        clean_img_path = os.path.join(dataset_path, \"original_png\", f\"{i:04d}.png\")\n",
    "        noisy_img = cv2.imread(noisy_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        clean_img = cv2.imread(clean_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if noisy_img is not None and clean_img is not None:\n",
    "            noisy_img_resized = cv2.resize(noisy_img, (desired_width, desired_height))\n",
    "            clean_img_resized = cv2.resize(clean_img, (desired_width, desired_height))\n",
    "            noisy_images.append(noisy_img_resized)\n",
    "            clean_images.append(clean_img_resized)\n",
    "        else:\n",
    "            print(f\"Error loading images: {noisy_img_path}, {clean_img_path}\")\n",
    "    return np.array(noisy_images), np.array(clean_images)\n",
    "\n",
    "# Function to perform wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL = coeffs[0]\n",
    "    return LL\n",
    "\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(images):\n",
    "    images = np.array([img.reshape(img.shape[0], img.shape[1], 1) for img in images], dtype='float32') / 255.0\n",
    "    return images\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "dataset_path = \"CBSD68\"\n",
    "desired_height = 256\n",
    "desired_width = 256\n",
    "noisy_images, clean_images = load_dataset(dataset_path, desired_height, desired_width)\n",
    "\n",
    "# Apply wavelet transform to noisy images\n",
    "noisy_images_wavelet = [wavelet_transform(img) for img in noisy_images]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_train = preprocess_data(y_train)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(desired_height, desired_width, 1)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mse = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test MSE:\", mse)\n",
    "\n",
    "# Make predictions\n",
    "# You can use the trained model to denoise new images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m desired_height \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[0;32m     32\u001b[0m desired_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[1;32m---> 33\u001b[0m noisy_images, clean_images \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m noisy_images, clean_images \u001b[38;5;241m=\u001b[39m preprocess_data(noisy_images, clean_images)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and testing sets\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[45], line 14\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(dataset_path, desired_height, desired_width)\u001b[0m\n\u001b[0;32m     11\u001b[0m clean_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataset_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_png\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Resize images to desired dimensions\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m noisy_img_resized \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesired_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_height\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m clean_img_resized \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(clean_img, (desired_width, desired_height))\n\u001b[0;32m     17\u001b[0m noisy_images\u001b[38;5;241m.\u001b[39mappend(noisy_img_resized)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load dataset\n",
    "def load_dataset(dataset_path, desired_height, desired_width):\n",
    "    noisy_images = []\n",
    "    clean_images = []\n",
    "    for i in range(1, 69):\n",
    "        noisy_img = cv2.imread(os.path.join(dataset_path, \"noisy50\", f\"{i:04d}.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "        clean_img = cv2.imread(os.path.join(dataset_path, \"original_png\", f\"{i:04d}.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Resize images to desired dimensions\n",
    "        noisy_img_resized = cv2.resize(noisy_img, (desired_width, desired_height))\n",
    "        clean_img_resized = cv2.resize(clean_img, (desired_width, desired_height))\n",
    "        \n",
    "        noisy_images.append(noisy_img_resized)\n",
    "        clean_images.append(clean_img_resized)\n",
    "    \n",
    "    return np.array(noisy_images), np.array(clean_images)\n",
    "\n",
    "# Function to preprocess data\n",
    "def preprocess_data(noisy_images, clean_images):\n",
    "    # Normalize pixel values to range [0, 1]\n",
    "    noisy_images = noisy_images / 255.0\n",
    "    clean_images = clean_images / 255.0\n",
    "    return noisy_images, clean_images\n",
    "\n",
    "# Load dataset and preprocess data\n",
    "dataset_path = \"CBSD68\"\n",
    "desired_height = 256\n",
    "desired_width = 256\n",
    "noisy_images, clean_images = load_dataset(dataset_path, desired_height, desired_width)\n",
    "noisy_images, clean_images = preprocess_data(noisy_images, clean_images)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data\n",
    "X_train = X_train.reshape(-1, X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(-1, X_test.shape[1], X_test.shape[2], 1)\n",
    "y_train = y_train.reshape(-1, y_train.shape[1], y_train.shape[2], 1)\n",
    "y_test = y_test.reshape(-1, y_test.shape[1], y_test.shape[2], 1)\n",
    "\n",
    "# Model definition, compilation, training, and evaluation code goes here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCBSD68\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m noisy_images, clean_images \u001b[38;5;241m=\u001b[39m load_dataset(dataset_path)\n\u001b[1;32m---> 47\u001b[0m noisy_images, clean_images \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Apply wavelet transform to noisy images\u001b[39;00m\n\u001b[0;32m     50\u001b[0m noisy_images_wavelet \u001b[38;5;241m=\u001b[39m [wavelet_transform(img) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m noisy_images]\n",
      "Cell \u001b[1;32mIn[48], line 20\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(noisy_images, clean_images, desired_height, desired_width)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_data\u001b[39m(noisy_images, clean_images, desired_height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, desired_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m):\n\u001b[1;32m---> 20\u001b[0m     resized_noisy_images \u001b[38;5;241m=\u001b[39m [\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesired_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_height\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m noisy_images]\n\u001b[0;32m     21\u001b[0m     resized_clean_images \u001b[38;5;241m=\u001b[39m [cv2\u001b[38;5;241m.\u001b[39mresize(img, (desired_width, desired_height)) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m clean_images]\n\u001b[0;32m     22\u001b[0m     normalized_noisy_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(resized_noisy_images, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "def load_dataset(dataset_path):\n",
    "    noisy_images = []\n",
    "    clean_images = []\n",
    "    for i in range(1, 69):\n",
    "        noisy_img = cv2.imread(os.path.join(dataset_path, \"noisy50\", f\"{i:04d}.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "        clean_img = cv2.imread(os.path.join(dataset_path, \"original_png\", f\"{i:04d}.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "        noisy_images.append(noisy_img)\n",
    "        clean_images.append(clean_img)\n",
    "    return noisy_images, clean_images\n",
    "\n",
    "def preprocess_data(noisy_images, clean_images, desired_height=256, desired_width=256):\n",
    "    resized_noisy_images = [cv2.resize(img, (desired_width, desired_height)) for img in noisy_images]\n",
    "    resized_clean_images = [cv2.resize(img, (desired_width, desired_height)) for img in clean_images]\n",
    "    normalized_noisy_images = np.array(resized_noisy_images, dtype='float32') / 255.0\n",
    "    normalized_clean_images = np.array(resized_clean_images, dtype='float32') / 255.0\n",
    "    return normalized_noisy_images, normalized_clean_images\n",
    "\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, (_, _) = coeffs\n",
    "    return LL\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = \"CBSD68\"\n",
    "    noisy_images, clean_images = load_dataset(dataset_path)\n",
    "    noisy_images, clean_images = preprocess_data(noisy_images, clean_images)\n",
    "\n",
    "    # Apply wavelet transform to noisy images\n",
    "    noisy_images_wavelet = [wavelet_transform(img) for img in noisy_images]\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(noisy_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Preprocess the data\n",
    "    X_train = np.expand_dims(X_train, axis=-1)\n",
    "    X_test = np.expand_dims(X_test, axis=-1)\n",
    "    y_train = np.expand_dims(y_train, axis=-1)\n",
    "    y_test = np.expand_dims(y_test, axis=-1)\n",
    "\n",
    "    # Build the model\n",
    "    model = build_model(input_shape=X_train[0].shape)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, mse = model.evaluate(X_test, y_test)\n",
    "    print(\"Test MSE:\", mse)\n",
    "\n",
    "    # Save the model\n",
    "    model.save('denoising_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.0577 - mse: 0.0568 - val_loss: 0.0552 - val_mse: 0.0552\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - loss: 0.0614 - mse: 0.0601 - val_loss: 0.0546 - val_mse: 0.0546\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - loss: 0.0568 - mse: 0.0551 - val_loss: 0.0567 - val_mse: 0.0567\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - loss: 0.0570 - mse: 0.0573 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.0581 - mse: 0.0591 - val_loss: 0.0497 - val_mse: 0.0497\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.0511 - mse: 0.0507 - val_loss: 0.0498 - val_mse: 0.0498\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 0.0469 - mse: 0.0454 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - loss: 0.0436 - mse: 0.0437 - val_loss: 0.0411 - val_mse: 0.0411\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - loss: 0.0442 - mse: 0.0447 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0422 - val_mse: 0.0422\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - loss: 0.0655 - mse: 0.0657 - val_loss: 0.0552 - val_mse: 0.0552\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - loss: 0.0589 - mse: 0.0585 - val_loss: 0.0545 - val_mse: 0.0545\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - loss: 0.0577 - mse: 0.0588 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.0586 - mse: 0.0601 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.0563 - mse: 0.0559 - val_loss: 0.0514 - val_mse: 0.0514\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - loss: 0.0578 - mse: 0.0574 - val_loss: 0.0510 - val_mse: 0.0510\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - loss: 0.0507 - mse: 0.0493 - val_loss: 0.0501 - val_mse: 0.0501\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.0530 - mse: 0.0539 - val_loss: 0.0517 - val_mse: 0.0517\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.0468 - mse: 0.0470 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - loss: 0.0439 - mse: 0.0444 - val_loss: 0.0443 - val_mse: 0.0443\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Function to load images from a folder\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        img = cv2.imread(os.path.join(folder_path,filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Function to apply wavelet transform to an image\n",
    "# Function to apply wavelet transform to an image\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL = coeffs[0]  # Select the approximation coefficients (LL) only\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(images, desired_width, desired_height):\n",
    "    resized_images = [cv2.resize(img, (desired_width, desired_height)) for img in images]\n",
    "    processed_images = np.array([img.reshape(img.shape[0], img.shape[1], 1) for img in resized_images], dtype='float32') / 255.0\n",
    "    return processed_images\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy5_images = load_images_from_folder(\"CBSD68/noisy5\")\n",
    "noisy10_images = load_images_from_folder(\"CBSD68/noisy50\")\n",
    "clean_images = load_images_from_folder(\"CBSD68/original_png\")\n",
    "\n",
    "# Check if the number of noisy and clean images match\n",
    "if len(noisy5_images) != len(clean_images):\n",
    "    raise ValueError(\"Number of noisy images and clean images do not match!\")\n",
    "\n",
    "# Apply wavelet transform to noisy images\n",
    "noisy5_images_wavelet = [wavelet_transform(img) for img in noisy5_images]\n",
    "noisy10_images_wavelet = [wavelet_transform(img) for img in noisy10_images]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(noisy5_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "X_train_10, X_test_10, y_train_10, y_test_10 = train_test_split(noisy10_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "desired_width = 256\n",
    "desired_height = 256\n",
    "X_train_5 = preprocess_data(X_train_5, desired_width, desired_height)\n",
    "X_test_5 = preprocess_data(X_test_5, desired_width, desired_height)\n",
    "y_train_5 = preprocess_data(y_train_5, desired_width, desired_height)\n",
    "y_test_5 = preprocess_data(y_test_5, desired_width, desired_height)\n",
    "X_train_10 = preprocess_data(X_train_10, desired_width, desired_height)\n",
    "X_test_10 = preprocess_data(X_test_10, desired_width, desired_height)\n",
    "y_train_10 = preprocess_data(y_train_10, desired_width, desired_height)\n",
    "y_test_10 = preprocess_data(y_test_10, desired_width, desired_height)\n",
    "\n",
    "# Define the CNN model\n",
    "def create_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(desired_width, desired_height, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(desired_width * desired_height, activation='sigmoid'))\n",
    "    model.add(layers.Reshape((desired_width, desired_height, 1)))\n",
    "    return model\n",
    "\n",
    "# Create models\n",
    "model_5 = create_model()\n",
    "model_10 = create_model()\n",
    "\n",
    "# Compile models\n",
    "model_5.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model_10.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train the models\n",
    "history_5 = model_5.fit(X_train_5, y_train_5, epochs=10, batch_size=16, validation_data=(X_test_5, y_test_5))\n",
    "history_10 = model_10.fit(X_train_10, y_train_10, epochs=10, batch_size=16, validation_data=(X_test_10, y_test_10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for denoising process\n",
    "def denoise_image(image):\n",
    "    # Perform wavelet transform to get LL coefficients\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    \n",
    "    # Predict denoised LL coefficients using the trained model\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    \n",
    "    # Perform inverse wavelet transform to get the denoised image\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    \n",
    "    return denoised_image\n",
    "\n",
    "# Load a noisy image (replace 'noisy_image_path' with the path to your noisy image)\n",
    "noisy_image = cv2.imread('0038.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Preprocess the noisy image\n",
    "noisy_image = cv2.resize(noisy_image, (256, 256))  # Resize if necessary\n",
    "noisy_image = noisy_image.astype('float32') / 255.0\n",
    "noisy_image = np.expand_dims(noisy_image, axis=-1)\n",
    "\n",
    "# Denoise the image\n",
    "denoised_image = denoise_image(noisy_image)\n",
    "\n",
    "# Display or save the denoised image\n",
    "cv2.imshow('Denoised Image', denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14s/step - loss: 0.0610 - mse: 0.0609 - val_loss: 0.0517 - val_mse: 0.0517\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15s/step - loss: 0.0576 - mse: 0.0568 - val_loss: 0.0499 - val_mse: 0.0499\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 22s/step - loss: 0.0564 - mse: 0.0565 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 21s/step - loss: 0.0526 - mse: 0.0526 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 18s/step - loss: 0.0475 - mse: 0.0477 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 12s/step - loss: 0.0411 - mse: 0.0416 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15s/step - loss: 0.0309 - mse: 0.0310 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 11s/step - loss: 0.0236 - mse: 0.0239 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 11s/step - loss: 0.0141 - mse: 0.0143 - val_loss: 0.0073 - val_mse: 0.0073\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12s/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original_png\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Function for denoising process\n",
    "def denoise_image(image):\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Example denoising\n",
    "noisy_example = X_test[0]\n",
    "denoised_example = denoise_image(noisy_example)\n",
    "\n",
    "# Save or display the denoised image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step\n"
     ]
    }
   ],
   "source": [
    "# Function for denoising process\n",
    "def denoise_image(image):\n",
    "    # Perform wavelet transform to get LL coefficients\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    \n",
    "    # Predict denoised LL coefficients using the trained model\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    \n",
    "    # Perform inverse wavelet transform to get the denoised image\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    \n",
    "    return denoised_image\n",
    "\n",
    "# Load a noisy image (replace 'noisy_image_path' with the path to your noisy image)\n",
    "noisy_image = cv2.imread('0038.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Preprocess the noisy image\n",
    "noisy_image = cv2.resize(noisy_image, (256, 256))  # Resize if necessary\n",
    "noisy_image = noisy_image.astype('float32') / 255.0\n",
    "noisy_image = np.expand_dims(noisy_image, axis=-1)\n",
    "\n",
    "# Denoise the image\n",
    "denoised_image = denoise_image(noisy_image)\n",
    "\n",
    "# Display or save the denoised image\n",
    "cv2.imshow('Denoised Image', denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680ms/step\n"
     ]
    }
   ],
   "source": [
    "# Example denoising\n",
    "noisy_example = X_test[0]\n",
    "denoised_example = denoise_image(noisy_example)\n",
    "\n",
    "# Save the denoised image\n",
    "cv2.imwrite('0038.png', denoised_example)\n",
    "\n",
    "# Display the denoised image\n",
    "cv2.imshow('Denoised Image', denoised_example)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 17s/step - loss: 0.0602 - mse: 0.0602 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 18s/step - loss: 0.0595 - mse: 0.0595 - val_loss: 0.0500 - val_mse: 0.0500\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 12s/step - loss: 0.0556 - mse: 0.0556 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 14s/step - loss: 0.0531 - mse: 0.0531 - val_loss: 0.0413 - val_mse: 0.0413\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 20s/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0348 - val_mse: 0.0348\n",
      "Epoch 6/10\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 23s/step - loss: 0.0424 - mse: 0.0424"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define custom mean squared error (MSE) metric\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original_png\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model with custom MSE metric\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[mse])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model in the native Keras format\n",
    "model.save(\"image_denoising_model.keras\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to post-process the predicted image\n",
    "def postprocess_image(img):\n",
    "    img = np.clip(img, 0, 1) * 255\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.keras\", compile=False)\n",
    "\n",
    "# Define the path to the noisy image\n",
    "noisy_image_path = \"0038.png\"\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Use the model to predict the denoised image\n",
    "denoised_image = model.predict(np.expand_dims(input_image, axis=0))[0]\n",
    "\n",
    "# Post-process the predicted image\n",
    "denoised_image = postprocess_image(denoised_image)\n",
    "\n",
    "# Display the original and denoised images\n",
    "original_image = cv2.imread(noisy_image_path)\n",
    "cv2.imshow(\"Original Image\", original_image)\n",
    "cv2.imshow(\"Denoised Image\", denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 18s/step - loss: 0.0617 - mse: 0.0617 - val_loss: 0.0521 - val_mse: 0.0521\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 35s/step - loss: 0.0587 - mse: 0.0587 - val_loss: 0.0499 - val_mse: 0.0499\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13s/step - loss: 0.0553 - mse: 0.0553 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 11s/step - loss: 0.0526 - mse: 0.0526 - val_loss: 0.0424 - val_mse: 0.0424\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 17s/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12s/step - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13s/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13s/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11s/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 14s/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0086 - val_mse: 0.0086\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A total of 1 objects could not be loaded. Example error message for object <keras.src.optimizers.adam.Adam object at 0x0000018EA6340FB0>:\n\n'Unable to synchronously open object (bad object header chunk size)'\n\nList of objects that could not be loaded:\n[<keras.src.optimizers.adam.Adam object at 0x0000018EA6340FB0>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_denoising_model.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_denoising_model.keras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmse\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Denoise a new image\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Load a noisy image (replace 'noisy_image_path' with the path to your noisy image)\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:176\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    173\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip:\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(filepath)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:192\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    189\u001b[0m         asset_store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m failed_trackables:\n\u001b[1;32m--> 192\u001b[0m          \u001b[43m_raise_loading_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror_msgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:273\u001b[0m, in \u001b[0;36m_raise_loading_failure\u001b[1;34m(error_msgs, warn_only)\u001b[0m\n\u001b[0;32m    271\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: A total of 1 objects could not be loaded. Example error message for object <keras.src.optimizers.adam.Adam object at 0x0000018EA6340FB0>:\n\n'Unable to synchronously open object (bad object header chunk size)'\n\nList of objects that could not be loaded:\n[<keras.src.optimizers.adam.Adam object at 0x0000018EA6340FB0>]"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "# Define custom mean squared error (MSE) metric\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Function to denoise image using the trained model\n",
    "def denoise_image(image, model):\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original_png\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model with custom MSE metric\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[mse])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model in the native Keras format\n",
    "model.save(\"image_denoising_model.keras\")\n",
    "\n",
    "# Load the trained model\n",
    "trained_model = tf.keras.models.load_model(\"image_denoising_model.keras\", custom_objects={'mse': mse})\n",
    "\n",
    "# Denoise a new image\n",
    "# Load a noisy image (replace 'noisy_image_path' with the path to your noisy image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trained_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m noisy_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(noisy_image, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Denoise the image\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m denoised_image \u001b[38;5;241m=\u001b[39m denoise_image(noisy_image, \u001b[43mtrained_model\u001b[49m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Save or display the denoised image\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trained_model' is not defined"
     ]
    }
   ],
   "source": [
    "noisy_image = cv2.imread('images.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Preprocess the noisy image\n",
    "noisy_image = cv2.resize(noisy_image, (256, 256))  # Resize if necessary\n",
    "noisy_image = noisy_image.astype('float32') / 255.0\n",
    "noisy_image = np.expand_dims(noisy_image, axis=-1)\n",
    "\n",
    "# Denoise the image\n",
    "denoised_image = denoise_image(noisy_image, trained_model)\n",
    "\n",
    "# Save or display the denoised image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 15s/step - loss: 0.0572 - mse: 0.0572 - val_loss: 0.0607 - val_mse: 0.0607\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 16s/step - loss: 0.0566 - mse: 0.0566 - val_loss: 0.0615 - val_mse: 0.0615\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 18s/step - loss: 0.0558 - mse: 0.0558 - val_loss: 0.0606 - val_mse: 0.0606\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12s/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 11s/step - loss: 0.0541 - mse: 0.0541 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 15s/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0598 - val_mse: 0.0598\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 13s/step - loss: 0.0557 - mse: 0.0557 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 12s/step - loss: 0.0541 - mse: 0.0541 - val_loss: 0.0599 - val_mse: 0.0599\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 11s/step - loss: 0.0533 - mse: 0.0533 - val_loss: 0.0602 - val_mse: 0.0602\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14s/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0598 - val_mse: 0.0598\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define custom mean squared error (MSE) metric\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model with custom MSE metric\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[mse])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model in the native Keras format\n",
    "model.save(\"image_denoising_model.keras\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to post-process the predicted image\n",
    "def postprocess_image(img):\n",
    "    img = np.clip(img, 0, 1) * 255\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.keras\", compile=False)\n",
    "\n",
    "# Define the path to the noisy image\n",
    "noisy_image_path = \"images.jpeg\"\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Use the model to predict the denoised image\n",
    "denoised_image = model.predict(np.expand_dims(input_image, axis=0))[0]\n",
    "\n",
    "# Post-process the predicted image\n",
    "denoised_image = postprocess_image(denoised_image)\n",
    "\n",
    "# Display the original and denoised images\n",
    "original_image = cv2.imread(noisy_image_path)\n",
    "cv2.imshow(\"Original Image\", original_image)\n",
    "cv2.imshow(\"Denoised Image\", denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the noisy image\n",
    "noisy_image_path = \"images.jpeg\"\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Use the model to predict the denoised image\n",
    "denoised_image = model.predict(np.expand_dims(input_image, axis=0))[0]\n",
    "\n",
    "# Post-process the predicted image\n",
    "denoised_image = postprocess_image(denoised_image)\n",
    "\n",
    "# Display the original and denoised images\n",
    "original_image = cv2.imread(noisy_image_path)\n",
    "cv2.imshow(\"Original Image\", original_image)\n",
    "cv2.imshow(\"Denoised Image\", denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 33s/step - loss: 0.0604 - mse: 0.0604 - val_loss: 0.0604 - val_mse: 0.0604\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 14s/step - loss: 0.0574 - mse: 0.0585 - val_loss: 0.0619 - val_mse: 0.0619\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - loss: 0.0558 - mse: 0.0555 - val_loss: 0.0606 - val_mse: 0.0606\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 19s/step - loss: 0.0559 - mse: 0.0564 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 16s/step - loss: 0.0541 - mse: 0.0531 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13s/step - loss: 0.0556 - mse: 0.0558 - val_loss: 0.0599 - val_mse: 0.0599\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 14s/step - loss: 0.0557 - mse: 0.0561 - val_loss: 0.0599 - val_mse: 0.0599\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15s/step - loss: 0.0550 - mse: 0.0552 - val_loss: 0.0602 - val_mse: 0.0602\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 12s/step - loss: 0.0540 - mse: 0.0533 - val_loss: 0.0602 - val_mse: 0.0602\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 17s/step - loss: 0.0553 - mse: 0.0557 - val_loss: 0.0598 - val_mse: 0.0598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`coeffs` must all be of equal size (or None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Example denoising\u001b[39;00m\n\u001b[0;32m     67\u001b[0m noisy_example \u001b[38;5;241m=\u001b[39m X_test[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 68\u001b[0m denoised_example \u001b[38;5;241m=\u001b[39m \u001b[43mdenoise_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_example\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Save or display the denoised image\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 63\u001b[0m, in \u001b[0;36mdenoise_image\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     61\u001b[0m LL, LH, HL, HH \u001b[38;5;241m=\u001b[39m wavelet_transform(img)\n\u001b[0;32m     62\u001b[0m denoised_LL \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mexpand_dims(LL, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m---> 63\u001b[0m denoised_image \u001b[38;5;241m=\u001b[39m \u001b[43mpywt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midwt2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdenoised_LL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mLH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhaar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m denoised_image\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\pywt\\_multidim.py:118\u001b[0m, in \u001b[0;36midwt2\u001b[1;34m(coeffs, wavelet, mode, axes)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2 axes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    117\u001b[0m coeffs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maa\u001b[39m\u001b[38;5;124m'\u001b[39m: LL, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mda\u001b[39m\u001b[38;5;124m'\u001b[39m: HL, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mad\u001b[39m\u001b[38;5;124m'\u001b[39m: LH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd\u001b[39m\u001b[38;5;124m'\u001b[39m: HH}\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43midwtn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoeffs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwavelet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\pywt\\_multidim.py:280\u001b[0m, in \u001b[0;36midwtn\u001b[1;34m(coeffs, wavelet, mode, axes)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`coeffs` must contain at least one non-null wavelet \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mband\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(s \u001b[38;5;241m!=\u001b[39m coeff_shape \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m coeff_shapes):\n\u001b[1;32m--> 280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`coeffs` must all be of equal size (or None)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    283\u001b[0m     axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(ndim_transform)\n",
      "\u001b[1;31mValueError\u001b[0m: `coeffs` must all be of equal size (or None)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs\n",
    "    return LL, LH, HL, HH\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model in the native Keras format\n",
    "model.save(\"image_denoising_model.keras\")\n",
    "\n",
    "\"\"\"# Function to denoise image using CNN and wavelet transform\n",
    "def denoise_image(img):\n",
    "    LL, LH, HL, HH = wavelet_transform(img)\n",
    "    denoised_LL = model.predict(np.expand_dims(LL, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_LL.squeeze(), (LH, HL, HH)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Example denoising\n",
    "noisy_example = X_test[0]\n",
    "denoised_example = denoise_image(noisy_example)\n",
    "\n",
    "# Save or display the denoised image\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to denoise image using CNN and wavelet transform\n",
    "def denoise_image(img):\n",
    "    LL, LH, HL, HH = wavelet_transform(img)\n",
    "    denoised_LL = model.predict(np.expand_dims(LL, axis=0))\n",
    "    \n",
    "    # Reshape denoised LL coefficient to match the shapes of LH, HL, and HH coefficients\n",
    "    denoised_LL_resized = cv2.resize(denoised_LL.squeeze(), (LH.shape[1], LH.shape[0]))\n",
    "    \n",
    "    denoised_image = pywt.idwt2((denoised_LL_resized, (LH, HL, HH)), 'haar')\n",
    "    return denoised_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to post-process the predicted image\n",
    "def postprocess_image(img):\n",
    "    img = np.clip(img, 0, 1) * 255\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.keras\", compile=False)\n",
    "\n",
    "# Function to denoise the input image\n",
    "def denoise_image(img):\n",
    "    denoised_img = model.predict(np.expand_dims(img, axis=0))[0]\n",
    "    return denoised_img\n",
    "\n",
    "# Define the path to the noisy image\n",
    "noisy_image_path = \"0038.png\"  # Replace with the path to your noisy image\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Denoise the image\n",
    "denoised_image = denoise_image(input_image)\n",
    "\n",
    "# Post-process the denoised image\n",
    "denoised_image = postprocess_image(denoised_image)\n",
    "\n",
    "# Display the original and denoised images\n",
    "original_image = cv2.imread(noisy_image_path)\n",
    "cv2.imshow(\"Original Image\", original_image)\n",
    "cv2.imshow(\"Denoised Image\", denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Original and denoised images saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to post-process the predicted image\n",
    "def postprocess_image(img):\n",
    "    img = np.clip(img, 0, 1) * 255\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.keras\", compile=False)\n",
    "\n",
    "# Function to denoise the input image\n",
    "def denoise_image(img):\n",
    "    denoised_img = model.predict(np.expand_dims(img, axis=0))[0]\n",
    "    return denoised_img\n",
    "\n",
    "# Define the path to the noisy image\n",
    "noisy_image_path = \"images.jpeg\"  # Replace with the path to your noisy image\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Denoise the image\n",
    "denoised_image = denoise_image(input_image)\n",
    "\n",
    "# Post-process the denoised image\n",
    "denoised_image = postprocess_image(denoised_image)\n",
    "\n",
    "# Save the original and denoised images\n",
    "original_image = cv2.imread(noisy_image_path)\n",
    "cv2.imwrite(\"original_image.jpg\", original_image)\n",
    "cv2.imwrite(\"denoised_image.jpg\", denoised_image)\n",
    "\n",
    "print(\"Original and denoised images saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 10s/step - loss: 0.0613 - val_loss: 0.0533\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10s/step - loss: 0.0576 - val_loss: 0.0503\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13s/step - loss: 0.0558 - val_loss: 0.0460\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 11s/step - loss: 0.0501 - val_loss: 0.0392\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 10s/step - loss: 0.0432 - val_loss: 0.0295\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11s/step - loss: 0.0327 - val_loss: 0.0191\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 10s/step - loss: 0.0205 - val_loss: 0.0101\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 11s/step - loss: 0.0110 - val_loss: 0.0064\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 16s/step - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12s/step - loss: 0.0097 - val_loss: 0.0095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original_png\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Function for denoising process\n",
    "def denoise_image(image):\n",
    "    noisy_ll = wavelet_transform(image)\n",
    "    denoised_ll = model.predict(np.expand_dims(noisy_ll, axis=0))\n",
    "    denoised_image = pywt.idwt2((denoised_ll.squeeze(), (None, None, None)), 'haar')\n",
    "    return denoised_image\n",
    "\n",
    "# Example denoising\n",
    "noisy_example = X_test[0]\n",
    "denoised_example = denoise_image(noisy_example)\n",
    "\n",
    "# Save or display the denoised image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to post-process the predicted image\n",
    "def postprocess_image(img):\n",
    "    img = np.clip(img, 0, 1) * 255\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.keras\", compile=False)\n",
    "\n",
    "# Define the path to the noisy image\n",
    "noisy_image_path = \"0002.jpeg\"  # Replace with your noisy image path\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Use the model to predict the denoised image\n",
    "denoised_image = model.predict(np.expand_dims(input_image, axis=0))[0]\n",
    "\n",
    "# Post-process the predicted image\n",
    "denoised_image = postprocess_image(denoised_image)\n",
    "\n",
    "# Save or display the denoised image\n",
    "cv2.imwrite(\"denoised_imagec.jpeg\", denoised_image)  # Save the denoised image\n",
    "# cv2.imshow(\"Denoised Image\", denoised_image)  # Display the denoised image\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43md\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 138s/step - accuracy: 0.0143 - loss: 0.0610 - val_accuracy: 4.3597e-06 - val_loss: 0.0571\n",
      "Epoch 2/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 293s/step - accuracy: 6.4756e-06 - loss: 0.0597 - val_accuracy: 4.3597e-06 - val_loss: 0.0556\n",
      "Epoch 3/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 43s/step - accuracy: 1.0767e-05 - loss: 0.0584 - val_accuracy: 4.3597e-06 - val_loss: 0.0522\n",
      "Epoch 4/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 102s/step - accuracy: 6.4756e-06 - loss: 0.0533 - val_accuracy: 4.3597e-06 - val_loss: 0.0344\n",
      "Epoch 5/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 84s/step - accuracy: 1.0767e-05 - loss: 0.0382 - val_accuracy: 4.3597e-06 - val_loss: 0.0569\n",
      "Epoch 6/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42s/step - accuracy: 1.0608e-05 - loss: 0.0556 - val_accuracy: 1.8529e-05 - val_loss: 0.0394\n",
      "Epoch 7/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 43s/step - accuracy: 0.0045 - loss: 0.0476 - val_accuracy: 0.0056 - val_loss: 0.0403\n",
      "Epoch 8/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 105s/step - accuracy: 0.0107 - loss: 0.0465 - val_accuracy: 0.0056 - val_loss: 0.0293\n",
      "Epoch 9/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 40s/step - accuracy: 0.0120 - loss: 0.0332 - val_accuracy: 0.0056 - val_loss: 0.0259\n",
      "Epoch 10/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 41s/step - accuracy: 0.0141 - loss: 0.0300 - val_accuracy: 0.0056 - val_loss: 0.0213\n",
      "Epoch 11/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 40s/step - accuracy: 0.0117 - loss: 0.0224 - val_accuracy: 0.0056 - val_loss: 0.0128\n",
      "Epoch 12/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 40s/step - accuracy: 0.0116 - loss: 0.0176 - val_accuracy: 0.0056 - val_loss: 0.0135\n",
      "Epoch 13/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 126s/step - accuracy: 0.0131 - loss: 0.0164 - val_accuracy: 0.0056 - val_loss: 0.0141\n",
      "Epoch 14/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 38s/step - accuracy: 0.0119 - loss: 0.0149 - val_accuracy: 0.0056 - val_loss: 0.0149\n",
      "Epoch 15/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 42s/step - accuracy: 0.0131 - loss: 0.0159 - val_accuracy: 0.0056 - val_loss: 0.0173\n",
      "Epoch 16/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 146s/step - accuracy: 0.0105 - loss: 0.0155 - val_accuracy: 0.0056 - val_loss: 0.0118\n",
      "Epoch 17/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 38s/step - accuracy: 0.0128 - loss: 0.0134 - val_accuracy: 0.0056 - val_loss: 0.0107\n",
      "Epoch 18/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 48s/step - accuracy: 0.0115 - loss: 0.0123 - val_accuracy: 0.0056 - val_loss: 0.0111\n",
      "Epoch 19/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2477s\u001b[0m 2432s/step - accuracy: 0.0100 - loss: 0.0120 - val_accuracy: 0.0056 - val_loss: 0.0104\n",
      "Epoch 20/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 37s/step - accuracy: 0.0126 - loss: 0.0119 - val_accuracy: 0.0056 - val_loss: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"\n",
    "clean_data_dir = \"CBSD68/original_png\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(noisy_images)\n",
    "y_train = preprocess_data(clean_images)\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    layers.UpSampling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.UpSampling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"image_denoising_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_denoising_model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Define the path to the noisy image\u001b[39;00m\n\u001b[0;32m     23\u001b[0m noisy_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_noisy_image.png\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Change this to the path of your noisy image\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    177\u001b[0m         filepath,\n\u001b[0;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:155\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    151\u001b[0m training_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(training_config)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Compile model.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43msaving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args_from_training_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m )\n\u001b[0;32m    159\u001b[0m saving_utils\u001b[38;5;241m.\u001b[39mtry_build_compiled_arguments(model)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Set optimizer weights.\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:143\u001b[0m, in \u001b[0;36mcompile_args_from_training_config\u001b[1;34m(training_config, custom_objects)\u001b[0m\n\u001b[0;32m    141\u001b[0m loss_config \u001b[38;5;241m=\u001b[39m training_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43m_deserialize_nested_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Ensure backwards compatibility for losses in legacy H5 files\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m _resolve_compile_arguments_compat(loss, loss_config, losses)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:202\u001b[0m, in \u001b[0;36m_deserialize_nested_config\u001b[1;34m(deserialize_fn, config)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_single_object(config):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    205\u001b[0m         k: _deserialize_nested_config(deserialize_fn, v)\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    207\u001b[0m     }\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\losses\\__init__.py:124\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.losses.deserialize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeserialize\u001b[39m(name, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserializes a serialized loss class/function instance.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m        A Keras `Loss` instance or a loss function.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_OBJECTS_DICT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:570\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module_objects[config], types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m--> 570\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                \u001b[49m\u001b[43mserialize_with_public_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_module_name\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m deserialize_keras_object(\n\u001b[0;32m    577\u001b[0m             serialize_with_public_class(\n\u001b[0;32m    578\u001b[0m                 module_objects[config], inner_config\u001b[38;5;241m=\u001b[39minner_config\n\u001b[0;32m    579\u001b[0m             ),\n\u001b[0;32m    580\u001b[0m             custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    581\u001b[0m         )\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PLAIN_TYPES):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:671\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    670\u001b[0m     fn_name \u001b[38;5;241m=\u001b[39m inner_config\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;66;03m# Below, handling of all classes.\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# First, is it a shared object?\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:805\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 805\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure custom classes are decorated with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to post-process the predicted image\n",
    "def postprocess_image(img):\n",
    "    img = np.clip(img, 0, 1) * 255\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.h5\", compile=False)\n",
    "\n",
    "# Define the path to the noisy image\n",
    "noisy_image_path = \"your_noisy_image.png\"  # Change this to the path of your noisy image\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Use the model to predict the denoised image\n",
    "denoised_image = model.predict(np.expand_dims(input_image, axis=0))[0]\n",
    "\n",
    "# Post-process the predicted image\n",
    "denoised_image = postprocess_image(denoised_image)\n",
    "\n",
    "# Save or display the denoised image\n",
    "cv2.imwrite(\"0002.png\", denoised_image)  # Save the denoised image\n",
    "cv2.imshow(\"Denoised Image\", denoised_image)      # Display the denoised image\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 256 and 128 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, sequential_1_1/conv2d_13_1/Sigmoid)' with input shapes: [?,256,256,1], [?,128,128,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m model_HH\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Train the models\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m \u001b[43mmodel_LL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_LL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_LL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m model_LH\u001b[38;5;241m.\u001b[39mfit(X_train_LH, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test_LH, y_test))\n\u001b[0;32m     76\u001b[0m model_HL\u001b[38;5;241m.\u001b[39mfit(X_train_HL, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test_HL, y_test))\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\losses\\losses.py:1154\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m   1152\u001b[0m y_true \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(y_true, dtype\u001b[38;5;241m=\u001b[39my_pred\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   1153\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m squeeze_or_expand_to_same_rank(y_true, y_pred)\n\u001b[1;32m-> 1154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mmean(ops\u001b[38;5;241m.\u001b[39msquare(\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 256 and 128 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](data_1, sequential_1_1/conv2d_13_1/Sigmoid)' with input shapes: [?,256,256,1], [?,128,128,1]."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs\n",
    "    return LL, LH, HL, HH\n",
    "\n",
    "# Preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Wavelet transform on noisy images\n",
    "noisy_images_wavelet = [wavelet_transform(img) for img in noisy_images]\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images_wavelet, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_LL = preprocess_data(np.array([img[0] for img in X_train]))\n",
    "X_train_LH = preprocess_data(np.array([img[1] for img in X_train]))\n",
    "X_train_HL = preprocess_data(np.array([img[2] for img in X_train]))\n",
    "X_train_HH = preprocess_data(np.array([img[3] for img in X_train]))\n",
    "y_train = preprocess_data(y_train)\n",
    "\n",
    "X_test_LL = preprocess_data(np.array([img[0] for img in X_test]))\n",
    "X_test_LH = preprocess_data(np.array([img[1] for img in X_test]))\n",
    "X_test_HL = preprocess_data(np.array([img[2] for img in X_test]))\n",
    "X_test_HH = preprocess_data(np.array([img[3] for img in X_test]))\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "def build_model(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Build and compile the model\n",
    "model_LL = build_model((256, 256, 1))\n",
    "model_LH = build_model((256, 256, 1))\n",
    "model_HL = build_model((256, 256, 1))\n",
    "model_HH = build_model((256, 256, 1))\n",
    "\n",
    "model_LL.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model_LH.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model_HL.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model_HH.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Train the models\n",
    "model_LL.fit(X_train_LL, y_train, epochs=10, batch_size=32, validation_data=(X_test_LL, y_test))\n",
    "model_LH.fit(X_train_LH, y_train, epochs=10, batch_size=32, validation_data=(X_test_LH, y_test))\n",
    "model_HL.fit(X_train_HL, y_train, epochs=10, batch_size=32, validation_data=(X_test_HL, y_test))\n",
    "model_HH.fit(X_train_HH, y_train, epochs=10, batch_size=32, validation_data=(X_test_HH, y_test))\n",
    "\n",
    "# Evaluate the models\n",
    "loss_LL, acc_LL = model_LL.evaluate(X_test_LL, y_test)\n",
    "loss_LH, acc_LH = model_LH.evaluate(X_test_LH, y_test)\n",
    "loss_HL, acc_HL = model_HL.evaluate(X_test_HL, y_test)\n",
    "loss_HH, acc_HH = model_HH.evaluate(X_test_HH, y_test)\n",
    "\n",
    "print(\"LL Model - Loss:\", loss_LL, \"Accuracy:\", acc_LL)\n",
    "print(\"LH Model - Loss:\", loss_LH, \"Accuracy:\", acc_LH)\n",
    "print(\"HL Model - Loss:\", loss_HL, \"Accuracy:\", acc_HL)\n",
    "print(\"HH Model - Loss:\", loss_HH, \"Accuracy:\", acc_HH)\n",
    "\n",
    "# Combine the models for denoising\n",
    "def denoise_image(model_LL, model_LH, model_HL, model_HH, img_LL, img_LH, img_HL, img_HH):\n",
    "    denoised_LL = model_LL.predict(img_LL)\n",
    "    denoised_LH = model_LH.predict(img_LH)\n",
    "    denoised_HL = model_HL.predict(img_HL)\n",
    "    denoised_HH = model_HH.predict(img_HH)\n",
    "    denoised_img = pywt.idwt2((denoised_LL.squeeze(), (denoised_LH.squeeze(), denoised_HL.squeeze(), denoised_HH.squeeze())), 'haar')\n",
    "    return denoised_img\n",
    "\n",
    "# Example denoising\n",
    "denoised_example = denoise_image(model_LL, model_LH, model_HL, model_HH, X_test_LL[0:1], X_test_LH[0:1], X_test_HL[0:1], X_test_HH[0:1])\n",
    "\n",
    "# Save or display the denoised image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 26s/step - accuracy: 4.6542e-05 - loss: 0.0564 - val_accuracy: 5.4496e-06 - val_loss: 0.0614\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 11s/step - accuracy: 1.2215e-05 - loss: 0.0573 - val_accuracy: 5.4496e-06 - val_loss: 0.0613\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 14s/step - accuracy: 7.6058e-06 - loss: 0.0552 - val_accuracy: 5.4496e-06 - val_loss: 0.0601\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 20s/step - accuracy: 1.2851e-05 - loss: 0.0565 - val_accuracy: 5.4496e-06 - val_loss: 0.0600\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 12s/step - accuracy: 1.1738e-05 - loss: 0.0562 - val_accuracy: 5.4496e-06 - val_loss: 0.0599\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12s/step - accuracy: 1.1738e-05 - loss: 0.0551 - val_accuracy: 5.4496e-06 - val_loss: 0.0600\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11s/step - accuracy: 1.2215e-05 - loss: 0.0567 - val_accuracy: 5.4496e-06 - val_loss: 0.0601\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 19s/step - accuracy: 1.2851e-05 - loss: 0.0547 - val_accuracy: 5.4496e-06 - val_loss: 0.0598\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 13s/step - accuracy: 8.7185e-06 - loss: 0.0542 - val_accuracy: 5.4496e-06 - val_loss: 0.0597\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 12s/step - accuracy: 1.2851e-05 - loss: 0.0538 - val_accuracy: 5.4496e-06 - val_loss: 0.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pywt\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    LL, _ = pywt.dwt2(img, 'haar')\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"image_denoising_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_denoising_model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Define the path to the noisy image\u001b[39;00m\n\u001b[0;32m     23\u001b[0m noisy_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0002.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    177\u001b[0m         filepath,\n\u001b[0;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:155\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    151\u001b[0m training_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(training_config)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Compile model.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43msaving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args_from_training_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m )\n\u001b[0;32m    159\u001b[0m saving_utils\u001b[38;5;241m.\u001b[39mtry_build_compiled_arguments(model)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Set optimizer weights.\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:143\u001b[0m, in \u001b[0;36mcompile_args_from_training_config\u001b[1;34m(training_config, custom_objects)\u001b[0m\n\u001b[0;32m    141\u001b[0m loss_config \u001b[38;5;241m=\u001b[39m training_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43m_deserialize_nested_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Ensure backwards compatibility for losses in legacy H5 files\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m _resolve_compile_arguments_compat(loss, loss_config, losses)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:202\u001b[0m, in \u001b[0;36m_deserialize_nested_config\u001b[1;34m(deserialize_fn, config)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_single_object(config):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    205\u001b[0m         k: _deserialize_nested_config(deserialize_fn, v)\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    207\u001b[0m     }\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\losses\\__init__.py:124\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.losses.deserialize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeserialize\u001b[39m(name, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserializes a serialized loss class/function instance.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m        A Keras `Loss` instance or a loss function.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_OBJECTS_DICT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:570\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module_objects[config], types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m--> 570\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                \u001b[49m\u001b[43mserialize_with_public_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_module_name\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m deserialize_keras_object(\n\u001b[0;32m    577\u001b[0m             serialize_with_public_class(\n\u001b[0;32m    578\u001b[0m                 module_objects[config], inner_config\u001b[38;5;241m=\u001b[39minner_config\n\u001b[0;32m    579\u001b[0m             ),\n\u001b[0;32m    580\u001b[0m             custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    581\u001b[0m         )\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PLAIN_TYPES):\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:671\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    670\u001b[0m     fn_name \u001b[38;5;241m=\u001b[39m inner_config\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;66;03m# Below, handling of all classes.\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# First, is it a shared object?\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:805\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[1;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 805\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure custom classes are decorated with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to post-process the predicted image\n",
    "def postprocess_image(img):\n",
    "    img = np.clip(img, 0, 1) * 255\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.h5\")\n",
    "\n",
    "# Define the path to the noisy image\n",
    "noisy_image_path = \"0002.png\"\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Use the model to predict the denoised image\n",
    "denoised_image = model.predict(np.expand_dims(input_image, axis=0))[0]\n",
    "\n",
    "# Post-process the predicted image\n",
    "denoised_image = postprocess_image(denoised_image)\n",
    "\n",
    "# Save the denoised image\n",
    "cv2.imwrite(\"denoised_image.png\", denoised_image)\n",
    "\n",
    "# Display the original and denoised images\n",
    "original_image = cv2.imread(noisy_image_path)\n",
    "cv2.imshow(\"Original Image\", original_image)\n",
    "cv2.imshow(\"Denoised Image\", denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.backend' has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39mmse, metrics\u001b[38;5;241m=\u001b[39m[mse])\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Model Training\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Save the model in the native Keras format\u001b[39;00m\n\u001b[0;32m     55\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_denoising_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36mmse\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmse\u001b[39m(y_true, y_pred):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m(K\u001b[38;5;241m.\u001b[39msquare(y_true \u001b[38;5;241m-\u001b[39m y_pred))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.backend' has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "\n",
    "# Define custom mean squared error (MSE) metric\n",
    "def mse(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true - y_pred))\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"  # Change this to the desired noisy level\n",
    "clean_data_dir = \"CBSD68/original\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model with custom MSE metric\n",
    "model.compile(optimizer='adam', loss=mse, metrics=[mse])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model in the native Keras format\n",
    "model.save(\"image_denoising_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.h5\", custom_objects={'mse': mse})\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to post-process the predicted image\n",
    "def postprocess_image(img):\n",
    "    img = np.clip(img, 0, 1) * 255\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Define the path to the noisy image\n",
    "noisy_image_path = \"0002.png\"\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Use the model to predict the denoised image\n",
    "denoised_image = model.predict(np.expand_dims(input_image, axis=0))[0]\n",
    "\n",
    "# Post-process the predicted image\n",
    "denoised_image = postprocess_image(denoised_image)\n",
    "\n",
    "# Save the denoised image\n",
    "cv2.imwrite(\"denoised_image.png\", denoised_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 15s/step - loss: 0.0606 - mse: 0.0605 - val_loss: 0.0516 - val_mse: 0.0516\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16s/step - loss: 0.0575 - mse: 0.0568 - val_loss: 0.0494 - val_mse: 0.0494\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15s/step - loss: 0.0570 - mse: 0.0584 - val_loss: 0.0460 - val_mse: 0.0460\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 15s/step - loss: 0.0506 - mse: 0.0497 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12s/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10s/step - loss: 0.0395 - mse: 0.0401 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 10s/step - loss: 0.0333 - mse: 0.0335 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 10s/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10s/step - loss: 0.0157 - mse: 0.0158 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11s/step - loss: 0.0120 - mse: 0.0123 - val_loss: 0.0089 - val_mse: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pywt\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    LL, _ = coeffs\n",
    "    return LL\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"\n",
    "clean_data_dir = \"CBSD68/original_png\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"image_denoising_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in the native Keras format\n",
    "model.save(\"image_denoising_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# Function to post-process the predicted image\n",
    "def postprocess_image(img):\n",
    "    img = np.clip(img, 0, 1) * 255\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model.keras\", compile=False)\n",
    "\n",
    "# Define the path to the noisy image\n",
    "noisy_image_path = \"0009.png\"\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = preprocess_image(noisy_image_path)\n",
    "\n",
    "# Use the model to predict the denoised image\n",
    "denoised_image = model.predict(np.expand_dims(input_image, axis=0))[0]\n",
    "\n",
    "# Post-process the predicted image\n",
    "denoised_image = postprocess_image(denoised_image)\n",
    "\n",
    "# Display the original and denoised images\n",
    "original_image = cv2.imread(noisy_image_path)\n",
    "cv2.imshow(\"Original Image\", original_image)\n",
    "cv2.imshow(\"Denoised Image\", denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 26s/step - loss: 0.0678 - mse: 0.0674 - val_loss: 0.0607 - val_mse: 0.0607\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11s/step - loss: 0.0662 - mse: 0.0662 - val_loss: 0.0591 - val_mse: 0.0591\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 12s/step - loss: 0.0643 - mse: 0.0647 - val_loss: 0.0562 - val_mse: 0.0562\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14s/step - loss: 0.0602 - mse: 0.0606 - val_loss: 0.0504 - val_mse: 0.0504\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 11s/step - loss: 0.0531 - mse: 0.0534 - val_loss: 0.0421 - val_mse: 0.0421\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12s/step - loss: 0.0439 - mse: 0.0445 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 11s/step - loss: 0.0315 - mse: 0.0318 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12s/step - loss: 0.0210 - mse: 0.0213 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 12s/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12s/step - loss: 0.0176 - mse: 0.0178 - val_loss: 0.0209 - val_mse: 0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pywt\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename))\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs_R = pywt.dwt2(img[:,:,0], 'haar')\n",
    "    coeffs_G = pywt.dwt2(img[:,:,1], 'haar')\n",
    "    coeffs_B = pywt.dwt2(img[:,:,2], 'haar')\n",
    "    LL_R, _ = coeffs_R\n",
    "    LL_G, _ = coeffs_G\n",
    "    LL_B, _ = coeffs_B\n",
    "    return LL_R, LL_G, LL_B\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return images\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"\n",
    "clean_data_dir = \"CBSD68/original_png\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"image_denoising_model_color.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 14s/step - loss: 0.0681 - mse: 0.0682 - val_loss: 0.0602 - val_mse: 0.0602\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13s/step - loss: 0.0642 - mse: 0.0635 - val_loss: 0.0579 - val_mse: 0.0579\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 11s/step - loss: 0.0605 - mse: 0.0598 - val_loss: 0.0523 - val_mse: 0.0523\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 11s/step - loss: 0.0563 - mse: 0.0559 - val_loss: 0.0466 - val_mse: 0.0466\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12s/step - loss: 0.0509 - mse: 0.0515 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13s/step - loss: 0.0411 - mse: 0.0416 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13s/step - loss: 0.0297 - mse: 0.0303 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 12s/step - loss: 0.0200 - mse: 0.0198 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13s/step - loss: 0.0150 - mse: 0.0152 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 14s/step - loss: 0.0136 - mse: 0.0138 - val_loss: 0.0154 - val_mse: 0.0154\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pywt\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(data_dir, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(data_dir, filename))\n",
    "        img = cv2.resize(img, target_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Function for wavelet transform\n",
    "def wavelet_transform(img):\n",
    "    coeffs_R = pywt.dwt2(img[:,:,0], 'haar')\n",
    "    coeffs_G = pywt.dwt2(img[:,:,1], 'haar')\n",
    "    coeffs_B = pywt.dwt2(img[:,:,2], 'haar')\n",
    "    LL_R, _ = coeffs_R\n",
    "    LL_G, _ = coeffs_G\n",
    "    LL_B, _ = coeffs_B\n",
    "    return LL_R, LL_G, LL_B\n",
    "\n",
    "# Function to preprocess and normalize data\n",
    "def preprocess_data(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return images\n",
    "\n",
    "# Load noisy and clean images\n",
    "noisy_data_dir = \"CBSD68/noisy50\"\n",
    "clean_data_dir = \"CBSD68/original_png\"\n",
    "noisy_images = load_data(noisy_data_dir)\n",
    "clean_images = load_data(clean_data_dir)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "y_train = preprocess_data(y_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "y_test = preprocess_data(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model in the native Keras format\n",
    "model.save(\"image_denoising_model_color.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A total of 1 objects could not be loaded. Example error message for object <keras.src.optimizers.adam.Adam object at 0x000002C13AB40650>:\n\n'Unable to synchronously open object (bad object header version number)'\n\nList of objects that could not be loaded:\n[<keras.src.optimizers.adam.Adam object at 0x000002C13AB40650>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m denoised_img\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_denoising_model_color.keras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Example denoising\u001b[39;00m\n\u001b[0;32m     25\u001b[0m noisy_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0009.png\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Path to the noisy image\u001b[39;00m\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:176\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    173\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip:\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(filepath)\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:192\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    189\u001b[0m         asset_store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m failed_trackables:\n\u001b[1;32m--> 192\u001b[0m          \u001b[43m_raise_loading_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror_msgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32md:\\greatestwork\\data\\CBSD68-dataset-master\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:273\u001b[0m, in \u001b[0;36m_raise_loading_failure\u001b[1;34m(error_msgs, warn_only)\u001b[0m\n\u001b[0;32m    271\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: A total of 1 objects could not be loaded. Example error message for object <keras.src.optimizers.adam.Adam object at 0x000002C13AB40650>:\n\n'Unable to synchronously open object (bad object header version number)'\n\nList of objects that could not be loaded:\n[<keras.src.optimizers.adam.Adam object at 0x000002C13AB40650>]"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pywt\n",
    "\n",
    "# Function to denoise an image using the trained model\n",
    "def denoise_image(image_path, model):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    # Resize the image to match the model input shape\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    # Preprocess the image\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    # Denoise the image using the model\n",
    "    denoised_img = model.predict(img)\n",
    "    # Rescale the pixel values to the range [0, 255]\n",
    "    denoised_img = (denoised_img[0] * 255).astype('uint8')\n",
    "    return denoised_img\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"image_denoising_model_color.keras\")\n",
    "\n",
    "# Example denoising\n",
    "noisy_image_path = \"0009.png\"  # Path to the noisy image\n",
    "denoised_image = denoise_image(noisy_image_path, model)\n",
    "\n",
    "# Display the original and denoised images\n",
    "noisy_image = cv2.imread(noisy_image_path)\n",
    "cv2.imshow(\"Noisy Image\", noisy_image)\n",
    "cv2.imshow(\"Denoised Image\", denoised_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
